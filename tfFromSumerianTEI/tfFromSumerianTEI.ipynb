{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF from Sumerian\n",
    "\n",
    "We convert a Sumerian dataset, indicated by Justin Cale Johnson, to text-fabric format.\n",
    "\n",
    "## Model\n",
    "\n",
    "We divide the corpus in sections as follows:\n",
    "\n",
    "* **compositions** Correspond to the individual files;\n",
    "* **sections** Correspond to consecutive `<l>` elements with the same `corresp` attribute;\n",
    "* **lines** Correspond to the individual `<l>` elements.\n",
    "\n",
    "So much for the sectioning.\n",
    "The text is divided further as follows:\n",
    "\n",
    "* **words** Correspond to the individual `<w>` elements;\n",
    "* **glyphs** Correspond to the `-` separated chunks that constitute words.\n",
    "\n",
    "All these divisions are exactly the node types of the resulting TF dataset.\n",
    "The slot type is `glyph`.\n",
    "\n",
    "### NB 1:\n",
    "Words may contain substrings of the form `&`*xyz*`;`.\n",
    "This *xyz* is either an HTML entity that stands for an unicode character.\n",
    "In those cases we replace the entity by the corresponding unicode character.\n",
    "\n",
    "In other cases we consider the *xyz* also to be a glyph, and we translate it into `{`*xyz*`}`.\n",
    "\n",
    "### NB 2:\n",
    "Sometimes lines or sections are empty, i.e. there is no concrete glyph in it.\n",
    "This does not play nice with TF, so we add a single, empty glyph in those elements.\n",
    "\n",
    "## Coverage\n",
    "The `<w>` elements may contain several types of elements. We have only covered\n",
    "**corr corrEnd damage damageEnd supplied suppliedEnd**, and we ignore (for the moment)\n",
    "**gloss note term unclear**.\n",
    "\n",
    "There are also elements between the `<w>` elements, such as `<distinct>`.\n",
    "These we have ignored (so far).\n",
    "\n",
    "Most information in the `<teiHeader>` we ignore,\n",
    "except the `<title>` in `<fileDesc><titleStmt>`.\n",
    "\n",
    "### Notes on features\n",
    "\n",
    "#### text-fabric specific\n",
    "\n",
    "* **otype** for each node type (such as `composition`, `section`, `word`, etc), lists\n",
    "  the ranges of nodes that are member of that type\n",
    "* **oslots** for each node (text-object), lists the glyph positions that are part of it\n",
    "* **otext** configures the sections (`composition`, `section`, `line`) and defines\n",
    "  text rendering formats.\n",
    "\n",
    "#### composition\n",
    "\n",
    "* **compNum** the hierarchical number of the composition, as found in the file name\n",
    "* **title** the English title of the composition, as found in the TEI header\n",
    "\n",
    "#### section\n",
    "\n",
    "* **secNum** the number of the section, as found in the `corresp` attribute on the `<l>`\n",
    "  elements. We take the part after the `p`, and omit the rest. This is always a number.\n",
    "  If the `corresp` attribute is missing, we fill in the value 0.\n",
    "  \n",
    "#### line\n",
    "\n",
    "* **lineNum** the number of the line, as found in the `n` attribute on the `<l>` \n",
    "  elements. This is not always a number.\n",
    "  \n",
    "#### word\n",
    "All attributes on the `<w>` elements are preserved under the same name:\n",
    "\n",
    "* **bound det emesal-prefix emesal form-type form label lemma npart pos type**\n",
    "* **freq_occ** computed feature with the frequency of each word form (using the\n",
    "  `form` attribute of the `<w>` element)\n",
    "* **freq_lex** computed feature with the frequency of each word lexeme (using the\n",
    "  `lemma` attribute of the `<w>` element)\n",
    "* **rank_occ rank_lex** derived from the corresponding `freq_` features.\n",
    "  A node with top frequency has rank 1, lesser frequencies get higher ranks.\n",
    "\n",
    "#### glyph\n",
    "\n",
    "* **ascii** the textual representation of the glyph, as found in the content of the `<w>`\n",
    "  elements.\n",
    "* **trailer** the material to put behind each glyph in order to recreate the original text.\n",
    "  In most cases, this will be a `-`. But for the last glyph of a word, it is ' '.\n",
    "  And if the glyph is of the form `{`*xyz*`}`, it is '', or '-', or ' ', depending on \n",
    "  where it is encountered.\n",
    "* **corr** comes from the `<corr>` and `<corrEnd>` elements. All glyphs inside a `<corr>` or\n",
    "  between a `<corr/>` and `<corrEnd/>` have value 1, the other glyphs have no value.\n",
    "* **damage** All glyphs between a `<damage/>` and `<damageEnd/>` have value 1, the other   \n",
    "  glyphs have no value.\n",
    "* **supplied** All glyphs between a `<supplied/>` and `<suppliedEnd/>` have value 1, the other   glyphs have no value.\n",
    "* **freq_occ** computed feature with the frequency of each glyph\n",
    "* **rank_occ** derived from the corresponding `freq_occ` feature.\n",
    "  A node with top frequency has rank 1, lesser frequencies get higher ranks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prelude\n",
    "General imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob, os, collections, re\n",
    "import xml.etree.ElementTree as ET\n",
    "from html import unescape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the text-fabric package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tf.fabric import Fabric\n",
    "from tf.timestamp import Timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize TF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 2.3.9\n",
      "Api reference : https://github.com/ETCBC/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/ETCBC/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Data sources  : https://github.com/ETCBC/text-fabric-data\n",
      "Data docs     : https://etcbc.github.io/text-fabric-data\n",
      "Shebanq docs  : https://shebanq.ancient-data.org/text\n",
      "Slack team    : https://shebanq.slack.com/signup\n",
      "Questions? Ask shebanq@ancient-data.org for an invite to Slack\n",
      "28 features found and 0 ignored\n"
     ]
    }
   ],
   "source": [
    "tm = Timestamp()\n",
    "TF = Fabric(locations='~/Dropbox/text-fabric-data', modules='sumerian/etcsl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the location of the source materials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DIR_PATH = '~/Documents/DANS/projects/nino/sumerian/tei/'.replace(\n",
    "    '~', os.path.expanduser('~').replace('\\\\', '/'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab the TEI data and store it in memory\n",
    "Set up an object in which all converted data is being collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self):\n",
    "        self.slotType = 'glyph'\n",
    "        self.slotNum = 0\n",
    "        self.nodeNum = 0\n",
    "        self.maxSlot = 0\n",
    "        self.maxNode = 0\n",
    "        self.paths = {}\n",
    "        self.slotFeatures = collections.defaultdict(dict)\n",
    "        self.nodeFeatures = collections.defaultdict(dict)\n",
    "        self.edgeSlotFeatures = collections.defaultdict(lambda: collections.defaultdict(list))\n",
    "        self.edgeFeatures = collections.defaultdict(lambda: collections.defaultdict(list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions to read and convert the TEI XML of a single document (composition)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectionpat = re.compile('^.*\\.p([0-9]+)$')\n",
    "\n",
    "sections = collections.defaultdict(dict)\n",
    "\n",
    "wordContentElems = set()\n",
    "\n",
    "spans = collections.defaultdict(list)\n",
    "\n",
    "def glyphsFromString(glyphString):\n",
    "    glyphs = []\n",
    "    glyphsMain = glyphString.split('-')\n",
    "    lastGlyphMain = len(glyphsMain) - 1\n",
    "    for (i, gm) in enumerate(glyphsMain):\n",
    "        glyphsSub = gm.split('}')\n",
    "        lastGlyphSub = len(glyphsSub) - 1\n",
    "        for (j, gs) in enumerate(glyphsSub):\n",
    "            glyphs.append(\n",
    "                (\n",
    "                    (gs + '}') if gs.startswith('{') else gs, \n",
    "                    ' ' if i == lastGlyphMain and j == lastGlyphSub else \\\n",
    "                    '-' if i != lastGlyphMain and j == lastGlyphSub else\\\n",
    "                    ''\n",
    "                )\n",
    "            )\n",
    "    return glyphs\n",
    "\n",
    "def doGlyphs(glyphString, compN, givenSecN, givenLineN, givenWordN):\n",
    "    glyphs = glyphsFromString(glyphString)\n",
    "    for (glyph, trailer) in glyphs:\n",
    "        data.slotNum += 1\n",
    "        glyphN = data.slotNum\n",
    "        data.slotFeatures['otype'][glyphN] = 'glyph'\n",
    "        data.slotFeatures['ascii'][glyphN] = glyph\n",
    "        data.slotFeatures['trailer'][glyphN] = trailer\n",
    "\n",
    "        data.edgeSlotFeatures['oslots'][compN].append(glyphN)\n",
    "        data.edgeSlotFeatures['oslots'][givenSecN].append(glyphN)\n",
    "        data.edgeSlotFeatures['oslots'][givenLineN].append(glyphN)\n",
    "        if givenWordN != None:\n",
    "            data.edgeSlotFeatures['oslots'][givenWordN].append(glyphN)\n",
    "\n",
    "def walkNode(node, path, compN, givenSecN=None, givenLineN=None, givenWordN=None):\n",
    "    secN = None\n",
    "    lineN = None\n",
    "    wordN = None\n",
    "    if node.tag == 'title' and path[-1] == 'titleStmt' and path[-2] == 'fileDesc' and path[-3] == 'teiHeader':\n",
    "        data.nodeFeatures['title'][compN] = ''.join(node.itertext())\n",
    "    elif node.tag == 'l':\n",
    "        if 'corresp' in node.attrib:\n",
    "            match = sectionpat.findall(node.attrib['corresp'])\n",
    "            secNum = match[0]\n",
    "        else:\n",
    "            secNum = '0'\n",
    "        if secNum not in sections[compN]:\n",
    "            data.nodeNum += 1\n",
    "            secN = data.nodeNum\n",
    "            data.nodeFeatures['otype'][secN] = 'section'\n",
    "            data.nodeFeatures['secNum'][secN] = secNum\n",
    "            sections[compN][secNum] = secN\n",
    "        else:\n",
    "            secN = sections[compN][secNum]\n",
    "        data.nodeNum += 1\n",
    "        lineN = data.nodeNum\n",
    "        lineNum = node.attrib['n']\n",
    "        data.nodeFeatures['otype'][lineN] = 'line'\n",
    "        data.nodeFeatures['lineNum'][lineN] = lineNum\n",
    "        if node.find('.//w') == None:\n",
    "            data.slotNum += 1\n",
    "            glyphN = data.slotNum\n",
    "            data.slotFeatures['otype'][glyphN] = 'glyph'\n",
    "            data.slotFeatures['ascii'][glyphN] = ''\n",
    "            data.slotFeatures['trailer'][glyphN] = ''\n",
    "            data.edgeSlotFeatures['oslots'][compN].append(glyphN)\n",
    "            theSecN = secN if secN != None else givenSecN\n",
    "            data.edgeSlotFeatures['oslots'][theSecN].append(glyphN)\n",
    "            data.edgeSlotFeatures['oslots'][lineN].append(glyphN)\n",
    "    elif node.tag == 'w':\n",
    "        data.nodeNum += 1\n",
    "        wordN = data.nodeNum\n",
    "        data.nodeFeatures['otype'][wordN] = 'word'\n",
    "        for (att, val) in node.attrib.items():\n",
    "            data.nodeFeatures[att][wordN] = val\n",
    "        if node.text != None:\n",
    "            doGlyphs(node.text, compN, givenSecN, givenLineN, wordN)\n",
    "    elif node.tag in {'corr', 'damage', 'supplied'}:\n",
    "        spans[node.tag].append([data.slotNum + 1])\n",
    "        if node.text != None:\n",
    "            doGlyphs(node.text, compN, givenSecN, givenLineN, givenWordN)\n",
    "            spans[node.tag][-1].append(data.slotNum)\n",
    "    elif node.tag in {'corrEnd', 'damageEnd', 'suppliedEnd'}:\n",
    "        spans[node.tag.replace('End', '')][-1].append(data.slotNum)\n",
    "    if givenWordN != None:\n",
    "        wordContentElems.add(node.tag)\n",
    "        if node.text != None and node.tag not in {'corr', 'damage', 'supplied'}:\n",
    "            doGlyphs(node.text, compN, givenSecN, givenLineN, givenWordN)\n",
    "        if node.tail != None:\n",
    "            doGlyphs(node.tail, compN, givenSecN, givenLineN, givenWordN)\n",
    "        \n",
    "    theSecN = secN if secN != None else givenSecN\n",
    "    theLineN = lineN if lineN != None else givenLineN\n",
    "    theWordN = wordN if wordN != None else givenWordN\n",
    "    for child in node:\n",
    "        walkNode(\n",
    "            child, path + (node.tag,), compN,\n",
    "            givenSecN=theSecN, givenLineN=theLineN, givenWordN=theWordN,\n",
    "        )\n",
    "\n",
    "def getNode(root, compNum):\n",
    "    data.nodeNum += 1\n",
    "    compN = data.nodeNum\n",
    "    data.nodeFeatures['otype'][compN] = 'composition'\n",
    "    data.nodeFeatures['compNum'][compN] = compNum\n",
    "    walkNode(root, (), compN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions to reorganize the data that has been collected, so that it is ready to be transformed to TF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def doSpans():\n",
    "    for (tag, stretches) in spans.items():\n",
    "        for span in stretches:\n",
    "            if len(span) < 2:\n",
    "                (start, end) = (span[0], span[0])\n",
    "            else:\n",
    "                (start, end) = (span[0], span[-1])\n",
    "            for glyphN in range(start, end + 1):\n",
    "                data.slotFeatures[tag][glyphN] = '1'\n",
    "\n",
    "def reorder():\n",
    "    slotType = data.slotType\n",
    "    data.maxSlot = data.slotNum\n",
    "    data.maxNode = data.nodeNum\n",
    "    otypeValues = set(data.nodeFeatures['otype'].values())\n",
    "    newIds = sorted(\n",
    "        range(1, data.maxNode + 1),\n",
    "        key=lambda n: (data.nodeFeatures['otype'][n], n),\n",
    "    )\n",
    "    mapping = dict(((v, i + 1 + data.maxSlot) for (i, v) in enumerate(newIds)))\n",
    "    \n",
    "    orderedFeatures = {}\n",
    "    for (name, dat) in data.nodeFeatures.items():\n",
    "        orderedFeatures[name] = dict(((mapping[n], v) for (n, v) in dat.items()))\n",
    "    for (name, dat) in data.slotFeatures.items():\n",
    "        if name not in orderedFeatures: orderedFeatures[name] = {}\n",
    "        orderedFeatures[name].update(dat)\n",
    "    data.nodeFeatures = orderedFeatures\n",
    "\n",
    "    orderedFeatures = {}\n",
    "    for (name, dat) in data.edgeFeatures.items():\n",
    "        orderedFeatures[name] = dict(((mapping[n], [mapping[m] for m in v]) for (n, v) in dat.items()))\n",
    "    for (name, dat) in data.edgeSlotFeatures.items():\n",
    "        if name not in orderedFeatures: orderedFeatures[name] = {}\n",
    "        orderedFeatures[name].update(dict(((mapping[n], v) for (n, v) in dat.items())))\n",
    "    data.edgeFeatures = orderedFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put everything together: \n",
    "\n",
    "* read the files\n",
    "* postprocess the data\n",
    "\n",
    "This will result in having all data in memory, in datastructures that can be readily written to TF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Scanning TEI sources of all compositions\n",
      "   |     0.00s composition   0: 0.1.1\n",
      "   |     0.01s composition   1: 0.1.2\n",
      "   |     0.01s composition   2: 0.2.01\n",
      "   |     0.02s composition   3: 0.2.02\n",
      "   |     0.03s composition   4: 0.2.03\n",
      "   |     0.03s composition   5: 0.2.04\n",
      "   |     0.04s composition   6: 0.2.05\n",
      "   |     0.05s composition   7: 0.2.06\n",
      "   |     0.05s composition   8: 0.2.07\n",
      "   |     0.06s composition   9: 0.2.08\n",
      "   |     0.07s composition  10: 0.2.11\n",
      "   |     0.07s composition  11: 0.2.12\n",
      "   |     0.08s composition  12: 0.2.13\n",
      "   |     0.08s composition  13: 1.1.1\n",
      "   |     0.13s composition  14: 1.1.2\n",
      "   |     0.16s composition  15: 1.1.3\n",
      "   |     0.22s composition  16: 1.1.4\n",
      "   |     0.23s composition  17: 1.2.1\n",
      "   |     0.28s composition  18: 1.2.2\n",
      "   |     0.31s composition  19: 1.3.1\n",
      "   |     0.38s composition  20: 1.3.2\n",
      "   |     0.40s composition  21: 1.3.3\n",
      "   |     0.44s composition  22: 1.3.4\n",
      "   |     0.45s composition  23: 1.3.5\n",
      "   |     0.47s composition  24: 1.4.1.1\n",
      "   |     0.48s composition  25: 1.4.1.3\n",
      "   |     0.50s composition  26: 1.4.1\n",
      "   |     0.55s composition  27: 1.4.3\n",
      "   |     0.59s composition  28: 1.4.4\n",
      "   |     0.61s composition  29: 1.5.1\n",
      "   |     0.65s composition  30: 1.6.1\n",
      "   |     0.68s composition  31: 1.6.2\n",
      "   |     0.76s composition  32: 1.6.3\n",
      "   |     0.77s composition  33: 1.7.1\n",
      "   |     0.79s composition  34: 1.7.3\n",
      "   |     0.81s composition  35: 1.7.4\n",
      "   |     0.83s composition  36: 1.7.6\n",
      "   |     0.83s composition  37: 1.7.7\n",
      "   |     0.84s composition  38: 1.7.8\n",
      "   |     0.86s composition  39: 1.8.1.1\n",
      "   |     0.87s composition  40: 1.8.1.2\n",
      "   |     0.95s composition  41: 1.8.1.3\n",
      "   |     1.00s composition  42: 1.8.1.4\n",
      "   |     1.06s composition  43: 1.8.1.5.1\n",
      "   |     1.09s composition  44: 1.8.1.5\n",
      "   |     1.13s composition  45: 1.8.2.1\n",
      "   |     1.19s composition  46: 1.8.2.2\n",
      "   |     1.23s composition  47: 1.8.2.3\n",
      "   |     1.30s composition  48: 1.8.2.4\n",
      "   |     1.34s composition  49: 2.1.1\n",
      "   |     1.38s composition  50: 2.1.2\n",
      "   |     1.40s composition  51: 2.1.3\n",
      "   |     1.40s composition  52: 2.1.4\n",
      "   |     1.42s composition  53: 2.1.5\n",
      "   |     1.46s composition  54: 2.1.6\n",
      "   |     1.47s composition  55: 2.1.7\n",
      "   |     1.63s composition  56: 2.2.2\n",
      "   |     1.69s composition  57: 2.2.3\n",
      "   |     1.75s composition  58: 2.2.4\n",
      "   |     1.79s composition  59: 2.2.5\n",
      "   |     1.83s composition  60: 2.2.6\n",
      "   |     1.85s composition  61: 2.3.1\n",
      "   |     1.86s composition  62: 2.3.2\n",
      "   |     1.87s composition  63: 2.4.1.1\n",
      "   |     1.93s composition  64: 2.4.1.2\n",
      "   |     1.94s composition  65: 2.4.1.3\n",
      "   |     1.96s composition  66: 2.4.1.4\n",
      "   |     1.98s composition  67: 2.4.1.5\n",
      "   |     1.99s composition  68: 2.4.1.6\n",
      "   |     2.00s composition  69: 2.4.1.7\n",
      "   |     2.01s composition  70: 2.4.1.8\n",
      "   |     2.01s composition  71: 2.4.1.a\n",
      "   |     2.01s composition  72: 2.4.2.01\n",
      "   |     2.03s composition  73: 2.4.2.02\n",
      "   |     2.11s composition  74: 2.4.2.03\n",
      "   |     2.14s composition  75: 2.4.2.04\n",
      "   |     2.22s composition  76: 2.4.2.05\n",
      "   |     2.24s composition  77: 2.4.2.07\n",
      "   |     2.25s composition  78: 2.4.2.12\n",
      "   |     2.26s composition  79: 2.4.2.14\n",
      "   |     2.27s composition  80: 2.4.2.15\n",
      "   |     2.30s composition  81: 2.4.2.16\n",
      "   |     2.31s composition  82: 2.4.2.17\n",
      "   |     2.32s composition  83: 2.4.2.18\n",
      "   |     2.34s composition  84: 2.4.2.20\n",
      "   |     2.35s composition  85: 2.4.2.21\n",
      "   |     2.36s composition  86: 2.4.2.22\n",
      "   |     2.37s composition  87: 2.4.2.23\n",
      "   |     2.37s composition  88: 2.4.2.24\n",
      "   |     2.39s composition  89: 2.4.2.25\n",
      "   |     2.40s composition  90: 2.4.2.26\n",
      "   |     2.41s composition  91: 2.4.2.a\n",
      "   |     2.42s composition  92: 2.4.2.b\n",
      "   |     2.43s composition  93: 2.4.3.1\n",
      "   |     2.44s composition  94: 2.4.4.1\n",
      "   |     2.45s composition  95: 2.4.4.2\n",
      "   |     2.45s composition  96: 2.4.4.3\n",
      "   |     2.46s composition  97: 2.4.4.4\n",
      "   |     2.47s composition  98: 2.4.4.5\n",
      "   |     2.48s composition  99: 2.4.4.6\n",
      "   |     2.49s composition 100: 2.4.4.9\n",
      "   |     2.49s composition 101: 2.4.4.a\n",
      "   |     2.50s composition 102: 2.4.5.1\n",
      "   |     2.51s composition 103: 2.4.5.2\n",
      "   |     2.53s composition 104: 2.4.5.3\n",
      "   |     2.54s composition 105: 2.4.5.4\n",
      "   |     2.55s composition 106: 2.4.5.5\n",
      "   |     2.55s composition 107: 2.5.1.2\n",
      "   |     2.57s composition 108: 2.5.1.3\n",
      "   |     2.58s composition 109: 2.5.1.4\n",
      "   |     2.58s composition 110: 2.5.2.1\n",
      "   |     2.60s composition 111: 2.5.2.3\n",
      "   |     2.60s composition 112: 2.5.3.1\n",
      "   |     2.63s composition 113: 2.5.3.2\n",
      "   |     2.64s composition 114: 2.5.3.3\n",
      "   |     2.66s composition 115: 2.5.3.4\n",
      "   |     2.67s composition 116: 2.5.4.01\n",
      "   |     2.73s composition 117: 2.5.4.02\n",
      "   |     2.75s composition 118: 2.5.4.03\n",
      "   |     2.76s composition 119: 2.5.4.04\n",
      "   |     2.76s composition 120: 2.5.4.05\n",
      "   |     2.77s composition 121: 2.5.4.08\n",
      "   |     2.79s composition 122: 2.5.4.09\n",
      "   |     2.80s composition 123: 2.5.4.10\n",
      "   |     2.81s composition 124: 2.5.4.11\n",
      "   |     2.82s composition 125: 2.5.4.13\n",
      "   |     2.84s composition 126: 2.5.4.15\n",
      "   |     2.87s composition 127: 2.5.4.16\n",
      "   |     2.87s composition 128: 2.5.4.17\n",
      "   |     2.89s composition 129: 2.5.4.19\n",
      "   |     2.90s composition 130: 2.5.4.21\n",
      "   |     2.90s composition 131: 2.5.4.23\n",
      "   |     2.92s composition 132: 2.5.4.24\n",
      "   |     2.93s composition 133: 2.5.4.27\n",
      "   |     2.94s composition 134: 2.5.4.29\n",
      "   |     2.94s composition 135: 2.5.4.a\n",
      "   |     2.95s composition 136: 2.5.4.b\n",
      "   |     2.95s composition 137: 2.5.5.1\n",
      "   |     2.97s composition 138: 2.5.5.2\n",
      "   |     2.98s composition 139: 2.5.5.3\n",
      "   |     2.99s composition 140: 2.5.5.4\n",
      "   |     3.00s composition 141: 2.5.5.5\n",
      "   |     3.01s composition 142: 2.5.5.8\n",
      "   |     3.01s composition 143: 2.5.6.1\n",
      "   |     3.03s composition 144: 2.5.6.2\n",
      "   |     3.04s composition 145: 2.5.6.3\n",
      "   |     3.05s composition 146: 2.5.6.4\n",
      "   |     3.06s composition 147: 2.5.6.5\n",
      "   |     3.07s composition 148: 2.5.6.6\n",
      "   |     3.08s composition 149: 2.5.7.1\n",
      "   |     3.08s composition 150: 2.5.7.2\n",
      "   |     3.09s composition 151: 2.5.8.1\n",
      "   |     3.11s composition 152: 2.6.2.1\n",
      "   |     3.11s composition 153: 2.6.2.a\n",
      "   |     3.12s composition 154: 2.6.6.1\n",
      "   |     3.13s composition 155: 2.6.6.5\n",
      "   |     3.14s composition 156: 2.6.7.1\n",
      "   |     3.15s composition 157: 2.6.9.1\n",
      "   |     3.16s composition 158: 2.6.9.2\n",
      "   |     3.17s composition 159: 2.6.9.3\n",
      "   |     3.18s composition 160: 2.6.9.4\n",
      "   |     3.18s composition 161: 2.6.9.5\n",
      "   |     3.28s composition 162: 2.6.9.6\n",
      "   |     3.28s composition 163: 2.6.9.7\n",
      "   |     3.29s composition 164: 2.6.9.8\n",
      "   |     3.30s composition 165: 2.6.9.a\n",
      "   |     3.30s composition 166: 2.7.1.1\n",
      "   |     3.31s composition 167: 2.8.2.1\n",
      "   |     3.32s composition 168: 2.8.2.2\n",
      "   |     3.33s composition 169: 2.8.2.3\n",
      "   |     3.34s composition 170: 2.8.2.4\n",
      "   |     3.35s composition 171: 2.8.2.5\n",
      "   |     3.35s composition 172: 2.8.2.6\n",
      "   |     3.36s composition 173: 2.8.3.1\n",
      "   |     3.37s composition 174: 2.8.3.2\n",
      "   |     3.38s composition 175: 2.8.3.3\n",
      "   |     3.38s composition 176: 2.8.3.4\n",
      "   |     3.39s composition 177: 2.8.3.5\n",
      "   |     3.39s composition 178: 2.8.3.6\n",
      "   |     3.40s composition 179: 2.8.3.7\n",
      "   |     3.41s composition 180: 2.8.3.8\n",
      "   |     3.41s composition 181: 2.8.5.1\n",
      "   |     3.42s composition 182: 2.8.5.a\n",
      "   |     3.42s composition 183: 2.8.5.b\n",
      "   |     3.43s composition 184: 2.99.b\n",
      "   |     3.43s composition 185: 2.99.c\n",
      "   |     3.44s composition 186: 2.99.d\n",
      "   |     3.44s composition 187: 3.1.01\n",
      "   |     3.45s composition 188: 3.1.02\n",
      "   |     3.46s composition 189: 3.1.03\n",
      "   |     3.46s composition 190: 3.1.04\n",
      "   |     3.47s composition 191: 3.1.05\n",
      "   |     3.47s composition 192: 3.1.06.1\n",
      "   |     3.48s composition 193: 3.1.06\n",
      "   |     3.48s composition 194: 3.1.07\n",
      "   |     3.50s composition 195: 3.1.08\n",
      "   |     3.51s composition 196: 3.1.10\n",
      "   |     3.51s composition 197: 3.1.11.1\n",
      "   |     3.52s composition 198: 3.1.11\n",
      "   |     3.53s composition 199: 3.1.13.1\n",
      "   |     3.53s composition 200: 3.1.13.2\n",
      "   |     3.54s composition 201: 3.1.15\n",
      "   |     3.55s composition 202: 3.1.16\n",
      "   |     3.55s composition 203: 3.1.17\n",
      "   |     3.57s composition 204: 3.1.18\n",
      "   |     3.57s composition 205: 3.1.19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   |     3.58s composition 206: 3.1.20\n",
      "   |     3.60s composition 207: 3.1.21\n",
      "   |     3.60s composition 208: 3.2.01\n",
      "   |     3.61s composition 209: 3.2.02\n",
      "   |     3.61s composition 210: 3.2.03\n",
      "   |     3.62s composition 211: 3.2.04\n",
      "   |     3.62s composition 212: 3.2.05\n",
      "   |     3.63s composition 213: 3.3.01\n",
      "   |     3.64s composition 214: 3.3.02\n",
      "   |     3.65s composition 215: 3.3.03\n",
      "   |     3.66s composition 216: 3.3.04\n",
      "   |     3.66s composition 217: 3.3.05\n",
      "   |     3.67s composition 218: 3.3.06\n",
      "   |     3.67s composition 219: 3.3.07\n",
      "   |     3.67s composition 220: 3.3.08\n",
      "   |     3.68s composition 221: 3.3.09\n",
      "   |     3.69s composition 222: 3.3.10\n",
      "   |     3.69s composition 223: 3.3.11\n",
      "   |     3.70s composition 224: 3.3.12\n",
      "   |     3.70s composition 225: 3.3.20\n",
      "   |     3.70s composition 226: 3.3.21\n",
      "   |     3.71s composition 227: 3.3.22\n",
      "   |     3.72s composition 228: 3.3.27\n",
      "   |     3.72s composition 229: 3.3.39\n",
      "   |     3.73s composition 230: 4.01.1\n",
      "   |     3.73s composition 231: 4.02.1\n",
      "   |     3.75s composition 232: 4.03.1\n",
      "   |     3.76s composition 233: 4.05.1\n",
      "   |     3.78s composition 234: 4.06.1\n",
      "   |     3.81s composition 235: 4.07.1\n",
      "   |     3.82s composition 236: 4.07.2\n",
      "   |     3.84s composition 237: 4.07.3\n",
      "   |     3.88s composition 238: 4.07.4\n",
      "   |     3.90s composition 239: 4.07.5\n",
      "   |     3.91s composition 240: 4.07.6\n",
      "   |     3.92s composition 241: 4.07.7\n",
      "   |     3.93s composition 242: 4.07.8\n",
      "   |     3.94s composition 243: 4.07.9\n",
      "   |     3.95s composition 244: 4.07.a\n",
      "   |     3.96s composition 245: 4.08.01\n",
      "   |     3.97s composition 246: 4.08.02\n",
      "   |     3.98s composition 247: 4.08.03\n",
      "   |     3.99s composition 248: 4.08.04\n",
      "   |     3.99s composition 249: 4.08.05\n",
      "   |     4.00s composition 250: 4.08.06\n",
      "   |     4.01s composition 251: 4.08.07\n",
      "   |     4.01s composition 252: 4.08.08\n",
      "   |     4.02s composition 253: 4.08.09\n",
      "   |     4.03s composition 254: 4.08.10\n",
      "   |     4.03s composition 255: 4.08.12\n",
      "   |     4.04s composition 256: 4.08.13\n",
      "   |     4.04s composition 257: 4.08.15\n",
      "   |     4.05s composition 258: 4.08.16\n",
      "   |     4.07s composition 259: 4.08.18\n",
      "   |     4.08s composition 260: 4.08.20\n",
      "   |     4.09s composition 261: 4.08.22\n",
      "   |     4.09s composition 262: 4.08.23\n",
      "   |     4.10s composition 263: 4.08.25\n",
      "   |     4.11s composition 264: 4.08.26\n",
      "   |     4.12s composition 265: 4.08.28\n",
      "   |     4.13s composition 266: 4.08.29\n",
      "   |     4.14s composition 267: 4.08.30\n",
      "   |     4.16s composition 268: 4.08.31\n",
      "   |     4.16s composition 269: 4.08.32\n",
      "   |     4.17s composition 270: 4.08.33\n",
      "   |     4.18s composition 271: 4.08.a\n",
      "   |     4.19s composition 272: 4.12.1\n",
      "   |     4.20s composition 273: 4.12.2\n",
      "   |     4.21s composition 274: 4.13.01\n",
      "   |     4.22s composition 275: 4.13.02\n",
      "   |     4.23s composition 276: 4.13.03\n",
      "   |     4.24s composition 277: 4.13.04\n",
      "   |     4.25s composition 278: 4.13.05\n",
      "   |     4.26s composition 279: 4.13.06\n",
      "   |     4.27s composition 280: 4.13.07\n",
      "   |     4.28s composition 281: 4.13.08\n",
      "   |     4.28s composition 282: 4.13.09\n",
      "   |     4.29s composition 283: 4.13.10\n",
      "   |     4.30s composition 284: 4.13.11\n",
      "   |     4.31s composition 285: 4.13.12\n",
      "   |     4.32s composition 286: 4.13.13\n",
      "   |     4.33s composition 287: 4.13.14\n",
      "   |     4.33s composition 288: 4.13.15\n",
      "   |     4.34s composition 289: 4.13.a\n",
      "   |     4.35s composition 290: 4.13.b\n",
      "   |     4.35s composition 291: 4.13.c\n",
      "   |     4.36s composition 292: 4.13.d\n",
      "   |     4.36s composition 293: 4.14.1\n",
      "   |     4.46s composition 294: 4.14.2\n",
      "   |     4.47s composition 295: 4.14.3\n",
      "   |     4.49s composition 296: 4.15.2\n",
      "   |     4.50s composition 297: 4.15.3\n",
      "   |     4.51s composition 298: 4.16.1\n",
      "   |     4.52s composition 299: 4.16.2\n",
      "   |     4.53s composition 300: 4.17.1\n",
      "   |     4.54s composition 301: 4.19.1\n",
      "   |     4.55s composition 302: 4.19.2\n",
      "   |     4.55s composition 303: 4.19.3\n",
      "   |     4.56s composition 304: 4.19.4\n",
      "   |     4.57s composition 305: 4.21.1\n",
      "   |     4.57s composition 306: 4.22.1\n",
      "   |     4.59s composition 307: 4.22.2\n",
      "   |     4.59s composition 308: 4.22.3\n",
      "   |     4.60s composition 309: 4.22.4\n",
      "   |     4.61s composition 310: 4.22.5\n",
      "   |     4.61s composition 311: 4.22.6\n",
      "   |     4.62s composition 312: 4.23.1\n",
      "   |     4.63s composition 313: 4.24.1\n",
      "   |     4.64s composition 314: 4.25.1\n",
      "   |     4.64s composition 315: 4.25.2\n",
      "   |     4.65s composition 316: 4.26.1\n",
      "   |     4.66s composition 317: 4.27.01\n",
      "   |     4.67s composition 318: 4.27.02\n",
      "   |     4.68s composition 319: 4.27.03\n",
      "   |     4.69s composition 320: 4.27.04\n",
      "   |     4.70s composition 321: 4.27.06\n",
      "   |     4.70s composition 322: 4.27.07\n",
      "   |     4.72s composition 323: 4.27.a\n",
      "   |     4.72s composition 324: 4.28.1\n",
      "   |     4.75s composition 325: 4.29.1\n",
      "   |     4.76s composition 326: 4.29.2\n",
      "   |     4.77s composition 327: 4.30.1\n",
      "   |     4.77s composition 328: 4.31.1\n",
      "   |     4.79s composition 329: 4.32.2\n",
      "   |     4.80s composition 330: 4.32.e\n",
      "   |     4.81s composition 331: 4.32.f\n",
      "   |     4.82s composition 332: 4.33.1\n",
      "   |     4.83s composition 333: 4.33.2\n",
      "   |     4.84s composition 334: 4.80.1\n",
      "   |     4.90s composition 335: 4.80.2\n",
      "   |     4.92s composition 336: 4.80.4\n",
      "   |     4.93s composition 337: 5.1.3\n",
      "   |     4.94s composition 338: 5.2.4\n",
      "   |     4.98s composition 339: 5.2.5\n",
      "   |     4.98s composition 340: 5.3.1\n",
      "   |     5.01s composition 341: 5.3.2\n",
      "   |     5.03s composition 342: 5.3.3\n",
      "   |     5.11s composition 343: 5.3.5\n",
      "   |     5.14s composition 344: 5.3.6\n",
      "   |     5.18s composition 345: 5.3.7\n",
      "   |     5.18s composition 346: 5.4.11\n",
      "   |     5.19s composition 347: 5.4.12\n",
      "   |     5.20s composition 348: 5.5.1\n",
      "   |     5.21s composition 349: 5.5.2\n",
      "   |     5.23s composition 350: 5.5.3\n",
      "   |     5.26s composition 351: 5.5.4\n",
      "   |     5.27s composition 352: 5.5.5\n",
      "   |     5.29s composition 353: 5.5.a\n",
      "   |     5.29s composition 354: 5.6.1\n",
      "   |     5.33s composition 355: 5.6.3\n",
      "   |     5.34s composition 356: 5.6.5\n",
      "   |     5.36s composition 357: 5.7.1\n",
      "   |     5.36s composition 358: 5.7.2\n",
      "   |     5.37s composition 359: 5.7.3\n",
      "   |     5.37s composition 360: 5.7.a\n",
      "   |     5.37s composition 361: 5.9.1\n",
      "   |     5.48s composition 362: 5.9.2\n",
      "   |     5.50s composition 363: 6.1.01\n",
      "   |     5.54s composition 364: 6.1.02\n",
      "   |     5.58s composition 365: 6.1.03\n",
      "   |     5.61s composition 366: 6.1.04\n",
      "   |     5.62s composition 367: 6.1.05\n",
      "   |     5.65s composition 368: 6.1.07\n",
      "   |     5.67s composition 369: 6.1.08\n",
      "   |     5.68s composition 370: 6.1.09\n",
      "   |     5.69s composition 371: 6.1.10\n",
      "   |     5.70s composition 372: 6.1.11\n",
      "   |     5.71s composition 373: 6.1.12\n",
      "   |     5.73s composition 374: 6.1.13\n",
      "   |     5.75s composition 375: 6.1.14\n",
      "   |     5.75s composition 376: 6.1.15\n",
      "   |     5.77s composition 377: 6.1.16\n",
      "   |     5.78s composition 378: 6.1.17\n",
      "   |     5.79s composition 379: 6.1.18\n",
      "   |     5.79s composition 380: 6.1.19\n",
      "   |     5.81s composition 381: 6.1.21\n",
      "   |     5.82s composition 382: 6.1.22\n",
      "   |     5.84s composition 383: 6.1.23\n",
      "   |     5.85s composition 384: 6.1.24\n",
      "   |     5.85s composition 385: 6.1.25\n",
      "   |     5.86s composition 386: 6.1.26\n",
      "   |     5.87s composition 387: 6.1.27\n",
      "   |     5.88s composition 388: 6.1.28\n",
      "   |     5.88s composition 389: 6.2.1\n",
      "   |     5.92s composition 390: 6.2.2\n",
      "   |     5.92s composition 391: 6.2.3\n",
      "   |     5.98s composition 392: 6.2.4\n",
      "   |     5.98s composition 393: 6.2.5\n",
      "  6.01s Slots:        412192\n",
      "  6.01s Other nodes:  213201\n",
      "  6.01s Processing data ...\n",
      "  6.78s Done\n",
      "Elements found in word content:\n",
      "\tcorr\n",
      "\tcorrEnd\n",
      "\tdamage\n",
      "\tdamageEnd\n",
      "\tgloss\n",
      "\tnote\n",
      "\tsupplied\n",
      "\tsuppliedEnd\n",
      "\tterm\n",
      "\tunclear\n"
     ]
    }
   ],
   "source": [
    "filenamepat = re.compile('^c\\.([0-9a-z.]*)$')\n",
    "entitypat = re.compile('&([^; \\n]+);')\n",
    "\n",
    "def replaceEntity(match): return '{{{}}}'.format(match.group(1))\n",
    "\n",
    "data = Data()\n",
    "\n",
    "tm.indent(level=0, reset=True)\n",
    "tm.info('Scanning TEI sources of all compositions')\n",
    "tm.indent(level=1, reset=True)\n",
    "for (i, xmlfile) in enumerate(glob.glob(DIR_PATH+'*.xml')):\n",
    "    (dirName, baseName) = os.path.split(xmlfile)\n",
    "    (fileName, extension) = os.path.splitext(baseName)\n",
    "    match = filenamepat.findall(fileName)\n",
    "    if len(match) == 0:\n",
    "        tm.error('unexpected file: \"{}\"'.format(baseName))\n",
    "        continue\n",
    "    compNum = match[0]\n",
    "    tm.info('composition {:>3}: {}'.format(i, compNum))\n",
    "    with open(xmlfile) as xf:\n",
    "        text = unescape(xf.read())\n",
    "        text = entitypat.sub(replaceEntity, text)\n",
    "    root = ET.fromstring(text)\n",
    "    getNode(root, compNum)\n",
    "tm.indent(level=0)\n",
    "tm.info('Slots:       {:>7}'.format(data.slotNum))\n",
    "tm.info('Other nodes: {:>7}'.format(data.nodeNum))\n",
    "tm.info('Processing data ...')\n",
    "doSpans()\n",
    "reorder()\n",
    "tm.info('Done')\n",
    "\n",
    "print('Elements found in word content:\\n\\t{}'.format('\\n\\t'.join(sorted(wordContentElems))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few checks.\n",
    "Finding out the contents of the `<w>` elements was a matter of trial and error.\n",
    "It seems that there are still a few rough edges (very few, indeed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "damage   : 11306 spans,   1 faulty\n",
      "supplied : 17865 spans,   4 faulty\n",
      "corr     :  1102 spans,   0 faulty\n"
     ]
    }
   ],
   "source": [
    "faulty = collections.defaultdict(list)\n",
    "for (tag, stretches) in spans.items():\n",
    "    for span in stretches:\n",
    "        if len(span) != 2:\n",
    "            faulty[tag].append(span)\n",
    "    print('{:<9}: {:>5} spans, {:>3} faulty'.format(tag, len(stretches), len(faulty[tag])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'corr': [],\n",
       "             'damage': [[412032, 412032, 412032]],\n",
       "             'supplied': [[3176, 3180, 3186],\n",
       "              [157050],\n",
       "              [282876, 282877, 282885],\n",
       "              [396033]]})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faulty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add metadata\n",
    "Before we can export to TF, we have to supply essential metadata about the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metaData = {\n",
    "    '': dict(\n",
    "        createdBy='Justin Cale Johnson and Dirk Roorda',\n",
    "    ),\n",
    "    'otext': {\n",
    "        'sectionFeatures': 'compNum,secNum,lineNum',\n",
    "        'sectionTypes': 'composition,section,line',\n",
    "        'fmt:text-orig-full': '{ascii}{trailer}',\n",
    "        'fmt:form-orig-full': '{form} ',\n",
    "        'fmt:lex-orig-full': '{lemma} ',\n",
    "    },\n",
    "}\n",
    "\n",
    "numberFeatures = set('''\n",
    "    secNum\n",
    "'''.strip().split())\n",
    "\n",
    "for nf in data.nodeFeatures:\n",
    "    metaData.setdefault(nf, {})['valueType'] = 'int' if nf in numberFeatures else 'str'\n",
    "for ef in data.edgeFeatures:\n",
    "    metaData.setdefault(ef, {})['valueType'] = 'int' if ef in numberFeatures else 'str'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra features: statistical\n",
    "We add some statistical features:\n",
    "\n",
    "* rank and frequency for word occurrences and lexemes\n",
    "* rank and frequency for glyphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8m 51s Computing statistics\n",
      " 8m 52s Done\n",
      " 8m 52s Adding statistics as features\n",
      " 8m 54s Done\n"
     ]
    }
   ],
   "source": [
    "tm.info('Computing statistics')\n",
    "gstats = {\n",
    "    'freq': {\n",
    "        'occ': collections.Counter(),\n",
    "    },\n",
    "    'rank': {\n",
    "        'occ': {},\n",
    "    },\n",
    "}\n",
    "wstats = {\n",
    "    'freq': {\n",
    "        'lex': collections.Counter(),\n",
    "        'occ': collections.Counter(),\n",
    "    },\n",
    "    'rank': {\n",
    "        'lex': {},\n",
    "        'occ': {},\n",
    "    },\n",
    "}\n",
    "\n",
    "nodeFeatures = data.nodeFeatures\n",
    "\n",
    "words = [n[0] for n in nodeFeatures['otype'].items() if n[1] == 'word']\n",
    "glyphs = [n[0] for n in nodeFeatures['otype'].items() if n[1] == 'glyph']\n",
    "\n",
    "for g in glyphs:\n",
    "    occ = nodeFeatures['ascii'][g]\n",
    "    gstats['freq']['occ'][occ] += 1\n",
    "tp = 'occ'\n",
    "rank = -1\n",
    "prev_n = -1\n",
    "amount = 1\n",
    "for (x, n) in sorted(gstats['freq'][tp].items(), key=lambda y: (-y[1], y[0])):\n",
    "    if n == prev_n:\n",
    "        amount += 1\n",
    "    else:\n",
    "        rank += amount\n",
    "        amount = 1\n",
    "    prev_n = n\n",
    "    gstats['rank'][tp][x] = rank\n",
    "        \n",
    "for w in words:\n",
    "    occ = nodeFeatures['form'][w]\n",
    "    lex = nodeFeatures['lemma'][w]\n",
    "    wstats['freq']['lex'][lex] += 1\n",
    "    wstats['freq']['occ'][occ] += 1\n",
    "for tp in ['lex', 'occ']:\n",
    "    rank = -1\n",
    "    prev_n = -1\n",
    "    amount = 1\n",
    "    for (x, n) in sorted(wstats['freq'][tp].items(), key=lambda y: (-y[1], y[0])):\n",
    "        if n == prev_n:\n",
    "            amount += 1\n",
    "        else:\n",
    "            rank += amount\n",
    "            amount = 1\n",
    "        prev_n = n\n",
    "        wstats['rank'][tp][x] = rank\n",
    "tm.info('Done')\n",
    "\n",
    "tm.info('Adding statistics as features')\n",
    "occFeatures = {}\n",
    "for tp in ['occ', 'lex']:\n",
    "    for ft in ('freq_{}'.format(tp), 'rank_{}'.format(tp)):\n",
    "        occFeatures[ft] = {}\n",
    "        metaData.setdefault(ft, {})['valueType'] = 'int'\n",
    "\n",
    "for g in glyphs:\n",
    "    occ = nodeFeatures['ascii'][g]\n",
    "    tp = 'occ'\n",
    "    ref = occ\n",
    "    for kn in ['freq', 'rank']:\n",
    "        ft = '{}_{}'.format(kn, tp)\n",
    "        occFeatures[ft][g] = str(gstats[kn][tp][ref])\n",
    "\n",
    "for w in words:\n",
    "    occ = nodeFeatures['form'][w]\n",
    "    lex = nodeFeatures['lemma'][w]\n",
    "    for tp in ['occ', 'lex']:\n",
    "        ref = occ if tp == 'occ' else lex\n",
    "        for kn in ['freq', 'rank']:\n",
    "            ft = '{}_{}'.format(kn, tp)\n",
    "            occFeatures[ft][w] = str(wstats[kn][tp][ref])\n",
    "\n",
    "nodeFeatures.update(occFeatures)\n",
    "\n",
    "tm.info('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we check whether some text objects have remained without glyphs\n",
    "(e.g. caused by a line with only a `<gap>` element and no `<w>` elements)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glyph: 1-412192\n",
      "composition: 412193-412586\n",
      "section: 449098-455609\n",
      "line: 412587-449097\n",
      "word: 455610-625393\n"
     ]
    }
   ],
   "source": [
    "for otype in ['glyph', 'composition', 'section', 'line', 'word']:\n",
    "    nodes = [n for n in data.nodeFeatures['otype'] if data.nodeFeatures['otype'][n] == otype]\n",
    "    print('{}: {}-{}'.format(\n",
    "        otype,\n",
    "        min(nodes),\n",
    "        max(nodes),\n",
    "    ))\n",
    "    if otype == 'glyph': continue\n",
    "    for n in nodes:\n",
    "        if n not in data.edgeFeatures['oslots']:\n",
    "            print('missing in {}: {}'.format(otype, n))\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the TF dataset\n",
    "We can now produce the text-fabric dataset with one command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Exporting 25 node and 1 edge and 1 config features to /Users/dirk/Dropbox/text-fabric-data/sumerian/etcsl:\n",
      "   |     0.80s T ascii                to /Users/dirk/Dropbox/text-fabric-data/sumerian/etcsl\n",
      "   |     0.01s T bound                to /Users/dirk/Dropbox/text-fabric-data/sumerian/etcsl\n",
      "   |     0.00s T compNum              to /Users/dirk/Dropbox/text-fabric-data/sumerian/etcsl\n",
      "   |     0.01s T corr                 to /Users/dirk/Dropbox/text-fabric-data/sumerian/etcsl\n",
      "   |     0.05s T damage               to /Users/dirk/Dropbox/text-fabric-data/sumerian/etcsl\n",
      "   |     0.04s T det                  to /Users/dirk/Dropbox/text-fabric-data/sumerian/etcsl\n",
      "   |     0.01s T emesal               to /Users/dirk/Dropbox/text-fabric-data/sumerian/etcsl\n",
      "   |     0.00s T emesal-prefix        to /Users/dirk/Dropbox/text-fabric-data/sumerian/etcsl\n",
      "   |     0.39s T form                 to /Users/dirk/Dropbox/text-fabric-data/sumerian/etcsl\n",
      "   |     0.03s T form-type            to /Users/dirk/Dropbox/text-fabric-data/sumerian/etcsl\n",
      "   |     0.49s T freq_lex             to /Users/dirk/Dropbox/text-fabric-data/sumerian/etcsl\n",
      "   |     1.33s T freq_occ             to /Users/dirk/Dropbox/text-fabric-data/sumerian/etcsl\n",
      "   |     0.53s T label                to /Users/dirk/Dropbox/text-fabric-data/sumerian/etcsl\n",
      "   |     0.43s T lemma                to /Users/dirk/Dropbox/text-fabric-data/sumerian/etcsl\n",
      "   |     0.07s T lineNum              to /Users/dirk/Dropbox/text-fabric-data/sumerian/etcsl\n",
      "   |     0.01s T npart                to /Users/dirk/Dropbox/text-fabric-data/sumerian/etcsl\n",
      "   |     0.35s T otype                to /Users/dirk/Dropbox/text-fabric-data/sumerian/etcsl\n",
      "   |     0.29s T pos                  to /Users/dirk/Dropbox/text-fabric-data/sumerian/etcsl\n",
      "   |     0.30s T rank_lex             to /Users/dirk/Dropbox/text-fabric-data/sumerian/etcsl\n",
      "   |     1.41s T rank_occ             to /Users/dirk/Dropbox/text-fabric-data/sumerian/etcsl\n",
      "   |     0.04s T secNum               to /Users/dirk/Dropbox/text-fabric-data/sumerian/etcsl\n",
      "   |     0.16s T supplied             to /Users/dirk/Dropbox/text-fabric-data/sumerian/etcsl\n",
      "   |     0.00s T title                to /Users/dirk/Dropbox/text-fabric-data/sumerian/etcsl\n",
      "   |     0.91s T trailer              to /Users/dirk/Dropbox/text-fabric-data/sumerian/etcsl\n",
      "   |     0.05s T type                 to /Users/dirk/Dropbox/text-fabric-data/sumerian/etcsl\n",
      "   |     1.37s T oslots               to /Users/dirk/Dropbox/text-fabric-data/sumerian/etcsl\n",
      "   |     0.00s M otext                to /Users/dirk/Dropbox/text-fabric-data/sumerian/etcsl\n",
      "  9.17s Exported 25 node features and 1 edge features and 1 config features to /Users/dirk/Dropbox/text-fabric-data/sumerian/etcsl\n"
     ]
    }
   ],
   "source": [
    "TF.save(nodeFeatures=data.nodeFeatures, edgeFeatures=data.edgeFeatures, metaData=metaData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
