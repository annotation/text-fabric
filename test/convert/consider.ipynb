{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T10:40:34.922214Z",
     "start_time": "2018-10-18T10:40:34.901689Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 7.4.3\n",
      "Api reference : https://annotation.github.io/text-fabric/Api/Fabric/\n",
      "\n",
      "10 features found and 0 ignored\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from tf.fabric import Fabric\n",
    "from tf.convert.walker import CV\n",
    "\n",
    "TF_DIR = os.path.expanduser('~/Downloads/banks/tf')\n",
    "\n",
    "TF = Fabric(locations=TF_DIR)\n",
    "\n",
    "cv = CV(TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = '''\n",
    "\n",
    "No\n",
    "\n",
    "## 3\n",
    "Yes\n",
    "\n",
    "# Consider Phlebas\n",
    "$ author=Iain M. Banks\n",
    "\n",
    "## 1\n",
    "Everything about us,\n",
    "\n",
    "in our own terms?\n",
    "\n",
    "## 2\n",
    "Besides,\n",
    "it left\n",
    "such as\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "slotType = 'word'\n",
    "\n",
    "generic = {\n",
    "    'name': 'Culture quotes from Iain Banks',\n",
    "    'compiler': 'Dirk Roorda',\n",
    "    'source': 'Good Reads',\n",
    "    'url': 'https://www.goodreads.com/work/quotes/14366-consider-phlebas',\n",
    "}\n",
    "\n",
    "otext = {\n",
    "    'fmt:text-orig-full': '{letters}{punc} ',\n",
    "    'sectionTypes': 'book,chapter',\n",
    "    'sectionFeatures': 'title,number',\n",
    "}\n",
    "\n",
    "intFeatures = {\n",
    "  'number',\n",
    "}\n",
    "\n",
    "featureMeta = {\n",
    "    'number': {\n",
    "        'description': 'number of chapter, or sentence in chapter, or line in sentence',\n",
    "    },\n",
    "    'title': {\n",
    "        'description': 'the title of a book',\n",
    "    },\n",
    "    'author': {\n",
    "        'description': 'the author of a book',\n",
    "    },\n",
    "    'terminator': {\n",
    "        'description': 'the last character of a line',\n",
    "    },\n",
    "    'letters': {\n",
    "        'description': 'the letters of a word',\n",
    "    },\n",
    "    'punc': {\n",
    "        'description': 'the punctuation after a word',\n",
    "    },\n",
    "}\n",
    "\n",
    "def director(cv):\n",
    "  counter = dict(\n",
    "    sentence=0,\n",
    "    line=0,\n",
    "  )\n",
    "  cur = dict(\n",
    "    book=None,\n",
    "    chapter=None,\n",
    "    sentence=None,\n",
    "  )\n",
    "\n",
    "  wordRe = re.compile(r'^(.*?)([^A-Za-z0-9]*)$')\n",
    "  metaRe = re.compile(r'^\\$\\s*([^= ]+)\\s*=\\s*(.*)')\n",
    "\n",
    "  for line in source.strip().split('\\n'):\n",
    "    line = line.rstrip()\n",
    "    if not line:\n",
    "      cv.terminate(cur['sentence'])              # action\n",
    "      for ntp in counter:\n",
    "        counter[ntp] += 1\n",
    "      cur['sentence'] = cv.node('sentence')      # action\n",
    "      cv.feature(\n",
    "        cur['sentence'],\n",
    "        number=counter['sentence'],\n",
    "      )                                          # action\n",
    "      continue\n",
    "      \n",
    "    if line.startswith('# '):\n",
    "      for ntp in ('sentence', 'chapter', 'book'):\n",
    "        cv.terminate(cur[ntp])                   # action\n",
    "        cur[ntp] = None         \n",
    "      title = line[2:].strip()\n",
    "      cur['book'] = cv.node('book')              # action\n",
    "      for ntp in counter:\n",
    "        counter[ntp] = 0\n",
    "      cv.feature(\n",
    "        cur['book'],\n",
    "        title=title,\n",
    "      )                                          # action\n",
    "      continue\n",
    "\n",
    "    if line.startswith('## '):\n",
    "      for ntp in ('sentence', 'chapter'):\n",
    "        cv.terminate(cur[ntp])                   # action\n",
    "        cur[ntp] = None         \n",
    "      number = line[2:].strip()\n",
    "      cur['chapter'] = cv.node('chapter')        # action\n",
    "      for ntp in counter:\n",
    "        counter[ntp] = 0\n",
    "      cv.feature(\n",
    "        cur['chapter'],\n",
    "        number=number,\n",
    "      )                                          # action\n",
    "      continue\n",
    "\n",
    "    if line.startswith('$'):\n",
    "      match = metaRe.match(line)\n",
    "      if not match:\n",
    "        cv.stop(f'Malformed metadata line: \"{line}\"') # action\n",
    "        return\n",
    "      name = match.group(1)\n",
    "      value = match.group(2)\n",
    "      cv.feature(\n",
    "        cur['book'],\n",
    "        **{name: value},\n",
    "      )                                           # action\n",
    "      continue\n",
    "        \n",
    "    if not cur['sentence']:\n",
    "      cur['sentence'] = cv.node('sentence')       # action\n",
    "      counter['sentence'] += 1\n",
    "      cv.feature(\n",
    "        cur['sentence'],\n",
    "        number=counter['sentence'],\n",
    "      )                                           # action\n",
    "      \n",
    "    cur['line'] = cv.node('line')                 # action\n",
    "    counter['line'] += 1\n",
    "    cv.feature(\n",
    "      cur['line'],\n",
    "      terminator=line[-1],\n",
    "      number=counter['line'],\n",
    "    )                                              # action\n",
    "    \n",
    "    gap = False\n",
    "    for word in line.split():\n",
    "      if word.startswith('['):\n",
    "        gap = True\n",
    "        cv.terminate(cur['line'])   # action\n",
    "        w = cv.slot()               # action\n",
    "        cv.feature(w, gap=1)        # action\n",
    "        word = word[1:]\n",
    "      elif word.endswith(']'):\n",
    "        w = cv.slot()               # action\n",
    "        cv.resume(cur['line'])      # action\n",
    "        cv.feature(w, gap=1)        # action\n",
    "        gap = False\n",
    "        word = word[0:-1]\n",
    "      else:\n",
    "        w = cv.slot()\n",
    "        if gap:\n",
    "          cv.feature(w, gap=1)      # action\n",
    "\n",
    "      (letters, punc) = wordRe.findall(word)[0]\n",
    "      cv.feature(w, letters=letters)            # action\n",
    "      if punc:\n",
    "        cv.feature(w, punc=punc)                # action\n",
    "    cv.terminate(cur['line'])                   # action\n",
    "    curLine = None\n",
    "    \n",
    "  for ntp in ('sentence', 'chapter', 'book'):\n",
    "    cv.terminate(cur[ntp])                      # action\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Importing data from walking through the source ...\n",
      "   |     0.00s Preparing metadata... \n",
      "   |   SECTION TYPES:    book, chapter\n",
      "   |   SECTION FEATURES: title, number\n",
      "   |   TEXT    FEATURES:\n",
      "   |      |   text-orig-full       letters, punc\n",
      "   |     0.00s OK\n",
      "   |     0.00s Following director... \n",
      "   |     0.00s \"edge\" actions: 0\n",
      "   |     0.00s \"feature\" actions: 38\n",
      "   |     0.00s \"node\" actions: 20\n",
      "   |     0.00s \"resume\" actions: 0\n",
      "   |     0.00s \"slot\" actions: 14\n",
      "   |     0.01s \"terminate\" actions: 24\n",
      "   |          1 x \"book\" node \n",
      "   |          3 x \"chapter\" node \n",
      "   |          7 x \"line\" node \n",
      "   |          9 x \"sentence\" node \n",
      "   |         14 x \"word\" node  = slot type\n",
      "   |         34 nodes of all types\n",
      "   |     0.01s OK\n",
      "   |     0.00s Removing unlinked nodes ... \n",
      "   |      |    4h 28m 21s      4 unlinked \"sentence\" nodes: [2, 4, 5, 8]\n",
      "   |      |    4h 28m 21s      4 unlinked nodes\n",
      "   |      |    4h 28m 21s Leaving     30 nodes\n",
      "   |     0.00s checking for nodes and edges ... \n",
      "   |     0.00s OK\n",
      "   |     0.00s checking features ... \n",
      "   |     0.00s OK\n",
      "   |     0.00s reordering nodes ...\n",
      "   |     0.00s Sorting 1 nodes of type \"book\"\n",
      "   |     0.00s Sorting 3 nodes of type \"chapter\"\n",
      "   |     0.00s Sorting 7 nodes of type \"line\"\n",
      "   |     0.00s Sorting 5 nodes of type \"sentence\"\n",
      "   |     0.00s Max node = 30\n",
      "   |     0.00s OK\n",
      "   |     0.00s reassigning feature values ...\n",
      "   |      |    4h 28m 21s node feature \"author\" with 1 node\n",
      "   |      |    4h 28m 21s node feature \"letters\" with 14 nodes\n",
      "   |      |    4h 28m 21s node feature \"number\" with 15 nodes\n",
      "   |      |    4h 28m 21s node feature \"punc\" with 3 nodes\n",
      "   |      |    4h 28m 21s node feature \"terminator\" with 7 nodes\n",
      "   |      |    4h 28m 21s node feature \"title\" with 1 node\n",
      "   |     0.00s OK\n",
      "  0.00s Exporting 7 node and 1 edge and 1 config features to /Users/dirk/Downloads/banks/tf:\n",
      "  0.00s VALIDATING oslots feature\n",
      "  0.00s maxSlot=         14\n",
      "  0.00s maxNode=         30\n",
      "  0.00s OK: oslots is valid\n",
      "   |     0.00s T author               to /Users/dirk/Downloads/banks/tf\n",
      "   |     0.00s T letters              to /Users/dirk/Downloads/banks/tf\n",
      "   |     0.00s T number               to /Users/dirk/Downloads/banks/tf\n",
      "   |     0.00s T otype                to /Users/dirk/Downloads/banks/tf\n",
      "   |     0.00s T punc                 to /Users/dirk/Downloads/banks/tf\n",
      "   |     0.00s T terminator           to /Users/dirk/Downloads/banks/tf\n",
      "   |     0.00s T title                to /Users/dirk/Downloads/banks/tf\n",
      "   |     0.00s T oslots               to /Users/dirk/Downloads/banks/tf\n",
      "   |     0.00s M otext                to /Users/dirk/Downloads/banks/tf\n",
      "  0.03s Exported 7 node features and 1 edge features and 1 config features to /Users/dirk/Downloads/banks/tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.03s WARNING slot outside sections (1 x):\n",
      "   |      |   1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   |      |    4h 28m 21s use `cv.walk(..., warn=False)` to continue after warnings\n",
      "   |      |    4h 28m 21s use `cv.walk(..., warn=None)` to suppress warnings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good = cv.walk(\n",
    "    director,\n",
    "    slotType,\n",
    "    otext=otext,\n",
    "    generic=generic,\n",
    "    intFeatures=intFeatures,\n",
    "    featureMeta=featureMeta,\n",
    "    warn=True,\n",
    ")\n",
    "\n",
    "good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 7.4.3\n",
      "Api reference : https://annotation.github.io/text-fabric/Api/Fabric/\n",
      "\n",
      "10 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.00s T otype                from /Users/dirk/Downloads/banks/tf\n",
      "   |     0.00s T oslots               from /Users/dirk/Downloads/banks/tf\n",
      "   |     0.00s T title                from /Users/dirk/Downloads/banks/tf\n",
      "   |     0.00s T number               from /Users/dirk/Downloads/banks/tf\n",
      "   |     0.00s T letters              from /Users/dirk/Downloads/banks/tf\n",
      "   |     0.00s T punc                 from /Users/dirk/Downloads/banks/tf\n",
      "   |      |     0.00s C __levels__           from otype, oslots, otext\n",
      "   |      |     0.00s C __order__            from otype, oslots, __levels__\n",
      "   |      |     0.00s C __rank__             from otype, __order__\n",
      "   |      |     0.00s C __levUp__            from otype, oslots, __levels__, __rank__\n",
      "   |      |     0.00s C __levDown__          from otype, __levUp__, __rank__\n",
      "   |      |     0.00s C __boundary__         from otype, oslots, __rank__\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   |      |     0.00s c __sections__         WARNING:    1 x section chapter without containing book\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   |      |     0.00s C __sections__         from otype, oslots, otext, __levUp__, __levels__, title, number\n",
      "   |     0.00s T author               from /Users/dirk/Downloads/banks/tf\n",
      "   |     0.00s T gap                  from /Users/dirk/Downloads/banks/tf\n",
      "   |     0.00s T terminator           from /Users/dirk/Downloads/banks/tf\n",
      "  0.04s All features loaded/computed - for details use loadLog()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Computed',\n",
       "  'computed-data',\n",
       "  ('C Computed', 'Call AllComputeds', 'Cs ComputedString')),\n",
       " ('Features', 'edge-features', ('E Edge', 'Eall AllEdges', 'Es EdgeString')),\n",
       " ('Fabric', 'loading', ('ensureLoaded', 'TF', 'ignored', 'loadLog')),\n",
       " ('Locality', 'locality', ('L Locality',)),\n",
       " ('Misc', 'messaging', ('cache', 'error', 'indent', 'info', 'reset')),\n",
       " ('Nodes',\n",
       "  'navigating-nodes',\n",
       "  ('N Nodes', 'sortKey', 'sortKeyTuple', 'otypeRank', 'sortNodes')),\n",
       " ('Features',\n",
       "  'node-features',\n",
       "  ('F Feature', 'Fall AllFeatures', 'Fs FeatureString')),\n",
       " ('Search', 'search', ('S Search',)),\n",
       " ('Text', 'text', ('T Text',))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TF = Fabric(locations=TF_DIR)\n",
    "\n",
    "allFeatures = TF.explore(silent=True, show=True)\n",
    "loadableFeatures = allFeatures['nodes'] + allFeatures['edges']\n",
    "loadableFeatures\n",
    "\n",
    "api = TF.load(loadableFeatures, silent=False)\n",
    "\n",
    "api.makeAvailableIn(globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF.clearCache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### otype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@node\n",
      "@compiler=Dirk Roorda\n",
      "@name=Culture quotes from Iain Banks\n",
      "@source=Good Reads\n",
      "@url=https://www.goodreads.com/work/quotes/14366-consider-phlebas\n",
      "@valueType=str\n",
      "@writtenBy=Text-Fabric\n",
      "@dateWritten=2019-01-30T15:30:24Z\n",
      "\n",
      "1-100\tword\n",
      "101\tbook\n",
      "102-104\tchapter\n",
      "105-117\tline\n",
      "118-121\tsentence\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(f'{TF_DIR}/otype.tf') as fh:\n",
    "  print(fh.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### otext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@config\n",
      "@compiler=Dirk Roorda\n",
      "@fmt:text-orig-full={letters}{punc} \n",
      "@name=Culture quotes from Iain Banks\n",
      "@sectionFeatures=title,number\n",
      "@sectionTypes=book,chapter\n",
      "@source=Good Reads\n",
      "@url=https://www.goodreads.com/work/quotes/14366-consider-phlebas\n",
      "@writtenBy=Text-Fabric\n",
      "@dateWritten=2019-01-30T15:30:24Z\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(f'{TF_DIR}/otext.tf') as fh:\n",
    "  print(fh.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### oslots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@edge\n",
      "@compiler=Dirk Roorda\n",
      "@name=Culture quotes from Iain Banks\n",
      "@source=Good Reads\n",
      "@url=https://www.goodreads.com/work/quotes/14366-consider-phlebas\n",
      "@valueType=str\n",
      "@writtenBy=Text-Fabric\n",
      "@dateWritten=2019-01-30T15:30:24Z\n",
      "\n",
      "101\t2-100\n",
      "1\n",
      "2-56\n",
      "57-100\n",
      "1\n",
      "2-4\n",
      "5-7\n",
      "8-10,15-21\n",
      "22-28\n",
      "29-39\n",
      "40-52\n",
      "53-56\n",
      "57\n",
      "58-76\n",
      "77-78,82-84\n",
      "85-89\n",
      "90-100\n",
      "1\n",
      "2-28\n",
      "29-56\n",
      "57-100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(f'{TF_DIR}/oslots.tf') as fh:\n",
    "  print(fh.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('the', 8),\n",
       " ('of', 5),\n",
       " ('and', 4),\n",
       " ('in', 3),\n",
       " ('we', 3),\n",
       " ('everything', 2),\n",
       " ('know', 2),\n",
       " ('most', 2),\n",
       " ('ones', 2),\n",
       " ('patterns', 2),\n",
       " ('us', 2),\n",
       " ('Besides', 1),\n",
       " ('Culture', 1),\n",
       " ('Everything', 1),\n",
       " ('So', 1),\n",
       " ('a', 1),\n",
       " ('about', 1),\n",
       " ('aid', 1),\n",
       " ('any', 1),\n",
       " ('around', 1),\n",
       " ('as', 1),\n",
       " ('barbarian', 1),\n",
       " ('bottom', 1),\n",
       " ('can', 1),\n",
       " ('care', 1),\n",
       " ('climbing', 1),\n",
       " ('composed', 1),\n",
       " ('control', 1),\n",
       " ('dead', 1),\n",
       " ('elegant', 1),\n",
       " ('enjoyable', 1),\n",
       " ('final', 1),\n",
       " ('find', 1),\n",
       " ('free', 1),\n",
       " ('games', 1),\n",
       " ('good', 1),\n",
       " ('harness', 1),\n",
       " ('have', 1),\n",
       " ('high', 1),\n",
       " ('humans', 1),\n",
       " ('impossible', 1),\n",
       " ('is', 1),\n",
       " ('it', 1),\n",
       " ('languages', 1),\n",
       " ('left', 1),\n",
       " ('life', 1),\n",
       " ('line', 1),\n",
       " ('make', 1),\n",
       " ('mattered', 1),\n",
       " ('mountains', 1),\n",
       " ('not', 1),\n",
       " ('nothing', 1),\n",
       " ('our', 1),\n",
       " ('over', 1),\n",
       " ('own', 1),\n",
       " ('problems', 1),\n",
       " ('really', 1),\n",
       " ('romance', 1),\n",
       " ('safety', 1),\n",
       " ('societies', 1),\n",
       " ('sports', 1),\n",
       " ('studying', 1),\n",
       " ('such', 1),\n",
       " ('take', 1),\n",
       " ('terms', 1),\n",
       " ('that', 1),\n",
       " ('thatâ€™s', 1),\n",
       " ('things', 1),\n",
       " ('those', 1),\n",
       " ('to', 1),\n",
       " ('truth', 1),\n",
       " ('ultimately', 1),\n",
       " ('where', 1),\n",
       " ('why', 1),\n",
       " ('without', 1))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.letters.freqList()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
