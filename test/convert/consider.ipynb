{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T10:40:34.922214Z",
     "start_time": "2018-10-18T10:40:34.901689Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 7.5.4\n",
      "Api reference : https://annotation.github.io/text-fabric/Api/Fabric/\n",
      "\n",
      "0 features found and 0 ignored\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s Warp feature \"otype\" not found in\n",
      "/Users/dirk/github/annotation/text-fabric/test/convert/banks/tf/\n",
      "  0.00s Warp feature \"oslots\" not found in\n",
      "/Users/dirk/github/annotation/text-fabric/test/convert/banks/tf/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Warp feature \"otext\" not found. Working without Text-API\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from tf.fabric import Fabric\n",
    "from tf.convert.walker import CV\n",
    "\n",
    "TF_DIR = os.path.expanduser('~/github/annotation/text-fabric/test/convert/banks/tf')\n",
    "\n",
    "TF = Fabric(locations=TF_DIR)\n",
    "\n",
    "cv = CV(TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = '''\n",
    "# Consider Phlebas\n",
    "$ author=Iain M. Banks\n",
    "\n",
    "## 1\n",
    "Everything about us,\n",
    "everything around us,\n",
    "everything we know [and can know of] is composed ultimately of patterns of nothing;\n",
    "that’s the bottom line, the final truth.\n",
    "\n",
    "So where we find we have any control over those patterns,\n",
    "why not make the most elegant ones, the most enjoyable and good ones,\n",
    "in our own terms?\n",
    "\n",
    "## 2\n",
    "Besides,\n",
    "it left the humans in the Culture free to take care of the things that really mattered in life,\n",
    "such as [sports, games, romance,] studying dead languages,\n",
    "barbarian societies and impossible problems,\n",
    "and climbing high mountains without the aid of a safety harness.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "slotType = 'word'\n",
    "\n",
    "generic = {\n",
    "    'name': 'Culture quotes from Iain Banks',\n",
    "    'compiler': 'Dirk Roorda',\n",
    "    'source': 'Good Reads',\n",
    "    'url': 'https://www.goodreads.com/work/quotes/14366-consider-phlebas',\n",
    "}\n",
    "\n",
    "otext = {\n",
    "    'fmt:text-orig-full': '{letters}{punc} ',\n",
    "    'sectionTypes': 'book,chapter',\n",
    "    'sectionFeatures': 'title,number',\n",
    "}\n",
    "\n",
    "intFeatures = {\n",
    "  'gap',\n",
    "  'number',\n",
    "}\n",
    "\n",
    "featureMeta = {\n",
    "    'number': {\n",
    "        'description': 'number of chapter, or sentence in chapter, or line in sentence',\n",
    "    },\n",
    "    'gap': {\n",
    "        'description': '1 for words that occur between [ ]',\n",
    "    },\n",
    "    'title': {\n",
    "        'description': 'the title of a book',\n",
    "    },\n",
    "    'author': {\n",
    "        'description': 'the author of a book',\n",
    "    },\n",
    "    'terminator': {\n",
    "        'description': 'the last character of a line',\n",
    "    },\n",
    "    'letters': {\n",
    "        'description': 'the letters of a word',\n",
    "    },\n",
    "    'punc': {\n",
    "        'description': 'the punctuation after a word',\n",
    "    },\n",
    "}\n",
    "\n",
    "def director(cv):\n",
    "  counter = dict(\n",
    "    sentence=0,\n",
    "    line=0,\n",
    "  )\n",
    "  cur = dict(\n",
    "    book=None,\n",
    "    chapter=None,\n",
    "    sentence=None,\n",
    "  )\n",
    "\n",
    "  wordRe = re.compile(r'^(.*?)([^A-Za-z0-9]*)$')\n",
    "  metaRe = re.compile(r'^\\$\\s*([^= ]+)\\s*=\\s*(.*)')\n",
    "\n",
    "  for line in source.strip().split('\\n'):\n",
    "    line = line.rstrip()\n",
    "    if not line:\n",
    "      cv.terminate(cur['sentence'])              # action\n",
    "      for ntp in counter:\n",
    "        counter[ntp] += 1\n",
    "      cur['sentence'] = cv.node('sentence')      # action\n",
    "      cv.feature(\n",
    "        cur['sentence'],\n",
    "        number=counter['sentence'],\n",
    "      )                                          # action\n",
    "      continue\n",
    "      \n",
    "    if line.startswith('# '):\n",
    "      for ntp in ('sentence', 'chapter', 'book'):\n",
    "        cv.terminate(cur[ntp])                   # action\n",
    "        cur[ntp] = None         \n",
    "      title = line[2:].strip()\n",
    "      cur['book'] = cv.node('book')              # action\n",
    "      for ntp in counter:\n",
    "        counter[ntp] = 0\n",
    "      cv.feature(\n",
    "        cur['book'],\n",
    "        title=title,\n",
    "      )                                          # action\n",
    "      continue\n",
    "\n",
    "    if line.startswith('## '):\n",
    "      for ntp in ('sentence', 'chapter'):\n",
    "        cv.terminate(cur[ntp])                   # action\n",
    "        cur[ntp] = None         \n",
    "      number = line[2:].strip()\n",
    "      cur['chapter'] = cv.node('chapter')        # action\n",
    "      for ntp in counter:\n",
    "        counter[ntp] = 0\n",
    "      cv.feature(\n",
    "        cur['chapter'],\n",
    "        number=number,\n",
    "      )                                          # action\n",
    "      continue\n",
    "\n",
    "    if line.startswith('$'):\n",
    "      match = metaRe.match(line)\n",
    "      if not match:\n",
    "        cv.stop(f'Malformed metadata line: \"{line}\"') # action\n",
    "        return\n",
    "      name = match.group(1)\n",
    "      value = match.group(2)\n",
    "      cv.feature(\n",
    "        cur['book'],\n",
    "        **{name: value},\n",
    "      )                                           # action\n",
    "      continue\n",
    "        \n",
    "    if not cur['sentence']:\n",
    "      cur['sentence'] = cv.node('sentence')       # action\n",
    "      counter['sentence'] += 1\n",
    "      cv.feature(\n",
    "        cur['sentence'],\n",
    "        number=counter['sentence'],\n",
    "      )                                           # action\n",
    "      \n",
    "    cur['line'] = cv.node('line')                 # action\n",
    "    counter['line'] += 1\n",
    "    cv.feature(\n",
    "      cur['line'],\n",
    "      terminator=line[-1],\n",
    "      number=counter['line'],\n",
    "    )                                              # action\n",
    "    \n",
    "    gap = False\n",
    "    for word in line.split():\n",
    "      if word.startswith('['):\n",
    "        gap = True\n",
    "        cv.terminate(cur['line'])   # action\n",
    "        w = cv.slot()               # action\n",
    "        cv.feature(w, gap=1)        # action\n",
    "        word = word[1:]\n",
    "      elif word.endswith(']'):\n",
    "        w = cv.slot()               # action\n",
    "        cv.resume(cur['line'])      # action\n",
    "        cv.feature(w, gap=1)        # action\n",
    "        gap = False\n",
    "        word = word[0:-1]\n",
    "      else:\n",
    "        w = cv.slot()\n",
    "        if gap:\n",
    "          cv.feature(w, gap=1)      # action\n",
    "\n",
    "      (letters, punc) = wordRe.findall(word)[0]\n",
    "      cv.feature(w, letters=letters)            # action\n",
    "      if punc:\n",
    "        cv.feature(w, punc=punc)                # action\n",
    "    cv.terminate(cur['line'])                   # action\n",
    "    curLine = None\n",
    "    \n",
    "  for ntp in ('sentence', 'chapter', 'book'):\n",
    "    cv.terminate(cur[ntp])                      # action\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Importing data from walking through the source ...\n",
      "   |     0.00s Preparing metadata... \n",
      "   |   SECTION TYPES:    book, chapter\n",
      "   |   SECTION FEATURES: title, number\n",
      "   |   TEXT    FEATURES:\n",
      "   |      |   text-orig-full       letters, punc\n",
      "   |     0.00s OK\n",
      "   |     0.00s Following director... \n",
      "   |     0.00s \"edge\" actions: 0\n",
      "   |     0.00s \"feature\" actions: 144\n",
      "   |     0.00s \"node\" actions: 20\n",
      "   |     0.00s \"resume\" actions: 2\n",
      "   |     0.00s \"slot\" actions: 99\n",
      "   |     0.00s \"terminate\" actions: 27\n",
      "   |          1 x \"book\" node \n",
      "   |          2 x \"chapter\" node \n",
      "   |         12 x \"line\" node \n",
      "   |          5 x \"sentence\" node \n",
      "   |         99 x \"word\" node  = slot type\n",
      "   |        119 nodes of all types\n",
      "   |     0.01s OK\n",
      "   |     0.00s Removing unlinked nodes ... \n",
      "   |      |   10m 23s      2 unlinked \"sentence\" nodes: [1, 4]\n",
      "   |      |   10m 23s      2 unlinked nodes\n",
      "   |      |   10m 23s Leaving    117 nodes\n",
      "   |     0.00s checking for nodes and edges ... \n",
      "   |     0.00s OK\n",
      "   |     0.00s checking features ... \n",
      "   |     0.00s OK\n",
      "   |     0.00s reordering nodes ...\n",
      "   |     0.00s Sorting 1 nodes of type \"book\"\n",
      "   |     0.00s Sorting 2 nodes of type \"chapter\"\n",
      "   |     0.00s Sorting 12 nodes of type \"line\"\n",
      "   |     0.00s Sorting 3 nodes of type \"sentence\"\n",
      "   |     0.00s Max node = 117\n",
      "   |     0.00s OK\n",
      "   |     0.00s reassigning feature values ...\n",
      "   |      |   10m 23s node feature \"author\" with 1 node\n",
      "   |      |   10m 23s node feature \"gap\" with 7 nodes\n",
      "   |      |   10m 23s node feature \"letters\" with 99 nodes\n",
      "   |      |   10m 23s node feature \"number\" with 17 nodes\n",
      "   |      |   10m 23s node feature \"punc\" with 17 nodes\n",
      "   |      |   10m 23s node feature \"terminator\" with 12 nodes\n",
      "   |      |   10m 23s node feature \"title\" with 1 node\n",
      "   |     0.01s OK\n",
      "  0.00s Exporting 8 node and 1 edge and 1 config features to /Users/dirk/github/annotation/text-fabric/test/convert/banks/tf:\n",
      "  0.00s VALIDATING oslots feature\n",
      "  0.00s maxSlot=         99\n",
      "  0.00s maxNode=        117\n",
      "  0.00s OK: oslots is valid\n",
      "   |     0.00s T author               to /Users/dirk/github/annotation/text-fabric/test/convert/banks/tf\n",
      "   |     0.00s T gap                  to /Users/dirk/github/annotation/text-fabric/test/convert/banks/tf\n",
      "   |     0.00s T letters              to /Users/dirk/github/annotation/text-fabric/test/convert/banks/tf\n",
      "   |     0.00s T number               to /Users/dirk/github/annotation/text-fabric/test/convert/banks/tf\n",
      "   |     0.00s T otype                to /Users/dirk/github/annotation/text-fabric/test/convert/banks/tf\n",
      "   |     0.00s T punc                 to /Users/dirk/github/annotation/text-fabric/test/convert/banks/tf\n",
      "   |     0.00s T terminator           to /Users/dirk/github/annotation/text-fabric/test/convert/banks/tf\n",
      "   |     0.00s T title                to /Users/dirk/github/annotation/text-fabric/test/convert/banks/tf\n",
      "   |     0.00s T oslots               to /Users/dirk/github/annotation/text-fabric/test/convert/banks/tf\n",
      "   |     0.00s M otext                to /Users/dirk/github/annotation/text-fabric/test/convert/banks/tf\n",
      "  0.03s Exported 8 node features and 1 edge features and 1 config features to /Users/dirk/github/annotation/text-fabric/test/convert/banks/tf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good = cv.walk(\n",
    "    director,\n",
    "    slotType,\n",
    "    otext=otext,\n",
    "    generic=generic,\n",
    "    intFeatures=intFeatures,\n",
    "    featureMeta=featureMeta,\n",
    "    warn=True,\n",
    ")\n",
    "\n",
    "good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 7.5.4\n",
      "Api reference : https://annotation.github.io/text-fabric/Api/Fabric/\n",
      "\n",
      "10 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.00s T otype                from /Users/dirk/github/annotation/text-fabric/test/convert/banks/tf\n",
      "   |     0.00s T oslots               from /Users/dirk/github/annotation/text-fabric/test/convert/banks/tf\n",
      "   |     0.00s T title                from /Users/dirk/github/annotation/text-fabric/test/convert/banks/tf\n",
      "   |     0.00s T number               from /Users/dirk/github/annotation/text-fabric/test/convert/banks/tf\n",
      "   |     0.00s T letters              from /Users/dirk/github/annotation/text-fabric/test/convert/banks/tf\n",
      "   |     0.00s T punc                 from /Users/dirk/github/annotation/text-fabric/test/convert/banks/tf\n",
      "   |      |     0.00s C __levels__           from otype, oslots, otext\n",
      "   |      |     0.00s C __order__            from otype, oslots, __levels__\n",
      "   |      |     0.00s C __rank__             from otype, __order__\n",
      "   |      |     0.00s C __levUp__            from otype, oslots, __levels__, __rank__\n",
      "   |      |     0.00s C __levDown__          from otype, __levUp__, __rank__\n",
      "   |      |     0.00s C __boundary__         from otype, oslots, __rank__\n",
      "   |      |     0.00s C __sections__         from otype, oslots, otext, __levUp__, __levels__, title, number\n",
      "   |     0.00s T author               from /Users/dirk/github/annotation/text-fabric/test/convert/banks/tf\n",
      "   |     0.00s T gap                  from /Users/dirk/github/annotation/text-fabric/test/convert/banks/tf\n",
      "   |     0.00s T terminator           from /Users/dirk/github/annotation/text-fabric/test/convert/banks/tf\n",
      "  0.04s All features loaded/computed - for details use loadLog()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Computed',\n",
       "  'computed-data',\n",
       "  ('C Computed', 'Call AllComputeds', 'Cs ComputedString')),\n",
       " ('Features', 'edge-features', ('E Edge', 'Eall AllEdges', 'Es EdgeString')),\n",
       " ('Fabric', 'loading', ('ensureLoaded', 'TF', 'ignored', 'loadLog')),\n",
       " ('Locality', 'locality', ('L Locality',)),\n",
       " ('Misc', 'messaging', ('cache', 'error', 'indent', 'info', 'reset')),\n",
       " ('Nodes',\n",
       "  'navigating-nodes',\n",
       "  ('N Nodes', 'sortKey', 'sortKeyTuple', 'otypeRank', 'sortNodes')),\n",
       " ('Features',\n",
       "  'node-features',\n",
       "  ('F Feature', 'Fall AllFeatures', 'Fs FeatureString')),\n",
       " ('Search', 'search', ('S Search',)),\n",
       " ('Text', 'text', ('T Text',))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TF = Fabric(locations=TF_DIR)\n",
    "\n",
    "allFeatures = TF.explore(silent=True, show=True)\n",
    "loadableFeatures = allFeatures['nodes'] + allFeatures['edges']\n",
    "loadableFeatures\n",
    "\n",
    "api = TF.load(loadableFeatures, silent=False)\n",
    "\n",
    "api.makeAvailableIn(globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF.clearCache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### otype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@node\n",
      "@compiler=Dirk Roorda\n",
      "@name=Culture quotes from Iain Banks\n",
      "@source=Good Reads\n",
      "@url=https://www.goodreads.com/work/quotes/14366-consider-phlebas\n",
      "@valueType=str\n",
      "@writtenBy=Text-Fabric\n",
      "@dateWritten=2019-04-04T18:04:16Z\n",
      "\n",
      "1-99\tword\n",
      "100\tbook\n",
      "101-102\tchapter\n",
      "103-114\tline\n",
      "115-117\tsentence\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(f'{TF_DIR}/otype.tf') as fh:\n",
    "  print(fh.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### otext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@config\n",
      "@compiler=Dirk Roorda\n",
      "@fmt:text-orig-full={letters}{punc} \n",
      "@name=Culture quotes from Iain Banks\n",
      "@sectionFeatures=title,number\n",
      "@sectionTypes=book,chapter\n",
      "@source=Good Reads\n",
      "@url=https://www.goodreads.com/work/quotes/14366-consider-phlebas\n",
      "@writtenBy=Text-Fabric\n",
      "@dateWritten=2019-04-04T18:04:16Z\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(f'{TF_DIR}/otext.tf') as fh:\n",
    "  print(fh.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### oslots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@edge\n",
      "@compiler=Dirk Roorda\n",
      "@name=Culture quotes from Iain Banks\n",
      "@source=Good Reads\n",
      "@url=https://www.goodreads.com/work/quotes/14366-consider-phlebas\n",
      "@valueType=str\n",
      "@writtenBy=Text-Fabric\n",
      "@dateWritten=2019-04-04T18:04:16Z\n",
      "\n",
      "100\t1-99\n",
      "1-55\n",
      "56-99\n",
      "1-3\n",
      "4-6\n",
      "7-9,14-20\n",
      "21-27\n",
      "28-38\n",
      "39-51\n",
      "52-55\n",
      "56\n",
      "57-75\n",
      "76-77,81-83\n",
      "84-88\n",
      "89-99\n",
      "1-27\n",
      "28-55\n",
      "56-99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(f'{TF_DIR}/oslots.tf') as fh:\n",
    "  print(fh.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('the', 8),\n",
       " ('of', 5),\n",
       " ('and', 4),\n",
       " ('in', 3),\n",
       " ('we', 3),\n",
       " ('everything', 2),\n",
       " ('know', 2),\n",
       " ('most', 2),\n",
       " ('ones', 2),\n",
       " ('patterns', 2),\n",
       " ('us', 2),\n",
       " ('Besides', 1),\n",
       " ('Culture', 1),\n",
       " ('Everything', 1),\n",
       " ('So', 1),\n",
       " ('a', 1),\n",
       " ('about', 1),\n",
       " ('aid', 1),\n",
       " ('any', 1),\n",
       " ('around', 1),\n",
       " ('as', 1),\n",
       " ('barbarian', 1),\n",
       " ('bottom', 1),\n",
       " ('can', 1),\n",
       " ('care', 1),\n",
       " ('climbing', 1),\n",
       " ('composed', 1),\n",
       " ('control', 1),\n",
       " ('dead', 1),\n",
       " ('elegant', 1),\n",
       " ('enjoyable', 1),\n",
       " ('final', 1),\n",
       " ('find', 1),\n",
       " ('free', 1),\n",
       " ('games', 1),\n",
       " ('good', 1),\n",
       " ('harness', 1),\n",
       " ('have', 1),\n",
       " ('high', 1),\n",
       " ('humans', 1),\n",
       " ('impossible', 1),\n",
       " ('is', 1),\n",
       " ('it', 1),\n",
       " ('languages', 1),\n",
       " ('left', 1),\n",
       " ('life', 1),\n",
       " ('line', 1),\n",
       " ('make', 1),\n",
       " ('mattered', 1),\n",
       " ('mountains', 1),\n",
       " ('not', 1),\n",
       " ('nothing', 1),\n",
       " ('our', 1),\n",
       " ('over', 1),\n",
       " ('own', 1),\n",
       " ('problems', 1),\n",
       " ('really', 1),\n",
       " ('romance', 1),\n",
       " ('safety', 1),\n",
       " ('societies', 1),\n",
       " ('sports', 1),\n",
       " ('studying', 1),\n",
       " ('such', 1),\n",
       " ('take', 1),\n",
       " ('terms', 1),\n",
       " ('that', 1),\n",
       " ('that’s', 1),\n",
       " ('things', 1),\n",
       " ('those', 1),\n",
       " ('to', 1),\n",
       " ('truth', 1),\n",
       " ('ultimately', 1),\n",
       " ('where', 1),\n",
       " ('why', 1),\n",
       " ('without', 1))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.letters.freqList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
