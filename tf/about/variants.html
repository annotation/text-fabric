<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.11.1" />
<title>tf.about.variants API documentation</title>
<meta name="description" content="Sentence boundaries in textual variants â€¦" />
<!-- integrity SRI from https://cdnjs.com/libraries/10up-sanitize.css/11.0.1 -->
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css"
integrity="sha512-kcbluZFacWN57NgWZ4aH6eUMBEaTyErFhIFD3y5qYZbKuuyImH0K/AKsBbfXlivh2z5C+3IDTIhI11YmKomzmA=="
crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css"
integrity="sha512-uVeAgzAmieLUTGba0qr9vXQgVD7fko2kcbYIKIraXUIDg9iJLxveTFUrg3DJhqn3cAf3HFDbgmhq0eGko5wEAA=="
crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>tf.about.variants</code></h1>
</header>
<section id="section-intro">
<h1 id="sentence-boundaries-in-textual-variants">Sentence boundaries in textual variants</h1>
<p>The TEI guidelines describe an element <code>&lt;app&gt;</code> for the encoding of textual variants. For a short overview see the
<a href="https://www.tei-c.org/release/doc/tei-p5-doc/en/html/examples-lem.html#TC">Critical Apparatus Module</a>.
This module is for dealing with a corpus encoded in TEI with <code>app</code>-, <code>lem</code>-, and
<code>rdg</code>-elements. Especially when you want to turn material between boundaries into
nodes. Think of sentences. If sentence boundaries are present, either
implicitly as full stops, or explicitly as milestones or processing
instructions, this module helps you to generate nodes for the material between
the boundaries, even in the presence of textual variants. It solves the problem
that arises when sentence boundaries are different in different variants.
The solution is to wrap sentences that are partly subject to variation into
sentence nodes that are specific to each witness.
When we try to do this in XML, the problem becomes utterly hard. However, in
the TF context there is no obligation to put the sentences in a single
tree hierarchy.
We have to make sentence nodes such that:</p>
<ul>
<li>all textual material in all variants is properly assigned to sentence nodes;</li>
<li>for each witness, the text is neatly contained in sentences; each such sentence;
is either a base sentence when the witness agrees completely with the base text
is a witness dependent sentence if part of it disagrees with the base text;</li>
<li>sentences are economical: we want as few variant-dependent sentence nodes as possible.</li>
</ul>
<p>We describe how to use this module in the context of a <code><a title="tf.convert.walker" href="../convert/walker.html">tf.convert.walker</a></code>
conversion. After that we will explain in detail what problem it solves, what
the result looks like, and how the algorithm performs it steps.</p>
<h1 id="usage">Usage</h1>
<p>This module is to be used in the context of a <code><a title="tf.convert.walker" href="../convert/walker.html">tf.convert.walker</a></code> conversion.
It can be imported as</p>
<pre><code class="language-python">from tf.convert.variants import Variants
</code></pre>
<p>It should be initialized in the <code>director()</code> function. It needs a storage
dictionary in which it stores relevant information. Typically this dict is
called <code>cur</code> and it should be initialized before:</p>
<pre><code class="language-python">def director(cv):
    cur = {}
    variants = Variants(
        cv,
        cur,
        BASE_WITNESS,
        SENTENCE,
        addWarning,
        addError,
    )
</code></pre>
<p>The node type of the "sentence" nodes can be customised, so you can use this
module to insert any kind of node based on their boundary information. The name
of the base text can also be customised. Usually it is <code>base</code>, but if one of
the witnesses is also called <code>base</code>, you should pass another name.
For more information, see <code>tf.convert.variants.Variants</code>.</p>
<h1 id="explanation">Explanation</h1>
<p>First we sketch what the result will look like, then we describe the algorithm
to achieve that result, and finally we explain how you can invoke the Python
module that implements the algorithm.</p>
<h2 id="the-app-element">The app element</h2>
<p>The <code>&lt;app&gt;</code> element with its subelements <code>&lt;lem&gt;</code> and <code>&lt;rdg&gt;</code> describe textual variants.</p>
<pre><code class="language-xml">base text (all witnesses)  
&lt;app&gt;  
Â  Â Â &lt;lem&gt;  
Â  Â  Â  Â Â base text (not in a b c d)  
Â  Â  Â  Â Â &lt;app&gt;  
Â  Â  Â  Â  Â  Â Â &lt;lem&gt;base text (not in a b c d e f g h)&lt;/lem&gt;  
Â  Â  Â  Â  Â  Â Â &lt;rdg wit=&quot;e f&quot;&gt;variant text (in e f)&lt;/rdg&gt;  
Â  Â  Â  Â  Â  Â Â &lt;rdg wit=&quot;g h&quot;&gt;variant text (in g h)&lt;/rdg&gt;  
Â  Â  Â  Â Â &lt;/app&gt;  
Â  Â  Â  Â Â base text (not in a b c d)
Â  Â Â &lt;/lem&gt;  
Â  Â Â &lt;rdg wit=&quot;a b&quot;&gt;variant text (in a b)&lt;/rdg&gt;  
Â  Â Â &lt;rdg wit=&quot;c d&quot;&gt;variant text (in c d)&lt;/rdg&gt;  
&lt;/app&gt;
base text (all witnesses)
</code></pre>
<p>It is assumed that text outside any <code>app</code>-element is the base text, as well as
the content of the <code>lem</code>-elements. The material in the <code>rdg</code>-elements (reading
groups) are variants on their sister <code>lem</code>-element.
Each reading group specifies in its <code>wit=</code> attribute which witnesses contain
that variant. The base text in the <code>lem</code>-element is witnessed by all witnesses,
except those that are mentioned in its sister <code>rdg</code> elements.
<code>lem</code>-elements can contain <code>app</code>-elements in turn. That means that a part of
the outer <code>lem</code>-element is itself subject to additional variation, contained in the
inner <code>rdg</code> elements. The base text in the inner <code>lem</code> element is witnessed by all
witnesses, except those mentioned in its sister <code>rdg</code>-elements, and in its <em>aunt</em>
<code>rdg</code>-elements (and great-(great-) aunt elements, &hellip;). See the following
picture.
<img alt="" src="../images/variants/app.png"></p>
<p>In the sequel we will use pictures like this a lot, so here are some points to remember:
*
a coloured area represent an app element its top black bar is the content
of the <code>lem</code>-element
*
which may be partly contained in the <code>lem</code>-element of a nested app element
the grey bars below are the content of the <code>rdg</code>-elements
*
the black bars represent the base text;
*
labels start with <code>-</code> and indicate the witnesses that do <em>not</em> support
the base text;
*
the grey bars represent the variant texts;
labels indicate the witnesses that support the variant in question
*
the numbers represent textual positions (slots), in the order in which they
occur in the source file. This is also the reading order of the base text
if you skip the variants
*
and it is the reading order of each witness, if you follow the base text
except for <code>app</code>-elements that have an <code>rdg</code> with this witness in its wit
attribute.</p>
<h2 id="from-boundaries-to-nodes">From boundaries to nodes</h2>
<p>Suppose you want to encode sentences. You could start by marking sentence
boundaries at every <code>.</code> that has the function of full stop.
We do not deal with the non-trivial problem of detecting sentence boundaries
here. They might have been assigned by hand and encoded as milestones or
processing instructions, or they might have been found by applying some
heuristic guidelines of more or lesser quality.
We assume that all sentence boundaries have been found.</p>
<h2 id="the-problem">The problem</h2>
<p>The problem arises when we want to define sentence nodes based on the sentence
boundaries. Because a sentence can start in the base text, and end in different
variants in different ways. Or a sentence that ends in the base text may have
started in different ways in different variants. Or any combination of these
phenomena may occur.
When that happens, we want to generate multiple nodes for the sentence , one
for each witness. But we do not want to duplicate the words in those sentences.</p>
<p>Here is a diagram that shows the problem in its generic complexity.
<img alt="" src="../images/variants/problem.png"></p>
<p>We see nested app elements with intricate variations. Here is what to look for:
*
there is an unequal number of sentence boundaries between the base text and
its variants; this happens in the outer app and in each of the two inner apps
*
the variants are divided over sets of witnesses in each app, but the two
inner apps have incompatible sets of witnesses in their variants: the first
one has a variant for witnesses <code>a</code> and <code>b</code>, while the second one has a
variant for witnesses <code>b</code> and <code>c</code>
*
there is <em>no</em> sentence boundary between the two inner apps. So unfinished
sentences from the left inner app continue through the base text to the right
inner app, where they may or may not be terminated in either the base text or
in a variant
*
look at variant <code>g</code>:
*
it shows up in the left inner app, where it continues the sentence
started in the base text at slot <code>5</code>
in the left inner app, the variant is also witnessed by <code>f</code>
*
it is not finished in the left inner app but continues through the base
text in slots <code>28-33</code>
*
then it enters the right inner app, in a variant that is no longer
witnessed by <code>f</code>, but by <code>h</code> instead
*
it is not finished in the right inner app, but continues through the base
text from slot <code>53</code> till <code>55</code>, where it is terminated.
*
All in all, this particular sentence in <code>g</code> has the slots <code>5-7, 22-27, 28-33, 47-52, 53-55</code>
*
look at the sentence in variant <code>f</code>:
like the one in <code>g</code> it has the piece <code>5-7</code> in the base text
and also the piece <code>22-27</code> in a variant shared with <code>g</code>
from where it continues with <code>28-33</code> in the base text
*
but in the right inner app there is no variant for witness <code>f</code>, so here
<code>f</code> follows the base text, which terminates the sentence at the end of
piece <code>34-35</code>.</p>
<p>Hopefully, this builds some intuition how sentences run through witnesses.</p>
<h2 id="the-resulting-nodes">The resulting nodes</h2>
<p>When we follow the reasoning above for all sentences and witnesses, we get this
end result. You see all slots in the text, organized by witness. Each
horizontal row represent a witness, the top row represents the base text. Not
all slots belong to all witnesses, hence many sentence nodes will have gaps,
but that is not a problem for TF. We have dealt with gaps extensively
in the Hebrew Bible, see the <a href="https://nbviewer.jupyter.org/github/ETCBC/bhsa/blob/master/tutorial/searchGaps.ipynb">gaps
tutorial</a>.</p>
<p><img alt="" src="../images/variants/result.png"></p>
<ul>
<li>the base text and each individual witness will get their own, separate set of
sentence nodes</li>
<li>triangles open and close sentence nodes</li>
<li>rhombs close a sentence node and open the next one</li>
<li>half circles suspend and resume sentence nodes</li>
</ul>
<p>Let's walk through the diagram to see where all the sentence nodes start, are
suspended, resumed, and finally end. When doing so, we will encounter steps
that will be not trivial to perform, a fact that we have to solve in our
algorithm.
The points where this happens are marked by a dotted border around triangles or
rhombs.
We are not there yet, so the following steps are not yet the algorithm, but
just a description of the result. However, at the bottom we display a stack
will values that will help the algorithm later on.</p>
<ul>
<li><code>1</code>:
the start of a sentence node in the base text. It is also the start of
sentences in witness <code>d</code> and <code>e</code>, because these witnesses will continue this
part of the sentence in different ways than the main text. <strong>It is a
challenge for the algorithm to find the starting point for variant
sentences.</strong></li>
<li><code>4</code>: the start of the outer app where there are variants for witnesses <code>d</code>
and <code>e</code>, but first we encounter the <code>lem</code>-element where the base text
continues, and hence the first sentence continues without interruption</li>
<li><code>5</code>: still in the <code>lem</code>-element, the first sentence in the base text terminates,
and a new one is started. It appears that this is also the point where
several sentences in the individual witnesses must start. For example, in the
left inner app there is a variant in witnesses <code>a</code> and <code>b</code> that has a
sentence boundary, at <code>17</code>. If you travel back from there along the text of
<code>a</code> and <code>b</code>, you see that here at <code>5</code> is the corresponding sentence boundary.
Likewise, you'll see that in <code>f</code> and <code>g</code> there must also start a sentence
here. <strong>This is a challenge for the algorithm later</strong>.</li>
<li><code>7</code>: the left inner app looms, in which the base text continues in its
<code>lem</code>-element. Once in that element, we will have base text that does not occur
in the witnesses <code>a b f g</code>. So the sentences in those witnesses that have
already started, must be suspended at this point. Hence those half circles.</li>
<li><code>8</code>: inside the inner <code>lem</code>-element the second sentence of the base text
continues.</li>
<li><code>10</code>: the second base text sentence ends, and the third one is started.
It
also appears that we must start a sentence in witness <code>c</code> here. That is
because of the boundary at <code>42</code>, where variants <code>b</code> and <code>c</code> have a sentence
boundary. This boundary is the for witness <code>c</code> the first witness-specific
boundary. Likewise, a sentence in witness <code>h</code> starts here, because there
appears to be a variant for <code>g</code> and <code>h</code> with a running sentence at <code>47</code>.
<strong>The algorithm needs to extricate individual witnesses out of the variants
that are shared by multiple witnesses.</strong></li>
<li><code>12</code>: the <code>lem</code>-element in the left inner app ends, and all running sentences
at this point must be suspended, which are the third base text sentence and
the running sentences in <code>c</code> and <code>h</code>.</li>
<li><code>13</code>: we dive in the variant witnessed by <code>a</code> and <code>b</code>. The running sentences
in these witnesses can be resumed.</li>
<li><code>17</code>: a sentence break in this variant. The running sentences in <code>a</code> and <code>b</code>
are terminated, and new ones are started.</li>
<li><code>21</code>: end of this variant, we suspend the running sentences in <code>a</code> and <code>b</code></li>
<li><code>22</code>: we dive in the variant of witnesses <code>f</code> and <code>g</code> and resume their
running sentences.</li>
<li><code>27</code>: end of this variant, we suspend the running sentences in <code>f</code> and <code>g</code></li>
<li><code>28</code>: back in the base text we resume all suspended sentences. Note that this
includes all sentences of the <code>rdg</code> elements that are now closed, because they
are not yet finished, they will be finished by a later sentence break.</li>
<li><code>33</code>: the right inner app looms, the base text continues, so all running
sentences can continue, except the ones that are taken up in the <code>rdg</code> elements
of the app. That is why we have to suspend <code>b</code>, <code>c</code>, <code>g</code>, and <code>h</code>.</li>
<li><code>34</code>: the base text continues in the <code>lem</code> element of the right inner app.
Running sentences in all witnesses except the ones mentioned in the <code>rdg</code>
elements can continue, which are sentences in <code>a</code> and <code>f</code>.</li>
<li><code>35</code>: a sentence boundary. The running sentence in the base text is
terminated and a new one started. The running sentences in <code>a</code> and <code>f</code> are
terminated as well, since <code>a</code> and <code>f</code> agree with the base text here. For the
same reason, no new <code>a</code> and <code>f</code> sentences are opened here, observing the fact
that there is no further material specific to <code>a</code> and <code>f</code> before the next
sentence break in the base text.</li>
<li><code>37</code>: the <code>lem</code>-element in the right inner app ends, and all running sentences
are suspended, which is only the current sentence in the base text.</li>
<li><code>38</code>: we dive in the variant witnessed by <code>b</code> and <code>c</code> and resume running
sentences in these witnessed. <strong>Note that in <code>c</code> we have a running sentence
that triggered the creation of the sentence already at slot <code>10</code>.</strong></li>
<li><code>42</code>: a sentence break in this variant. The running sentences in <code>b</code> and <code>c</code>
are terminated, and new ones are started.</li>
<li><code>46</code>: end of this variant, we suspend the running sentences in <code>b</code> and <code>c</code></li>
<li><code>47</code>: we dive in the variant witnessed by <code>g</code> and <code>h</code> and resume their
running sentences. <strong>Note that in <code>h</code> we have a running sentence that
triggered the creation of the sentence already at slot <code>10</code>.</strong></li>
<li><code>52</code>: end of this variant, we suspend the running sentences in <code>g</code> and <code>h</code></li>
<li><code>53</code>: back from the inner app in the base text we resume all suspended
sentences. Note that this includes all sentences of the <code>rdg</code> elements that are
now closed, because they are not yet finished, they will be finished by a
later sentence break.</li>
<li><code>55</code>: a sentence boundary. The running sentence in the base text is
terminated and a new one started. The running sentences in <code>b</code>, <code>g</code>, <code>c</code> and
<code>h</code> are terminated as well, since these witnesses agree with the base text
here. For the same reason, no new witness-bound sentences are opened here.</li>
<li><code>58</code>: now we are about to end the <code>lem</code>-element of the outer app. We suspend
the running sentence in the base text</li>
<li><code>59</code>: we dive in the variant witnessed by <code>d</code> and resume its running sentence. </li>
<li><code>64</code>: this variant ends and we suspend the sentence in <code>d</code> since it is not
yet finished. </li>
<li><code>65</code>: we dive in the variant witnessed by <code>e</code> and resume its running sentence. </li>
<li><code>68</code>: a sentence break in this variant. The running sentence in <code>e</code> is
terminated, and a new one started.</li>
<li><code>70</code>: this variant ends and we suspend the sentence in <code>e</code> since it is not
yet finished. </li>
<li><code>71</code>: back to the main text, outside all app elements. We resume the running
sentence in the base text, and the suspended left overs in the variants for
<code>d</code> and <code>e</code>.</li>
<li><code>75</code>: a sentence break in the main text. All running sentences can be
terminated now.</li>
</ul>
<h2 id="processing-applemrdg">Processing <code>&lt;app&gt;&lt;lem&gt;&lt;rdg&gt;</code></h2>
<p>At this point we understand what sentence division means in the presence of
variant texts. We know that for each individual witness we have to make
sentence nodes for each sentence of which a part differs from the main text.
The problem is that the <code>app</code>-<code>lem</code>-<code>rdg</code>-elements neatly wrap themselves around the
differences, but that the sentences in which these differences are contained
may spread outside these elements. This spreading may extend over multiple
other app elements, which can also be nested.
When we process the text from left to right, we encounter locations where we
have to insert witness-dependent sentence starts before we have seen any hint
of the presence of that witness.
We solve that problem as follows:</p>
<ol>
<li>in a first, preparatory pass, we walk through the complete text and collect
for each <code>app</code>-element the witnesses that occur in its <code>rdg</code> elements</li>
<li>in the second, node-generating pass, we know, upon entering an app element,
which are the witnesses of its variants in the <code>rdg</code> elements.</li>
<li>if we start processing an <code>rdg</code> element, there are several cases:<ol>
<li>the content starts with a new sentence: no problem, we generate a new
sentence node for the witnesses of that <code>rdg</code> on the spot</li>
<li>the content starts in the middle of a sentence:<ol>
<li>we have seen that witness before: that means there is currently a
suspended sentence in that witness, and we resume it on the spot</li>
<li>we have not seen that witness before: that means the following
sentence part continues a sentence in the base text that was
suspended just before this <code>app</code>-element started: we make a copy of
that suspended sentence node for this witness.</li>
</ol>
</li>
</ol>
</li>
</ol>
<p>The last case is possible if we remember the last suspended sentence part in
front of each <code>app</code>-element. Because <code>app</code>-elements can be nested, we remember
these fragments on a corresponding stack. This stack is exactly what you see at
the bottom of the diagram above. Whenever we enter an <code>app</code>-element, we push the
positions of the last base sentence leading to that app on the stack. Whenever
we leave an app, we pop the stack. Whenever we start a new <code>rdg</code> element, we use
the value on the top of the stack when we have to create a new sentence node
for the witnesses in that <code>rdg</code>.</p>
<p>We also need to remember the current sentence fragments that are in progress.
The only thing we need is for each witness the node that is in progress.</p>
<p>With this information in hand we are able to make every decision we need to
make with the information that is accessible at the moment that the decision is
required.</p>
<h2 id="walker-conversion">Walker conversion</h2>
<p>The context of the algorithm is the <em>walker</em> conversion by which we issue
node-creation statements and where slots are automatically added to all current
nodes that are not yet terminated. See <code><a title="tf.convert.walker" href="../convert/walker.html">tf.convert.walker</a></code>.
Because of this environment we can now specify the information that we maintain
while walking through the TEI source.</p>
<h2 id="implementation">Implementation</h2>
<p>Here we describe how the algorithm is implemented within the walker conversion
framework.</p>
<h3 id="creating-terminating-resuming-nodes">Creating, terminating, resuming nodes</h3>
<p>We create a sentence node by issuing a statement</p>
<pre><code class="language-python">s = cv.node(&quot;sentence&quot;)
</code></pre>
<p>If it belongs to the base text, we give it a <code>wit</code> attribute with a standard value:</p>
<pre><code class="language-python">cv.feature(s, wit=&quot;base&quot;)
</code></pre>
<p>If the node is witness dependent, we give it the feature <code>wit</code> with the name of
the witness as value, e.g. for witness <code>a</code>:</p>
<pre><code class="language-python">cv.feature(s, wit=&quot;a&quot;)
</code></pre>
<p>Now the sentence node <code>s</code> is open, new slots are automatically linked to <code>s</code>.
But we must remember that <code>s</code> is a currently active sentence for witness <code>a</code>.
We assume that we have a big dictionary <code>cur</code> in which we have a subdictionary
<code>cur["variantssentence"]</code> in which we can store this information:</p>
<pre><code class="language-python">cur[&quot;variantssentence&quot;][&quot;a&quot;] = s
</code></pre>
<p>And so we do for all witnesses in which we build sentences.
We also do it for the base text, which we remember as</p>
<pre><code class="language-python">cur[&quot;variantssentence&quot;][&quot;base&quot;] = s
</code></pre>
<p>If the <code>rdg</code> that contains witness <code>a</code> comes to an end, we end this sentence <code>s</code>:</p>
<pre><code class="language-python">cv.terminate(s)
</code></pre>
<p>As far as the walker machinery is concerned, the <code>s</code> is now terminated. Now, if
the <code>rdg</code> ended with an unfinished sentence, we keep <code>s</code> in
<code>cur["sentence"]["a"]</code> so that we can resume <code>s</code> when needed.
That will happen when we enter an later <code>rdg</code> for which <code>a</code> is a witness, or when
we return to the base text before having passed a sentence boundary.
In those cases we do</p>
<pre><code class="language-python">cv.resume(s)
</code></pre>
<p>If we encounter a sentence boundary at the end of an <code>rdg</code> element for witness
<code>a</code>, we terminate <code>s</code> and we remove <code>cur["sentence"]["a"]</code>, so that this
sentence node will not be resumed later.</p>
<h3 id="the-stack">The stack</h3>
<p>For each <code>app</code>-element, we must remember the sentence in the base text that leads
to the start of this app or rather which slots that sentence contains.
Because, whenever we enter one of its <code>rdg</code> elements, and that element starts
with an unfinished sentence, it is a continuation of that leading sentence.
Because apps are nested, we remember these values on a stack.
If we are outside any <code>app</code>-element, the stack is empty.</p>
<pre><code class="language-python">cur[&quot;appstack&quot;] = []
</code></pre>
<p>When we encounter an <code>app</code> element, we add a new value on the stack. We
retrieve the current sentence in the base text, and find out which slots have
been linked to that sentence so far. It goes as follows:</p>
<pre><code class="language-python">n = cur[&quot;variantssentence&quot;][&quot;&quot;]
slots = cv.linked(n)
cur[&quot;appstack&quot;].append(slots)
</code></pre>
<p>And whenever we encounter an <code>rdg</code> whose material must be prepended with these
slots, it works as follows:</p>
<pre><code class="language-python">w = cv.node(&quot;sentence&quot;)
cv.feature(w, wit=&quot;a&quot;)
slots = cur[&quot;appstack&quot;][-1]
cv.link(w, slots)
</code></pre>
<p>When we have finished the last <code>rdg</code> of an app, we leave the app and do</p>
<pre><code class="language-python">cur[&quot;appstack&quot;].pop()
</code></pre>
<p>This solves the problem of having to create witness dependent nodes before we
can know that we have to do so. We postpone the creation of such nodes until
the moment that we are confronted with the witness for the first time, and
at that moment we link exactly the right slots to that node in one go, before
we rely on the automatic slot-linking machinery of the walker conversion.</p>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric/blob/1606be8081b05d38725496b91c9815487ac8e93c/tf/about/variants.py#L1-L3" class="git-link">Browse git</a>
</summary>
<pre><code class="python">&#34;&#34;&#34;
.. include:: ../docs/about/variants.md
&#34;&#34;&#34;</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<p><a href="https://github.com/annotation" title="annotation on GitHub"><img src="../../tf/images/tf-small.png" alt="annotation"></a></p>
<p><a href="../../tf/index.html">tf home</a> -
<a href="../../tf/cheatsheet.html">cheat sheet</a> -
<a href="https://github.com/annotation/text-fabric" title="GitHub repo"><img src="../../tf/images/GitHub_Logo.png" alt="GitHub" width="50"></a></p>
</p>
<form>
<input id="lunr-search" name="q" placeholder="ðŸ”Ž Search ..." aria-label="Search"
disabled minlength="2">
</form>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/tingle/0.15.3/tingle.min.css" integrity="sha512-j1u8eUJ4f23xPPxwOrLUPQaCD2dwzNqqmDDcWS4deWsMv2ohLqmXXuP3hU7g8TyzbMSakP/mMqoNBYWj8AEIFg==" crossorigin>
<script src="https://cdnjs.cloudflare.com/ajax/libs/tingle/0.15.3/tingle.min.js" integrity="sha512-plGUER9JkeEWPPqQBE4sdLqBoQug5Ap+BCGMc7bJ8BXkm+VVj6QzkpBz5Yv2yPkkq+cqg9IpkBaGCas6uDbW8g==" crossorigin></script>
<style>
.modal-dialog iframe {
width: 100vw;
height: calc(100vh - 80px);
}
@media screen and (min-width: 700px) {
.modal-dialog iframe {
width: 70vw;
height: 80vh;
}
}
.modal-dialog .tingle-modal-box {width: auto;}
.modal-dialog .tingle-modal-box__content {padding: 0;}
</style>
<script>
const input = document.getElementById('lunr-search');
input.disabled = false;
input.form.addEventListener('submit', (ev) => {
ev.preventDefault();
const url = new URL(window.location);
url.searchParams.set('q', input.value);
history.replaceState({}, null, url.toString());
search(input.value);
});
const query = new URL(window.location).searchParams.get('q');
if (query)
search(query);
function search(query) {
const url = '../../doc-search.html#' + encodeURIComponent(query);
new tingle.modal({
cssClass: ['modal-dialog'],
onClose: () => {
const url = new URL(window.location);
url.searchParams.delete('q');
history.replaceState({}, null, url.toString());
setTimeout(() => input.focus(), 100);
}
}).setContent('<iframe src="' + url + '"></iframe>').open();
}
</script>
<h1>Index</h1>
<div class="toc">
<ul>
<li><a href="#sentence-boundaries-in-textual-variants">Sentence boundaries in textual variants</a></li>
<li><a href="#usage">Usage</a></li>
<li><a href="#explanation">Explanation</a><ul>
<li><a href="#the-app-element">The app element</a></li>
<li><a href="#from-boundaries-to-nodes">From boundaries to nodes</a></li>
<li><a href="#the-problem">The problem</a></li>
<li><a href="#the-resulting-nodes">The resulting nodes</a></li>
<li><a href="#processing-applemrdg">Processing &lt;app&gt;&lt;lem&gt;&lt;rdg&gt;</a></li>
<li><a href="#walker-conversion">Walker conversion</a></li>
<li><a href="#implementation">Implementation</a><ul>
<li><a href="#creating-terminating-resuming-nodes">Creating, terminating, resuming nodes</a></li>
<li><a href="#the-stack">The stack</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="tf.about" href="index.html">tf.about</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<a href="https://pure.knaw.nl/portal/en/persons/dirk-roorda">Dirk Roorda</a>
<a href="https://huc.knaw.nl"><img alt="HuC" src="../../tf/images/huc.png" width="200" alt="Humanities Cluster"></a>
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.11.1</a>.</p>
</footer>
</body>
</html>
