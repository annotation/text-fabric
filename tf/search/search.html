<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>tf.search.search API documentation</title>
<meta name="description" content="Search (top-level)" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>tf.search.search</code></h1>
</header>
<section id="section-intro">
<h1 id="search-top-level">Search (top-level)</h1>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric/blob/5760b670709c4be44256e51cdeea8af5d464ae31/tf/search/search.py#L1-L544" class="git-link">Browse git</a>
</summary>
<pre><code class="python">&#34;&#34;&#34;
# Search (top-level)
&#34;&#34;&#34;

from ..core.helpers import console, wrapMessages
from .searchexe import SearchExe
from ..parameters import YARN_RATIO, TRY_LIMIT_FROM, TRY_LIMIT_TO
from ..core.timestamp import SILENT_D, AUTO, silentConvert


class Search(object):
    &#34;&#34;&#34; &#34;&#34;&#34;

    def __init__(self, api, silent=SILENT_D):
        silent = silentConvert(silent)
        self.api = api
        self.silent = silent
        self.exe = None
        self.perfDefaults = dict(
            yarnRatio=YARN_RATIO,
            tryLimitFrom=TRY_LIMIT_FROM,
            tryLimitTo=TRY_LIMIT_TO,
        )
        self.perfParams = {}
        self.perfParams.update(self.perfDefaults)
        SearchExe.setPerfParams(self.perfParams)

    def tweakPerformance(self, silent=SILENT_D, **kwargs):
        &#34;&#34;&#34;Tweak parameters that influence the search process.

        !!! explanation &#34;Theory&#34;
            Before the search engine retrieves result tuples of nodes,
            there is a process to narrow down the search space.

            See `tf.about.searchdesign` and and remember that we use the term *yarn* for
            the sets of candidate nodes from which we stitch our results together.

            *Edge spinning* is the process of
            transferring constraints on one node via edges to constraints on
            another node. The one node lives in a yarn, i.e. a set of candidate nodes,
            and the node at the other side of the edge lives in a yarn.

            If the first yarn is small then we might be able to reduce the second yarn
            by computing the counterparts of the nodes in the small yarn in the second
            yarn. We can leave out all other nodes from the second yarn.
            A big reduction!

            The success of edge spinning depends mainly on two factors:

            !!! info &#34;Size difference&#34;
                Edge spinning works best if there is a big difference in size
                between the candidate
                sets for the nodes at both sides of an edge.

            !!! info &#34;Spread&#34;
                The spread of a relation is the number of different edges
                that can start from the same node or end at the same node.

                For example, the spread of the `equality` operator is just 1, but
                the spread of the `inequality` operator is virtually as big
                as the relevant yarn.

                If there are constraints on a node in one yarn, and if there is an edge
                between that yarn and another one, and if the spread is big,
                not much of the constraint can be transferred to the other yarn.

            !!! example &#34;Example&#34;
                Suppose both yarns are words, the first yarn has been constrained
                to verbs, and the equality relation holds must hold between the yarns.
                Then in all results the node from the second yarn is also a verb.
                So we can constrain the second yarn to verbs too.

                But if the relation is inequality, we cannot impose any additional
                restriction on nodes in the second yarn. All nodes in the second
                yarn are unequal to at least one verb.

            !!! info &#34;Estimating the spread&#34;
                We estimate the spreads of edges over and over again, in a series
                of iterations where we reduce yarns.

                An exhaustive computation would be too expensive, so we take
                a sample of a limited amount of relation computations.


        If you do not pass a parameter, its value will not be changed.
        If you pass `None` for a parameter, its value will be reset to the default value.

        Here are the parameters that you can tweak:

        Parameters
        ----------

        yarnRatio: float
            The `yarnRatio` is the minimal factor between the sizes of
            the smallest and the biggest set of candidates of the nodes at both ends of
            the edge. And that divided by the spread of the relation as estimated
            by a sample.

            !!! example &#34;Example&#34;
                Suppose we set the yarnRatio to 1.5.
                Then, if we have yarns of 100,000 and 10,000 members,
                with a relation between them with spread 5,
                then 100,000 / 10,000 / 5 = 2.
                This is higher than the yarnRatio of 1.5,
                so the search engine decides that edge spinning is worth it.

                The reasoning is that the 10,000 nodes in the smallest yarn are expected
                to reach only 10,000 * 5 nodes in the other yarn by the relation,
                and so we can achieve a significant reduction.

            If you have a very slow query, and you think that a bit more edge spinning
            helps, decrease the yarnRatio towards 0.

            If you find that a lot of queries spend too much time in edge spinning,
            increase the yarnRatio.

        tryLimitFrom: integer
            In order to determine the spreads of the relations, TF takes
            random samples and extrapolates the results. We grab some nodes
            from the set at the *from* side of an edge, and some nodes at the
            *to* side of the same edge, Then we compute in how many cases the relation
            holds. That is a measure for the spread.

            The parameters `tryLimitFrom` and `tryLimitTo` dictate how big these
            samples are. The bigger, the better the estimation of the spread.
            But also the more work it is.

            If you find that your queries take consistently a tad too much time,
            consider lowering these parameters to 10.

            If you find that the times your queries take varies a lot,
            increase these values to 10000.
        tryLimitTo: integer
            See `tryLimitFrom`
        &#34;&#34;&#34;

        silent = silentConvert(silent)
        api = self.api
        TF = api.TF
        error = TF.error
        info = TF.info
        isSilent = TF.isSilent
        setSilent = TF.setSilent
        defaults = self.perfDefaults

        wasSilent = isSilent()
        setSilent(silent)
        for (k, v) in kwargs.items():
            if k not in defaults:
                error(f&#39;No such performance parameter: &#34;{k}&#34;&#39;, tm=False)
                continue
            if v is None:
                v = defaults[k]
            elif type(v) is not int and k != &#34;yarnRatio&#34;:
                error(
                    f&#39;Performance parameter &#34;{k}&#34; must be set to an integer, not to &#34;{v}&#34;&#39;,
                    tm=False,
                )
                continue
            self.perfParams[k] = v
        info(&#34;Performance parameters, current values:&#34;, tm=False)
        for (k, v) in sorted(self.perfParams.items()):
            info(f&#34;\t{k:&lt;20} = {v:&gt;7}&#34;, tm=False)
        SearchExe.setPerfParams(self.perfParams)
        setSilent(wasSilent)

    def search(
        self,
        searchTemplate,
        limit=None,
        sets=None,
        shallow=False,
        silent=SILENT_D,
        here=True,
        _msgCache=False,
    ):
        &#34;&#34;&#34;Searches for combinations of nodes that together match a search template.

        If you can, you should use `tf.advanced.search.search` instead.

        Parameters
        ----------
        searchTemplate: string
            A string that conforms to the rules described in `tf.about.searchusage`.

        shallow: set | tuple
            If `True` or `1`, the result is a set of things that match the
            top-level element of the `query`.

            If `2` or a bigger number *n*, return the set of truncated result tuples:
            only the first *n* members of each tuple is retained.

            If `False` or `0`, a sorted list of all result tuples will be returned.

        sets: dict
            If not `None`, it should be a dictionary of sets, keyed by a names.

        limit: integer, optional `None`
            If `limit` is a positive number, it will fetch only that many results.
            If it is negative, 0, None, or absent, it will fetch arbitrary many results.

            !!! caution &#34;there is an upper *fail limit* for safety reasons.
                The limit is a factor times the max node in your corpus.
                See `tf.parameters.SEARCH_FAIL_FACTOR`.
                If this *fail limit* is exceeded in cases where no positive `limit`
                has been passed, you get a warning message.

        Returns
        -------
        generator | tuple
            Each result is a tuple of nodes, where each node corresponds to an
            *atom*-line in your search template.about.searchusage`).

            If `limit` is not `None`, a *generator* is returned,
            which yields the results one by one.

            Otherwise, the results will be fetched up till `limit`
            and delivered as a tuple.

        Notes
        -----
        !!! hint &#34;More info on the search plan&#34;
            Searching is complex. The search template must be parsed, interpreted,
            and translated into a search plan. See `tf.search.search.Search.study`.
        &#34;&#34;&#34;

        exe = SearchExe(
            self.api,
            searchTemplate,
            outerTemplate=searchTemplate,
            quKind=None,
            offset=0,
            sets=sets,
            shallow=shallow,
            silent=silent,
            _msgCache=_msgCache,
            setInfo={},
        )
        if here:
            self.exe = exe
        queryResults = exe.search(limit=limit)
        if type(_msgCache) is list:
            messages = wrapMessages(_msgCache)
            self._msgCache = _msgCache
            return (queryResults, messages) if here else (queryResults, messages, exe)
        return queryResults

    def study(
        self,
        searchTemplate,
        strategy=None,
        sets=None,
        shallow=False,
        here=True,
        silent=SILENT_D,
    ):
        &#34;&#34;&#34;Studies a template to prepare for searching with it.

        The search space will be narrowed down and a plan for retrieving the results
        will be set up.

        If the search template query has quantifiers, the asscociated search templates
        will be constructed and executed. These searches will be reported clearly.

        The resulting plan can be viewd by `tf.search.search.Search.showPlan`.

        Parameters
        ----------
        searchTemplate: string
            A string that conforms to the rules described in `tf.about.searchusage`.

        strategy: string
            In order to tame the performance of search, the strategy by which results
            are fetched matters a lot.  The search strategy is an implementation detail,
            but we bring it to the surface nevertheless.

            To see the names of the available strategies, just call
            `S.study(&#39;&#39;, strategy=&#39;x&#39;)` and you will get a list of options reported to
            choose from.

            Feel free to experiment. To see what the strategies do, see the
            code in `tf.search.stitch`.

        shallow: set | tuple
            If `True` or `1`, the result is a set of things that match the
            top-level element of the search template.

            If `2` or a bigger number *n*, return the set of truncated result tuples:
            only the first *n* members of each tuple is retained.

            If `False` or `0`, a sorted list of all result tuples will be returned.

        sets: dict
            If not `None`, it should be a dictionary of sets, keyed by a names.
            In the search template you can refer to those names to invoke those sets.

        silent: string, optional `tf.core.timestamp.SILENT_D`
            See `tf.core.timestamp.Timestamp`

        See Also
        --------
        tf.about.searchusage: Search guide
        &#34;&#34;&#34;

        if silent is False:
            silent = AUTO

        exe = SearchExe(
            self.api,
            searchTemplate,
            outerTemplate=searchTemplate,
            quKind=None,
            offset=0,
            sets=sets,
            shallow=shallow,
            silent=SILENT_D,
            showQuantifiers=True,
            setInfo={},
        )
        if here:
            self.exe = exe
        return exe.study(strategy=strategy)

    def fetch(self, limit=None, _msgCache=False):
        &#34;&#34;&#34;Retrieves query results, up to a limit.

        Must be called after a previous `tf.search.search.Search.search()` or
        `tf.search.search.Search.study()`.

        Parameters
        ----------

        limit: integer, optional `None`
            If `limit` is a positive number, it will fetch only that many results.
            If it is negative, 0, None, or absent, it will fetch arbitrary many results.

            !!! caution &#34;there is an upper *fail limit* for safety reasons.
                The limit is a factor times the max node in your corpus.
                See `tf.parameters.SEARCH_FAIL_FACTOR`.
                If this *fail limit* is exceeded in cases where no positive `limit`
                has been passed, you get a warning message.


        Returns
        -------
        generator | tuple
            Each result is a tuple of nodes, where each node corresponds to an
            *atom*-line in your search template.about.searchusage`).

            If `limit` is not `None`, a *generator* is returned,
            which yields the results one by one.

            Otherwise, the results will be fetched up till `limit`
            and delivered as a tuple.

        Notes
        -----
        !!! example &#34;Iterating over the `fetch()` generator&#34;
            You typically fetch results by saying:

                i = 0
                for tup in S.results():
                    do_something(tup[0])
                    do_something_else(tup[1])

            Alternatively, you can set the `limit` parameter, to ask for just so many
            results. They will be fetched, and when they are all collected,
            returned as a tuple.

        !!! example &#34;Fetching a limited amount of results&#34;
            This

                S.fetch(limit=10)

            gives you the first 10 results without further ado.
        &#34;&#34;&#34;

        exe = self.exe
        TF = self.api.TF

        if exe is None:
            error = TF.error
            error(&#39;Cannot fetch if there is no previous &#34;study()&#34;&#39;)
        else:
            queryResults = exe.fetch(limit=limit)
            if type(_msgCache) is list:
                messages = TF.cache(_asString=True)
                return (queryResults, messages)
            return queryResults

    def count(self, progress=None, limit=None):
        &#34;&#34;&#34;Counts the results, with progress messages, optionally up to a limit.

        Must be called after a previous `tf.search.search.Search.search()` or
        `tf.search.search.Search.study()`.

        Parameters
        ----------
        progress: integer, optional, default `100`
            Every once for every `progress` results a progress message is shown
            when fetching results.

        limit: integer, optional `None`
            If `limit` is a positive number, it will fetch only that many results.
            If it is negative, 0, None, or absent, it will fetch arbitrary many results.

            !!! caution &#34;there is an upper *fail limit* for safety reasons.
                The limit is a factor times the max node in your corpus.
                See `tf.parameters.SEARCH_FAIL_FACTOR`.
                If this *fail limit* is exceeded in cases where no positive `limit`
                has been passed, you get a warning message.

        !!! note &#34;why needed&#34;
            You typically need this in cases where result fetching turns out to
            be (very) slow.

        !!! caution &#34;generator versus list&#34;
            `len(S.results())` does not work in general, because `S.results()` is
            usually a generator that delivers its results as they come.

        Returns
        -------
        None
            The point of this function is to show the counting of the results
            on the screen in a series of timed messages.
        &#34;&#34;&#34;

        exe = self.exe
        if exe is None:
            error = self.api.TF.error
            error(&#39;Cannot count if there is no previous &#34;study()&#34;&#39;)
        else:
            exe.count(progress=progress, limit=limit)

    def showPlan(self, details=False):
        &#34;&#34;&#34;Show the result of the latest study of a template.

        Search results are tuples of nodes and the plan shows which part of the tuple
        corresponds to which part of the search template.

        Only meaningful after a previous `tf.search.search.Search.study`.

        Parameters
        ----------
        details: boolean, optional `False`
            If `True`, more information will be provided:
            an overview of the search space and a description of how the results
            will be retrieved.

        !!! note &#34;after S.study()&#34;
            This function is only meaningful after a call to `S.study()`.
        &#34;&#34;&#34;

        exe = self.exe
        if exe is None:
            error = self.api.TF.error
            error(&#39;Cannot show plan if there is no previous &#34;study()&#34;&#39;)
        else:
            exe.showPlan(details=details)

    def relationsLegend(self):
        &#34;&#34;&#34;Dynamic info about the basic relations that can be used in templates.

        It includes the edge features that are available in your dataset.

        Returns
        -------
        None
            The legend will be shown in the output.
        &#34;&#34;&#34;

        exe = self.exe
        if exe is None:
            exe = SearchExe(self.api, &#34;&#34;)
        console(exe.relationLegend)

    def glean(self, tup):
        &#34;&#34;&#34;Renders a single result into something human readable.

        A search result is just a tuple of nodes that correspond to your template, as
        indicated by `showPlan()`. Nodes give you access to all information that the
        corpus has about it.

        This function is meant to just give you a quick first impression.

        Parameters
        ----------
        tup: tuple of int
            The tuple of nodes in question.

        Returns
        -------
        string
            The result indicats where the tuple occurs in terms of sections,
            and what text is associated with the tuple.

        Notes
        -----
        !!! example &#34;Inspecting results&#34;
            This

                for result in S.fetch(limit=10):
                    TF.info(S.glean(result))

            is a handy way to get an impression of the first bunch of results.

        !!! hint &#34;Universal&#34;
            This function works on all tuples of nodes, whether they have been
            obtained by search or not.

        !!! hint &#34;More ways of showing results&#34;
            The advanced API offers much better ways of showing results.
            See `tf.advanced.display.show` and `tf.advanced.display.table`.
        &#34;&#34;&#34;

        T = self.api.T
        F = self.api.F
        E = self.api.E
        fOtype = F.otype.v
        slotType = F.otype.slotType
        maxSlot = F.otype.maxSlot
        eoslots = E.oslots.data

        lR = len(tup)
        if lR == 0:
            return &#34;&#34;
        fields = []
        for (i, n) in enumerate(tup):
            otype = fOtype(n)
            words = [n] if otype == slotType else eoslots[n - maxSlot - 1]
            if otype == T.sectionTypes[2]:
                field = &#34;{} {}:{}&#34;.format(*T.sectionFromNode(n))
            elif otype == slotType:
                field = T.text(words)
            elif otype in T.sectionTypes[0:2]:
                field = &#34;&#34;
            else:
                field = &#34;{}[{}{}]&#34;.format(
                    otype,
                    T.text(words[0:5]),
                    &#34;...&#34; if len(words) &gt; 5 else &#34;&#34;,
                )
            fields.append(field)
        return &#34; &#34;.join(fields)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="tf.search.search.Search"><code class="flex name class">
<span>class <span class="ident">Search</span></span>
<span>(</span><span>api, silent='terse')</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric/blob/5760b670709c4be44256e51cdeea8af5d464ae31/tf/search/search.py#L11-L544" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class Search(object):
    &#34;&#34;&#34; &#34;&#34;&#34;

    def __init__(self, api, silent=SILENT_D):
        silent = silentConvert(silent)
        self.api = api
        self.silent = silent
        self.exe = None
        self.perfDefaults = dict(
            yarnRatio=YARN_RATIO,
            tryLimitFrom=TRY_LIMIT_FROM,
            tryLimitTo=TRY_LIMIT_TO,
        )
        self.perfParams = {}
        self.perfParams.update(self.perfDefaults)
        SearchExe.setPerfParams(self.perfParams)

    def tweakPerformance(self, silent=SILENT_D, **kwargs):
        &#34;&#34;&#34;Tweak parameters that influence the search process.

        !!! explanation &#34;Theory&#34;
            Before the search engine retrieves result tuples of nodes,
            there is a process to narrow down the search space.

            See `tf.about.searchdesign` and and remember that we use the term *yarn* for
            the sets of candidate nodes from which we stitch our results together.

            *Edge spinning* is the process of
            transferring constraints on one node via edges to constraints on
            another node. The one node lives in a yarn, i.e. a set of candidate nodes,
            and the node at the other side of the edge lives in a yarn.

            If the first yarn is small then we might be able to reduce the second yarn
            by computing the counterparts of the nodes in the small yarn in the second
            yarn. We can leave out all other nodes from the second yarn.
            A big reduction!

            The success of edge spinning depends mainly on two factors:

            !!! info &#34;Size difference&#34;
                Edge spinning works best if there is a big difference in size
                between the candidate
                sets for the nodes at both sides of an edge.

            !!! info &#34;Spread&#34;
                The spread of a relation is the number of different edges
                that can start from the same node or end at the same node.

                For example, the spread of the `equality` operator is just 1, but
                the spread of the `inequality` operator is virtually as big
                as the relevant yarn.

                If there are constraints on a node in one yarn, and if there is an edge
                between that yarn and another one, and if the spread is big,
                not much of the constraint can be transferred to the other yarn.

            !!! example &#34;Example&#34;
                Suppose both yarns are words, the first yarn has been constrained
                to verbs, and the equality relation holds must hold between the yarns.
                Then in all results the node from the second yarn is also a verb.
                So we can constrain the second yarn to verbs too.

                But if the relation is inequality, we cannot impose any additional
                restriction on nodes in the second yarn. All nodes in the second
                yarn are unequal to at least one verb.

            !!! info &#34;Estimating the spread&#34;
                We estimate the spreads of edges over and over again, in a series
                of iterations where we reduce yarns.

                An exhaustive computation would be too expensive, so we take
                a sample of a limited amount of relation computations.


        If you do not pass a parameter, its value will not be changed.
        If you pass `None` for a parameter, its value will be reset to the default value.

        Here are the parameters that you can tweak:

        Parameters
        ----------

        yarnRatio: float
            The `yarnRatio` is the minimal factor between the sizes of
            the smallest and the biggest set of candidates of the nodes at both ends of
            the edge. And that divided by the spread of the relation as estimated
            by a sample.

            !!! example &#34;Example&#34;
                Suppose we set the yarnRatio to 1.5.
                Then, if we have yarns of 100,000 and 10,000 members,
                with a relation between them with spread 5,
                then 100,000 / 10,000 / 5 = 2.
                This is higher than the yarnRatio of 1.5,
                so the search engine decides that edge spinning is worth it.

                The reasoning is that the 10,000 nodes in the smallest yarn are expected
                to reach only 10,000 * 5 nodes in the other yarn by the relation,
                and so we can achieve a significant reduction.

            If you have a very slow query, and you think that a bit more edge spinning
            helps, decrease the yarnRatio towards 0.

            If you find that a lot of queries spend too much time in edge spinning,
            increase the yarnRatio.

        tryLimitFrom: integer
            In order to determine the spreads of the relations, TF takes
            random samples and extrapolates the results. We grab some nodes
            from the set at the *from* side of an edge, and some nodes at the
            *to* side of the same edge, Then we compute in how many cases the relation
            holds. That is a measure for the spread.

            The parameters `tryLimitFrom` and `tryLimitTo` dictate how big these
            samples are. The bigger, the better the estimation of the spread.
            But also the more work it is.

            If you find that your queries take consistently a tad too much time,
            consider lowering these parameters to 10.

            If you find that the times your queries take varies a lot,
            increase these values to 10000.
        tryLimitTo: integer
            See `tryLimitFrom`
        &#34;&#34;&#34;

        silent = silentConvert(silent)
        api = self.api
        TF = api.TF
        error = TF.error
        info = TF.info
        isSilent = TF.isSilent
        setSilent = TF.setSilent
        defaults = self.perfDefaults

        wasSilent = isSilent()
        setSilent(silent)
        for (k, v) in kwargs.items():
            if k not in defaults:
                error(f&#39;No such performance parameter: &#34;{k}&#34;&#39;, tm=False)
                continue
            if v is None:
                v = defaults[k]
            elif type(v) is not int and k != &#34;yarnRatio&#34;:
                error(
                    f&#39;Performance parameter &#34;{k}&#34; must be set to an integer, not to &#34;{v}&#34;&#39;,
                    tm=False,
                )
                continue
            self.perfParams[k] = v
        info(&#34;Performance parameters, current values:&#34;, tm=False)
        for (k, v) in sorted(self.perfParams.items()):
            info(f&#34;\t{k:&lt;20} = {v:&gt;7}&#34;, tm=False)
        SearchExe.setPerfParams(self.perfParams)
        setSilent(wasSilent)

    def search(
        self,
        searchTemplate,
        limit=None,
        sets=None,
        shallow=False,
        silent=SILENT_D,
        here=True,
        _msgCache=False,
    ):
        &#34;&#34;&#34;Searches for combinations of nodes that together match a search template.

        If you can, you should use `tf.advanced.search.search` instead.

        Parameters
        ----------
        searchTemplate: string
            A string that conforms to the rules described in `tf.about.searchusage`.

        shallow: set | tuple
            If `True` or `1`, the result is a set of things that match the
            top-level element of the `query`.

            If `2` or a bigger number *n*, return the set of truncated result tuples:
            only the first *n* members of each tuple is retained.

            If `False` or `0`, a sorted list of all result tuples will be returned.

        sets: dict
            If not `None`, it should be a dictionary of sets, keyed by a names.

        limit: integer, optional `None`
            If `limit` is a positive number, it will fetch only that many results.
            If it is negative, 0, None, or absent, it will fetch arbitrary many results.

            !!! caution &#34;there is an upper *fail limit* for safety reasons.
                The limit is a factor times the max node in your corpus.
                See `tf.parameters.SEARCH_FAIL_FACTOR`.
                If this *fail limit* is exceeded in cases where no positive `limit`
                has been passed, you get a warning message.

        Returns
        -------
        generator | tuple
            Each result is a tuple of nodes, where each node corresponds to an
            *atom*-line in your search template.about.searchusage`).

            If `limit` is not `None`, a *generator* is returned,
            which yields the results one by one.

            Otherwise, the results will be fetched up till `limit`
            and delivered as a tuple.

        Notes
        -----
        !!! hint &#34;More info on the search plan&#34;
            Searching is complex. The search template must be parsed, interpreted,
            and translated into a search plan. See `tf.search.search.Search.study`.
        &#34;&#34;&#34;

        exe = SearchExe(
            self.api,
            searchTemplate,
            outerTemplate=searchTemplate,
            quKind=None,
            offset=0,
            sets=sets,
            shallow=shallow,
            silent=silent,
            _msgCache=_msgCache,
            setInfo={},
        )
        if here:
            self.exe = exe
        queryResults = exe.search(limit=limit)
        if type(_msgCache) is list:
            messages = wrapMessages(_msgCache)
            self._msgCache = _msgCache
            return (queryResults, messages) if here else (queryResults, messages, exe)
        return queryResults

    def study(
        self,
        searchTemplate,
        strategy=None,
        sets=None,
        shallow=False,
        here=True,
        silent=SILENT_D,
    ):
        &#34;&#34;&#34;Studies a template to prepare for searching with it.

        The search space will be narrowed down and a plan for retrieving the results
        will be set up.

        If the search template query has quantifiers, the asscociated search templates
        will be constructed and executed. These searches will be reported clearly.

        The resulting plan can be viewd by `tf.search.search.Search.showPlan`.

        Parameters
        ----------
        searchTemplate: string
            A string that conforms to the rules described in `tf.about.searchusage`.

        strategy: string
            In order to tame the performance of search, the strategy by which results
            are fetched matters a lot.  The search strategy is an implementation detail,
            but we bring it to the surface nevertheless.

            To see the names of the available strategies, just call
            `S.study(&#39;&#39;, strategy=&#39;x&#39;)` and you will get a list of options reported to
            choose from.

            Feel free to experiment. To see what the strategies do, see the
            code in `tf.search.stitch`.

        shallow: set | tuple
            If `True` or `1`, the result is a set of things that match the
            top-level element of the search template.

            If `2` or a bigger number *n*, return the set of truncated result tuples:
            only the first *n* members of each tuple is retained.

            If `False` or `0`, a sorted list of all result tuples will be returned.

        sets: dict
            If not `None`, it should be a dictionary of sets, keyed by a names.
            In the search template you can refer to those names to invoke those sets.

        silent: string, optional `tf.core.timestamp.SILENT_D`
            See `tf.core.timestamp.Timestamp`

        See Also
        --------
        tf.about.searchusage: Search guide
        &#34;&#34;&#34;

        if silent is False:
            silent = AUTO

        exe = SearchExe(
            self.api,
            searchTemplate,
            outerTemplate=searchTemplate,
            quKind=None,
            offset=0,
            sets=sets,
            shallow=shallow,
            silent=SILENT_D,
            showQuantifiers=True,
            setInfo={},
        )
        if here:
            self.exe = exe
        return exe.study(strategy=strategy)

    def fetch(self, limit=None, _msgCache=False):
        &#34;&#34;&#34;Retrieves query results, up to a limit.

        Must be called after a previous `tf.search.search.Search.search()` or
        `tf.search.search.Search.study()`.

        Parameters
        ----------

        limit: integer, optional `None`
            If `limit` is a positive number, it will fetch only that many results.
            If it is negative, 0, None, or absent, it will fetch arbitrary many results.

            !!! caution &#34;there is an upper *fail limit* for safety reasons.
                The limit is a factor times the max node in your corpus.
                See `tf.parameters.SEARCH_FAIL_FACTOR`.
                If this *fail limit* is exceeded in cases where no positive `limit`
                has been passed, you get a warning message.


        Returns
        -------
        generator | tuple
            Each result is a tuple of nodes, where each node corresponds to an
            *atom*-line in your search template.about.searchusage`).

            If `limit` is not `None`, a *generator* is returned,
            which yields the results one by one.

            Otherwise, the results will be fetched up till `limit`
            and delivered as a tuple.

        Notes
        -----
        !!! example &#34;Iterating over the `fetch()` generator&#34;
            You typically fetch results by saying:

                i = 0
                for tup in S.results():
                    do_something(tup[0])
                    do_something_else(tup[1])

            Alternatively, you can set the `limit` parameter, to ask for just so many
            results. They will be fetched, and when they are all collected,
            returned as a tuple.

        !!! example &#34;Fetching a limited amount of results&#34;
            This

                S.fetch(limit=10)

            gives you the first 10 results without further ado.
        &#34;&#34;&#34;

        exe = self.exe
        TF = self.api.TF

        if exe is None:
            error = TF.error
            error(&#39;Cannot fetch if there is no previous &#34;study()&#34;&#39;)
        else:
            queryResults = exe.fetch(limit=limit)
            if type(_msgCache) is list:
                messages = TF.cache(_asString=True)
                return (queryResults, messages)
            return queryResults

    def count(self, progress=None, limit=None):
        &#34;&#34;&#34;Counts the results, with progress messages, optionally up to a limit.

        Must be called after a previous `tf.search.search.Search.search()` or
        `tf.search.search.Search.study()`.

        Parameters
        ----------
        progress: integer, optional, default `100`
            Every once for every `progress` results a progress message is shown
            when fetching results.

        limit: integer, optional `None`
            If `limit` is a positive number, it will fetch only that many results.
            If it is negative, 0, None, or absent, it will fetch arbitrary many results.

            !!! caution &#34;there is an upper *fail limit* for safety reasons.
                The limit is a factor times the max node in your corpus.
                See `tf.parameters.SEARCH_FAIL_FACTOR`.
                If this *fail limit* is exceeded in cases where no positive `limit`
                has been passed, you get a warning message.

        !!! note &#34;why needed&#34;
            You typically need this in cases where result fetching turns out to
            be (very) slow.

        !!! caution &#34;generator versus list&#34;
            `len(S.results())` does not work in general, because `S.results()` is
            usually a generator that delivers its results as they come.

        Returns
        -------
        None
            The point of this function is to show the counting of the results
            on the screen in a series of timed messages.
        &#34;&#34;&#34;

        exe = self.exe
        if exe is None:
            error = self.api.TF.error
            error(&#39;Cannot count if there is no previous &#34;study()&#34;&#39;)
        else:
            exe.count(progress=progress, limit=limit)

    def showPlan(self, details=False):
        &#34;&#34;&#34;Show the result of the latest study of a template.

        Search results are tuples of nodes and the plan shows which part of the tuple
        corresponds to which part of the search template.

        Only meaningful after a previous `tf.search.search.Search.study`.

        Parameters
        ----------
        details: boolean, optional `False`
            If `True`, more information will be provided:
            an overview of the search space and a description of how the results
            will be retrieved.

        !!! note &#34;after S.study()&#34;
            This function is only meaningful after a call to `S.study()`.
        &#34;&#34;&#34;

        exe = self.exe
        if exe is None:
            error = self.api.TF.error
            error(&#39;Cannot show plan if there is no previous &#34;study()&#34;&#39;)
        else:
            exe.showPlan(details=details)

    def relationsLegend(self):
        &#34;&#34;&#34;Dynamic info about the basic relations that can be used in templates.

        It includes the edge features that are available in your dataset.

        Returns
        -------
        None
            The legend will be shown in the output.
        &#34;&#34;&#34;

        exe = self.exe
        if exe is None:
            exe = SearchExe(self.api, &#34;&#34;)
        console(exe.relationLegend)

    def glean(self, tup):
        &#34;&#34;&#34;Renders a single result into something human readable.

        A search result is just a tuple of nodes that correspond to your template, as
        indicated by `showPlan()`. Nodes give you access to all information that the
        corpus has about it.

        This function is meant to just give you a quick first impression.

        Parameters
        ----------
        tup: tuple of int
            The tuple of nodes in question.

        Returns
        -------
        string
            The result indicats where the tuple occurs in terms of sections,
            and what text is associated with the tuple.

        Notes
        -----
        !!! example &#34;Inspecting results&#34;
            This

                for result in S.fetch(limit=10):
                    TF.info(S.glean(result))

            is a handy way to get an impression of the first bunch of results.

        !!! hint &#34;Universal&#34;
            This function works on all tuples of nodes, whether they have been
            obtained by search or not.

        !!! hint &#34;More ways of showing results&#34;
            The advanced API offers much better ways of showing results.
            See `tf.advanced.display.show` and `tf.advanced.display.table`.
        &#34;&#34;&#34;

        T = self.api.T
        F = self.api.F
        E = self.api.E
        fOtype = F.otype.v
        slotType = F.otype.slotType
        maxSlot = F.otype.maxSlot
        eoslots = E.oslots.data

        lR = len(tup)
        if lR == 0:
            return &#34;&#34;
        fields = []
        for (i, n) in enumerate(tup):
            otype = fOtype(n)
            words = [n] if otype == slotType else eoslots[n - maxSlot - 1]
            if otype == T.sectionTypes[2]:
                field = &#34;{} {}:{}&#34;.format(*T.sectionFromNode(n))
            elif otype == slotType:
                field = T.text(words)
            elif otype in T.sectionTypes[0:2]:
                field = &#34;&#34;
            else:
                field = &#34;{}[{}{}]&#34;.format(
                    otype,
                    T.text(words[0:5]),
                    &#34;...&#34; if len(words) &gt; 5 else &#34;&#34;,
                )
            fields.append(field)
        return &#34; &#34;.join(fields)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="tf.search.search.Search.count"><code class="name flex">
<span>def <span class="ident">count</span></span>(<span>self, progress=None, limit=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Counts the results, with progress messages, optionally up to a limit.</p>
<p>Must be called after a previous <code><a title="tf.search.search.Search.search" href="#tf.search.search.Search.search">Search.search()</a></code> or
<code><a title="tf.search.search.Search.study" href="#tf.search.search.Search.study">Search.study()</a></code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>progress</code></strong> :&ensp;<code>integer</code>, optional, default <code>100</code></dt>
<dd>Every once for every <code>progress</code> results a progress message is shown
when fetching results.</dd>
<dt><strong><code>limit</code></strong> :&ensp;<code>integer</code>, optional <code>None</code></dt>
<dd>
<p>If <code>limit</code> is a positive number, it will fetch only that many results.
If it is negative, 0, None, or absent, it will fetch arbitrary many results.</p>
<p>!!! caution "there is an upper <em>fail limit</em> for safety reasons.
The limit is a factor times the max node in your corpus.
See <code><a title="tf.parameters.SEARCH_FAIL_FACTOR" href="../parameters.html#tf.parameters.SEARCH_FAIL_FACTOR">SEARCH_FAIL_FACTOR</a></code>.
If this <em>fail limit</em> is exceeded in cases where no positive <code>limit</code>
has been passed, you get a warning message.</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">why needed</p>
<p>You typically need this in cases where result fetching turns out to
be (very) slow.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">generator versus list</p>
<p><code>len(S.results())</code> does not work in general, because <code>S.results()</code> is
usually a generator that delivers its results as they come.</p>
</div>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>The point of this function is to show the counting of the results
on the screen in a series of timed messages.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric/blob/5760b670709c4be44256e51cdeea8af5d464ae31/tf/search/search.py#L391-L433" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def count(self, progress=None, limit=None):
    &#34;&#34;&#34;Counts the results, with progress messages, optionally up to a limit.

    Must be called after a previous `tf.search.search.Search.search()` or
    `tf.search.search.Search.study()`.

    Parameters
    ----------
    progress: integer, optional, default `100`
        Every once for every `progress` results a progress message is shown
        when fetching results.

    limit: integer, optional `None`
        If `limit` is a positive number, it will fetch only that many results.
        If it is negative, 0, None, or absent, it will fetch arbitrary many results.

        !!! caution &#34;there is an upper *fail limit* for safety reasons.
            The limit is a factor times the max node in your corpus.
            See `tf.parameters.SEARCH_FAIL_FACTOR`.
            If this *fail limit* is exceeded in cases where no positive `limit`
            has been passed, you get a warning message.

    !!! note &#34;why needed&#34;
        You typically need this in cases where result fetching turns out to
        be (very) slow.

    !!! caution &#34;generator versus list&#34;
        `len(S.results())` does not work in general, because `S.results()` is
        usually a generator that delivers its results as they come.

    Returns
    -------
    None
        The point of this function is to show the counting of the results
        on the screen in a series of timed messages.
    &#34;&#34;&#34;

    exe = self.exe
    if exe is None:
        error = self.api.TF.error
        error(&#39;Cannot count if there is no previous &#34;study()&#34;&#39;)
    else:
        exe.count(progress=progress, limit=limit)</code></pre>
</details>
</dd>
<dt id="tf.search.search.Search.fetch"><code class="name flex">
<span>def <span class="ident">fetch</span></span>(<span>self, limit=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Retrieves query results, up to a limit.</p>
<p>Must be called after a previous <code><a title="tf.search.search.Search.search" href="#tf.search.search.Search.search">Search.search()</a></code> or
<code><a title="tf.search.search.Search.study" href="#tf.search.search.Search.study">Search.study()</a></code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>limit</code></strong> :&ensp;<code>integer</code>, optional <code>None</code></dt>
<dd>
<p>If <code>limit</code> is a positive number, it will fetch only that many results.
If it is negative, 0, None, or absent, it will fetch arbitrary many results.</p>
<p>!!! caution "there is an upper <em>fail limit</em> for safety reasons.
The limit is a factor times the max node in your corpus.
See <code><a title="tf.parameters.SEARCH_FAIL_FACTOR" href="../parameters.html#tf.parameters.SEARCH_FAIL_FACTOR">SEARCH_FAIL_FACTOR</a></code>.
If this <em>fail limit</em> is exceeded in cases where no positive <code>limit</code>
has been passed, you get a warning message.</p>
</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>generator | tuple</code></dt>
<dd>
<p>Each result is a tuple of nodes, where each node corresponds to an
<em>atom</em>-line in your search template.about.searchusage`).</p>
<p>If <code>limit</code> is not <code>None</code>, a <em>generator</em> is returned,
which yields the results one by one.</p>
<p>Otherwise, the results will be fetched up till <code>limit</code>
and delivered as a tuple.</p>
</dd>
</dl>
<h2 id="notes">Notes</h2>
<div class="admonition example">
<p class="admonition-title">Iterating over the <code>fetch()</code> generator</p>
<p>You typically fetch results by saying:</p>
<pre><code>i = 0
for tup in S.results():
    do_something(tup[0])
    do_something_else(tup[1])
</code></pre>
<p>Alternatively, you can set the <code>limit</code> parameter, to ask for just so many
results. They will be fetched, and when they are all collected,
returned as a tuple.</p>
</div>
<div class="admonition example">
<p class="admonition-title">Fetching a limited amount of results</p>
<p>This</p>
<pre><code>S.fetch(limit=10)
</code></pre>
<p>gives you the first 10 results without further ado.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric/blob/5760b670709c4be44256e51cdeea8af5d464ae31/tf/search/search.py#L324-L389" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def fetch(self, limit=None, _msgCache=False):
    &#34;&#34;&#34;Retrieves query results, up to a limit.

    Must be called after a previous `tf.search.search.Search.search()` or
    `tf.search.search.Search.study()`.

    Parameters
    ----------

    limit: integer, optional `None`
        If `limit` is a positive number, it will fetch only that many results.
        If it is negative, 0, None, or absent, it will fetch arbitrary many results.

        !!! caution &#34;there is an upper *fail limit* for safety reasons.
            The limit is a factor times the max node in your corpus.
            See `tf.parameters.SEARCH_FAIL_FACTOR`.
            If this *fail limit* is exceeded in cases where no positive `limit`
            has been passed, you get a warning message.


    Returns
    -------
    generator | tuple
        Each result is a tuple of nodes, where each node corresponds to an
        *atom*-line in your search template.about.searchusage`).

        If `limit` is not `None`, a *generator* is returned,
        which yields the results one by one.

        Otherwise, the results will be fetched up till `limit`
        and delivered as a tuple.

    Notes
    -----
    !!! example &#34;Iterating over the `fetch()` generator&#34;
        You typically fetch results by saying:

            i = 0
            for tup in S.results():
                do_something(tup[0])
                do_something_else(tup[1])

        Alternatively, you can set the `limit` parameter, to ask for just so many
        results. They will be fetched, and when they are all collected,
        returned as a tuple.

    !!! example &#34;Fetching a limited amount of results&#34;
        This

            S.fetch(limit=10)

        gives you the first 10 results without further ado.
    &#34;&#34;&#34;

    exe = self.exe
    TF = self.api.TF

    if exe is None:
        error = TF.error
        error(&#39;Cannot fetch if there is no previous &#34;study()&#34;&#39;)
    else:
        queryResults = exe.fetch(limit=limit)
        if type(_msgCache) is list:
            messages = TF.cache(_asString=True)
            return (queryResults, messages)
        return queryResults</code></pre>
</details>
</dd>
<dt id="tf.search.search.Search.glean"><code class="name flex">
<span>def <span class="ident">glean</span></span>(<span>self, tup)</span>
</code></dt>
<dd>
<div class="desc"><p>Renders a single result into something human readable.</p>
<p>A search result is just a tuple of nodes that correspond to your template, as
indicated by <code>showPlan()</code>. Nodes give you access to all information that the
corpus has about it.</p>
<p>This function is meant to just give you a quick first impression.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tup</code></strong> :&ensp;<code>tuple</code> of <code>int</code></dt>
<dd>The tuple of nodes in question.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>string</code></dt>
<dd>The result indicats where the tuple occurs in terms of sections,
and what text is associated with the tuple.</dd>
</dl>
<h2 id="notes">Notes</h2>
<div class="admonition example">
<p class="admonition-title">Inspecting results</p>
<p>This</p>
<pre><code>for result in S.fetch(limit=10):
    TF.info(S.glean(result))
</code></pre>
<p>is a handy way to get an impression of the first bunch of results.</p>
</div>
<div class="admonition hint">
<p class="admonition-title">Universal</p>
<p>This function works on all tuples of nodes, whether they have been
obtained by search or not.</p>
</div>
<div class="admonition hint">
<p class="admonition-title">More ways of showing results</p>
<p>The advanced API offers much better ways of showing results.
See <code><a title="tf.advanced.display.show" href="../advanced/display.html#tf.advanced.display.show">show()</a></code> and <code><a title="tf.advanced.display.table" href="../advanced/display.html#tf.advanced.display.table">table()</a></code>.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric/blob/5760b670709c4be44256e51cdeea8af5d464ae31/tf/search/search.py#L477-L544" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def glean(self, tup):
    &#34;&#34;&#34;Renders a single result into something human readable.

    A search result is just a tuple of nodes that correspond to your template, as
    indicated by `showPlan()`. Nodes give you access to all information that the
    corpus has about it.

    This function is meant to just give you a quick first impression.

    Parameters
    ----------
    tup: tuple of int
        The tuple of nodes in question.

    Returns
    -------
    string
        The result indicats where the tuple occurs in terms of sections,
        and what text is associated with the tuple.

    Notes
    -----
    !!! example &#34;Inspecting results&#34;
        This

            for result in S.fetch(limit=10):
                TF.info(S.glean(result))

        is a handy way to get an impression of the first bunch of results.

    !!! hint &#34;Universal&#34;
        This function works on all tuples of nodes, whether they have been
        obtained by search or not.

    !!! hint &#34;More ways of showing results&#34;
        The advanced API offers much better ways of showing results.
        See `tf.advanced.display.show` and `tf.advanced.display.table`.
    &#34;&#34;&#34;

    T = self.api.T
    F = self.api.F
    E = self.api.E
    fOtype = F.otype.v
    slotType = F.otype.slotType
    maxSlot = F.otype.maxSlot
    eoslots = E.oslots.data

    lR = len(tup)
    if lR == 0:
        return &#34;&#34;
    fields = []
    for (i, n) in enumerate(tup):
        otype = fOtype(n)
        words = [n] if otype == slotType else eoslots[n - maxSlot - 1]
        if otype == T.sectionTypes[2]:
            field = &#34;{} {}:{}&#34;.format(*T.sectionFromNode(n))
        elif otype == slotType:
            field = T.text(words)
        elif otype in T.sectionTypes[0:2]:
            field = &#34;&#34;
        else:
            field = &#34;{}[{}{}]&#34;.format(
                otype,
                T.text(words[0:5]),
                &#34;...&#34; if len(words) &gt; 5 else &#34;&#34;,
            )
        fields.append(field)
    return &#34; &#34;.join(fields)</code></pre>
</details>
</dd>
<dt id="tf.search.search.Search.relationsLegend"><code class="name flex">
<span>def <span class="ident">relationsLegend</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Dynamic info about the basic relations that can be used in templates.</p>
<p>It includes the edge features that are available in your dataset.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>The legend will be shown in the output.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric/blob/5760b670709c4be44256e51cdeea8af5d464ae31/tf/search/search.py#L461-L475" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def relationsLegend(self):
    &#34;&#34;&#34;Dynamic info about the basic relations that can be used in templates.

    It includes the edge features that are available in your dataset.

    Returns
    -------
    None
        The legend will be shown in the output.
    &#34;&#34;&#34;

    exe = self.exe
    if exe is None:
        exe = SearchExe(self.api, &#34;&#34;)
    console(exe.relationLegend)</code></pre>
</details>
</dd>
<dt id="tf.search.search.Search.search"><code class="name flex">
<span>def <span class="ident">search</span></span>(<span>self, searchTemplate, limit=None, sets=None, shallow=False, silent='terse', here=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Searches for combinations of nodes that together match a search template.</p>
<p>If you can, you should use <code><a title="tf.advanced.search.search" href="../advanced/search.html#tf.advanced.search.search">search()</a></code> instead.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>searchTemplate</code></strong> :&ensp;<code>string</code></dt>
<dd>A string that conforms to the rules described in <code><a title="tf.about.searchusage" href="../about/searchusage.html">tf.about.searchusage</a></code>.</dd>
<dt><strong><code>shallow</code></strong> :&ensp;<code>set | tuple</code></dt>
<dd>
<p>If <code>True</code> or <code>1</code>, the result is a set of things that match the
top-level element of the <code>query</code>.</p>
<p>If <code>2</code> or a bigger number <em>n</em>, return the set of truncated result tuples:
only the first <em>n</em> members of each tuple is retained.</p>
<p>If <code>False</code> or <code>0</code>, a sorted list of all result tuples will be returned.</p>
</dd>
<dt><strong><code>sets</code></strong> :&ensp;<code>dict</code></dt>
<dd>If not <code>None</code>, it should be a dictionary of sets, keyed by a names.</dd>
<dt><strong><code>limit</code></strong> :&ensp;<code>integer</code>, optional <code>None</code></dt>
<dd>
<p>If <code>limit</code> is a positive number, it will fetch only that many results.
If it is negative, 0, None, or absent, it will fetch arbitrary many results.</p>
<p>!!! caution "there is an upper <em>fail limit</em> for safety reasons.
The limit is a factor times the max node in your corpus.
See <code><a title="tf.parameters.SEARCH_FAIL_FACTOR" href="../parameters.html#tf.parameters.SEARCH_FAIL_FACTOR">SEARCH_FAIL_FACTOR</a></code>.
If this <em>fail limit</em> is exceeded in cases where no positive <code>limit</code>
has been passed, you get a warning message.</p>
</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>generator | tuple</code></dt>
<dd>
<p>Each result is a tuple of nodes, where each node corresponds to an
<em>atom</em>-line in your search template.about.searchusage`).</p>
<p>If <code>limit</code> is not <code>None</code>, a <em>generator</em> is returned,
which yields the results one by one.</p>
<p>Otherwise, the results will be fetched up till <code>limit</code>
and delivered as a tuple.</p>
</dd>
</dl>
<h2 id="notes">Notes</h2>
<div class="admonition hint">
<p class="admonition-title">More info on the search plan</p>
<p>Searching is complex. The search template must be parsed, interpreted,
and translated into a search plan. See <code><a title="tf.search.search.Search.study" href="#tf.search.search.Search.study">Search.study()</a></code>.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric/blob/5760b670709c4be44256e51cdeea8af5d464ae31/tf/search/search.py#L167-L246" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def search(
    self,
    searchTemplate,
    limit=None,
    sets=None,
    shallow=False,
    silent=SILENT_D,
    here=True,
    _msgCache=False,
):
    &#34;&#34;&#34;Searches for combinations of nodes that together match a search template.

    If you can, you should use `tf.advanced.search.search` instead.

    Parameters
    ----------
    searchTemplate: string
        A string that conforms to the rules described in `tf.about.searchusage`.

    shallow: set | tuple
        If `True` or `1`, the result is a set of things that match the
        top-level element of the `query`.

        If `2` or a bigger number *n*, return the set of truncated result tuples:
        only the first *n* members of each tuple is retained.

        If `False` or `0`, a sorted list of all result tuples will be returned.

    sets: dict
        If not `None`, it should be a dictionary of sets, keyed by a names.

    limit: integer, optional `None`
        If `limit` is a positive number, it will fetch only that many results.
        If it is negative, 0, None, or absent, it will fetch arbitrary many results.

        !!! caution &#34;there is an upper *fail limit* for safety reasons.
            The limit is a factor times the max node in your corpus.
            See `tf.parameters.SEARCH_FAIL_FACTOR`.
            If this *fail limit* is exceeded in cases where no positive `limit`
            has been passed, you get a warning message.

    Returns
    -------
    generator | tuple
        Each result is a tuple of nodes, where each node corresponds to an
        *atom*-line in your search template.about.searchusage`).

        If `limit` is not `None`, a *generator* is returned,
        which yields the results one by one.

        Otherwise, the results will be fetched up till `limit`
        and delivered as a tuple.

    Notes
    -----
    !!! hint &#34;More info on the search plan&#34;
        Searching is complex. The search template must be parsed, interpreted,
        and translated into a search plan. See `tf.search.search.Search.study`.
    &#34;&#34;&#34;

    exe = SearchExe(
        self.api,
        searchTemplate,
        outerTemplate=searchTemplate,
        quKind=None,
        offset=0,
        sets=sets,
        shallow=shallow,
        silent=silent,
        _msgCache=_msgCache,
        setInfo={},
    )
    if here:
        self.exe = exe
    queryResults = exe.search(limit=limit)
    if type(_msgCache) is list:
        messages = wrapMessages(_msgCache)
        self._msgCache = _msgCache
        return (queryResults, messages) if here else (queryResults, messages, exe)
    return queryResults</code></pre>
</details>
</dd>
<dt id="tf.search.search.Search.showPlan"><code class="name flex">
<span>def <span class="ident">showPlan</span></span>(<span>self, details=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Show the result of the latest study of a template.</p>
<p>Search results are tuples of nodes and the plan shows which part of the tuple
corresponds to which part of the search template.</p>
<p>Only meaningful after a previous <code><a title="tf.search.search.Search.study" href="#tf.search.search.Search.study">Search.study()</a></code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>details</code></strong> :&ensp;<code>boolean</code>, optional <code>False</code></dt>
<dd>If <code>True</code>, more information will be provided:
an overview of the search space and a description of how the results
will be retrieved.</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">after S.study()</p>
<p>This function is only meaningful after a call to <code>S.study()</code>.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric/blob/5760b670709c4be44256e51cdeea8af5d464ae31/tf/search/search.py#L435-L459" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def showPlan(self, details=False):
    &#34;&#34;&#34;Show the result of the latest study of a template.

    Search results are tuples of nodes and the plan shows which part of the tuple
    corresponds to which part of the search template.

    Only meaningful after a previous `tf.search.search.Search.study`.

    Parameters
    ----------
    details: boolean, optional `False`
        If `True`, more information will be provided:
        an overview of the search space and a description of how the results
        will be retrieved.

    !!! note &#34;after S.study()&#34;
        This function is only meaningful after a call to `S.study()`.
    &#34;&#34;&#34;

    exe = self.exe
    if exe is None:
        error = self.api.TF.error
        error(&#39;Cannot show plan if there is no previous &#34;study()&#34;&#39;)
    else:
        exe.showPlan(details=details)</code></pre>
</details>
</dd>
<dt id="tf.search.search.Search.study"><code class="name flex">
<span>def <span class="ident">study</span></span>(<span>self, searchTemplate, strategy=None, sets=None, shallow=False, here=True, silent='terse')</span>
</code></dt>
<dd>
<div class="desc"><p>Studies a template to prepare for searching with it.</p>
<p>The search space will be narrowed down and a plan for retrieving the results
will be set up.</p>
<p>If the search template query has quantifiers, the asscociated search templates
will be constructed and executed. These searches will be reported clearly.</p>
<p>The resulting plan can be viewd by <code><a title="tf.search.search.Search.showPlan" href="#tf.search.search.Search.showPlan">Search.showPlan()</a></code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>searchTemplate</code></strong> :&ensp;<code>string</code></dt>
<dd>A string that conforms to the rules described in <code><a title="tf.about.searchusage" href="../about/searchusage.html">tf.about.searchusage</a></code>.</dd>
<dt><strong><code>strategy</code></strong> :&ensp;<code>string</code></dt>
<dd>
<p>In order to tame the performance of search, the strategy by which results
are fetched matters a lot.
The search strategy is an implementation detail,
but we bring it to the surface nevertheless.</p>
<p>To see the names of the available strategies, just call
<code>S.study('', strategy='x')</code> and you will get a list of options reported to
choose from.</p>
<p>Feel free to experiment. To see what the strategies do, see the
code in <code><a title="tf.search.stitch" href="stitch.html">tf.search.stitch</a></code>.</p>
</dd>
<dt><strong><code>shallow</code></strong> :&ensp;<code>set | tuple</code></dt>
<dd>
<p>If <code>True</code> or <code>1</code>, the result is a set of things that match the
top-level element of the search template.</p>
<p>If <code>2</code> or a bigger number <em>n</em>, return the set of truncated result tuples:
only the first <em>n</em> members of each tuple is retained.</p>
<p>If <code>False</code> or <code>0</code>, a sorted list of all result tuples will be returned.</p>
</dd>
<dt><strong><code>sets</code></strong> :&ensp;<code>dict</code></dt>
<dd>If not <code>None</code>, it should be a dictionary of sets, keyed by a names.
In the search template you can refer to those names to invoke those sets.</dd>
<dt><strong><code>silent</code></strong> :&ensp;<code>string</code>, optional <code><a title="tf.core.timestamp.SILENT_D" href="../core/timestamp.html#tf.core.timestamp.SILENT_D">SILENT_D</a></code></dt>
<dd>See <code><a title="tf.core.timestamp.Timestamp" href="../core/timestamp.html#tf.core.timestamp.Timestamp">Timestamp</a></code></dd>
</dl>
<h2 id="see-also">See Also</h2>
<dl>
<dt><code><a title="tf.about.searchusage" href="../about/searchusage.html">tf.about.searchusage</a></code></dt>
<dd>Search guide</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric/blob/5760b670709c4be44256e51cdeea8af5d464ae31/tf/search/search.py#L248-L322" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def study(
    self,
    searchTemplate,
    strategy=None,
    sets=None,
    shallow=False,
    here=True,
    silent=SILENT_D,
):
    &#34;&#34;&#34;Studies a template to prepare for searching with it.

    The search space will be narrowed down and a plan for retrieving the results
    will be set up.

    If the search template query has quantifiers, the asscociated search templates
    will be constructed and executed. These searches will be reported clearly.

    The resulting plan can be viewd by `tf.search.search.Search.showPlan`.

    Parameters
    ----------
    searchTemplate: string
        A string that conforms to the rules described in `tf.about.searchusage`.

    strategy: string
        In order to tame the performance of search, the strategy by which results
        are fetched matters a lot.  The search strategy is an implementation detail,
        but we bring it to the surface nevertheless.

        To see the names of the available strategies, just call
        `S.study(&#39;&#39;, strategy=&#39;x&#39;)` and you will get a list of options reported to
        choose from.

        Feel free to experiment. To see what the strategies do, see the
        code in `tf.search.stitch`.

    shallow: set | tuple
        If `True` or `1`, the result is a set of things that match the
        top-level element of the search template.

        If `2` or a bigger number *n*, return the set of truncated result tuples:
        only the first *n* members of each tuple is retained.

        If `False` or `0`, a sorted list of all result tuples will be returned.

    sets: dict
        If not `None`, it should be a dictionary of sets, keyed by a names.
        In the search template you can refer to those names to invoke those sets.

    silent: string, optional `tf.core.timestamp.SILENT_D`
        See `tf.core.timestamp.Timestamp`

    See Also
    --------
    tf.about.searchusage: Search guide
    &#34;&#34;&#34;

    if silent is False:
        silent = AUTO

    exe = SearchExe(
        self.api,
        searchTemplate,
        outerTemplate=searchTemplate,
        quKind=None,
        offset=0,
        sets=sets,
        shallow=shallow,
        silent=SILENT_D,
        showQuantifiers=True,
        setInfo={},
    )
    if here:
        self.exe = exe
    return exe.study(strategy=strategy)</code></pre>
</details>
</dd>
<dt id="tf.search.search.Search.tweakPerformance"><code class="name flex">
<span>def <span class="ident">tweakPerformance</span></span>(<span>self, silent='terse', **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Tweak parameters that influence the search process.</p>
<div class="admonition explanation">
<p class="admonition-title">Theory</p>
<p>Before the search engine retrieves result tuples of nodes,
there is a process to narrow down the search space.</p>
<p>See <code><a title="tf.about.searchdesign" href="../about/searchdesign.html">tf.about.searchdesign</a></code> and and remember that we use the term <em>yarn</em> for
the sets of candidate nodes from which we stitch our results together.</p>
<p><em>Edge spinning</em> is the process of
transferring constraints on one node via edges to constraints on
another node. The one node lives in a yarn, i.e. a set of candidate nodes,
and the node at the other side of the edge lives in a yarn.</p>
<p>If the first yarn is small then we might be able to reduce the second yarn
by computing the counterparts of the nodes in the small yarn in the second
yarn. We can leave out all other nodes from the second yarn.
A big reduction!</p>
<p>The success of edge spinning depends mainly on two factors:</p>
<div class="admonition info">
<p class="admonition-title">Size difference</p>
<p>Edge spinning works best if there is a big difference in size
between the candidate
sets for the nodes at both sides of an edge.</p>
</div>
<div class="admonition info">
<p class="admonition-title">Spread</p>
<p>The spread of a relation is the number of different edges
that can start from the same node or end at the same node.</p>
<p>For example, the spread of the <code>equality</code> operator is just 1, but
the spread of the <code>inequality</code> operator is virtually as big
as the relevant yarn.</p>
<p>If there are constraints on a node in one yarn, and if there is an edge
between that yarn and another one, and if the spread is big,
not much of the constraint can be transferred to the other yarn.</p>
</div>
<div class="admonition example">
<p class="admonition-title">Example</p>
<p>Suppose both yarns are words, the first yarn has been constrained
to verbs, and the equality relation holds must hold between the yarns.
Then in all results the node from the second yarn is also a verb.
So we can constrain the second yarn to verbs too.</p>
<p>But if the relation is inequality, we cannot impose any additional
restriction on nodes in the second yarn. All nodes in the second
yarn are unequal to at least one verb.</p>
</div>
<div class="admonition info">
<p class="admonition-title">Estimating the spread</p>
<p>We estimate the spreads of edges over and over again, in a series
of iterations where we reduce yarns.</p>
<p>An exhaustive computation would be too expensive, so we take
a sample of a limited amount of relation computations.</p>
</div>
</div>
<p>If you do not pass a parameter, its value will not be changed.
If you pass <code>None</code> for a parameter, its value will be reset to the default value.</p>
<p>Here are the parameters that you can tweak:</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>yarnRatio</code></strong> :&ensp;<code>float</code></dt>
<dd>
<p>The <code>yarnRatio</code> is the minimal factor between the sizes of
the smallest and the biggest set of candidates of the nodes at both ends of
the edge. And that divided by the spread of the relation as estimated
by a sample.</p>
<div class="admonition example">
<p class="admonition-title">Example</p>
<p>Suppose we set the yarnRatio to 1.5.
Then, if we have yarns of 100,000 and 10,000 members,
with a relation between them with spread 5,
then 100,000 / 10,000 / 5 = 2.
This is higher than the yarnRatio of 1.5,
so the search engine decides that edge spinning is worth it.</p>
<p>The reasoning is that the 10,000 nodes in the smallest yarn are expected
to reach only 10,000 * 5 nodes in the other yarn by the relation,
and so we can achieve a significant reduction.</p>
</div>
<p>If you have a very slow query, and you think that a bit more edge spinning
helps, decrease the yarnRatio towards 0.</p>
<p>If you find that a lot of queries spend too much time in edge spinning,
increase the yarnRatio.</p>
</dd>
<dt><strong><code>tryLimitFrom</code></strong> :&ensp;<code>integer</code></dt>
<dd>
<p>In order to determine the spreads of the relations, TF takes
random samples and extrapolates the results. We grab some nodes
from the set at the <em>from</em> side of an edge, and some nodes at the
<em>to</em> side of the same edge, Then we compute in how many cases the relation
holds. That is a measure for the spread.</p>
<p>The parameters <code>tryLimitFrom</code> and <code>tryLimitTo</code> dictate how big these
samples are. The bigger, the better the estimation of the spread.
But also the more work it is.</p>
<p>If you find that your queries take consistently a tad too much time,
consider lowering these parameters to 10.</p>
<p>If you find that the times your queries take varies a lot,
increase these values to 10000.</p>
</dd>
<dt><strong><code>tryLimitTo</code></strong> :&ensp;<code>integer</code></dt>
<dd>See <code>tryLimitFrom</code></dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric/blob/5760b670709c4be44256e51cdeea8af5d464ae31/tf/search/search.py#L28-L165" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def tweakPerformance(self, silent=SILENT_D, **kwargs):
    &#34;&#34;&#34;Tweak parameters that influence the search process.

    !!! explanation &#34;Theory&#34;
        Before the search engine retrieves result tuples of nodes,
        there is a process to narrow down the search space.

        See `tf.about.searchdesign` and and remember that we use the term *yarn* for
        the sets of candidate nodes from which we stitch our results together.

        *Edge spinning* is the process of
        transferring constraints on one node via edges to constraints on
        another node. The one node lives in a yarn, i.e. a set of candidate nodes,
        and the node at the other side of the edge lives in a yarn.

        If the first yarn is small then we might be able to reduce the second yarn
        by computing the counterparts of the nodes in the small yarn in the second
        yarn. We can leave out all other nodes from the second yarn.
        A big reduction!

        The success of edge spinning depends mainly on two factors:

        !!! info &#34;Size difference&#34;
            Edge spinning works best if there is a big difference in size
            between the candidate
            sets for the nodes at both sides of an edge.

        !!! info &#34;Spread&#34;
            The spread of a relation is the number of different edges
            that can start from the same node or end at the same node.

            For example, the spread of the `equality` operator is just 1, but
            the spread of the `inequality` operator is virtually as big
            as the relevant yarn.

            If there are constraints on a node in one yarn, and if there is an edge
            between that yarn and another one, and if the spread is big,
            not much of the constraint can be transferred to the other yarn.

        !!! example &#34;Example&#34;
            Suppose both yarns are words, the first yarn has been constrained
            to verbs, and the equality relation holds must hold between the yarns.
            Then in all results the node from the second yarn is also a verb.
            So we can constrain the second yarn to verbs too.

            But if the relation is inequality, we cannot impose any additional
            restriction on nodes in the second yarn. All nodes in the second
            yarn are unequal to at least one verb.

        !!! info &#34;Estimating the spread&#34;
            We estimate the spreads of edges over and over again, in a series
            of iterations where we reduce yarns.

            An exhaustive computation would be too expensive, so we take
            a sample of a limited amount of relation computations.


    If you do not pass a parameter, its value will not be changed.
    If you pass `None` for a parameter, its value will be reset to the default value.

    Here are the parameters that you can tweak:

    Parameters
    ----------

    yarnRatio: float
        The `yarnRatio` is the minimal factor between the sizes of
        the smallest and the biggest set of candidates of the nodes at both ends of
        the edge. And that divided by the spread of the relation as estimated
        by a sample.

        !!! example &#34;Example&#34;
            Suppose we set the yarnRatio to 1.5.
            Then, if we have yarns of 100,000 and 10,000 members,
            with a relation between them with spread 5,
            then 100,000 / 10,000 / 5 = 2.
            This is higher than the yarnRatio of 1.5,
            so the search engine decides that edge spinning is worth it.

            The reasoning is that the 10,000 nodes in the smallest yarn are expected
            to reach only 10,000 * 5 nodes in the other yarn by the relation,
            and so we can achieve a significant reduction.

        If you have a very slow query, and you think that a bit more edge spinning
        helps, decrease the yarnRatio towards 0.

        If you find that a lot of queries spend too much time in edge spinning,
        increase the yarnRatio.

    tryLimitFrom: integer
        In order to determine the spreads of the relations, TF takes
        random samples and extrapolates the results. We grab some nodes
        from the set at the *from* side of an edge, and some nodes at the
        *to* side of the same edge, Then we compute in how many cases the relation
        holds. That is a measure for the spread.

        The parameters `tryLimitFrom` and `tryLimitTo` dictate how big these
        samples are. The bigger, the better the estimation of the spread.
        But also the more work it is.

        If you find that your queries take consistently a tad too much time,
        consider lowering these parameters to 10.

        If you find that the times your queries take varies a lot,
        increase these values to 10000.
    tryLimitTo: integer
        See `tryLimitFrom`
    &#34;&#34;&#34;

    silent = silentConvert(silent)
    api = self.api
    TF = api.TF
    error = TF.error
    info = TF.info
    isSilent = TF.isSilent
    setSilent = TF.setSilent
    defaults = self.perfDefaults

    wasSilent = isSilent()
    setSilent(silent)
    for (k, v) in kwargs.items():
        if k not in defaults:
            error(f&#39;No such performance parameter: &#34;{k}&#34;&#39;, tm=False)
            continue
        if v is None:
            v = defaults[k]
        elif type(v) is not int and k != &#34;yarnRatio&#34;:
            error(
                f&#39;Performance parameter &#34;{k}&#34; must be set to an integer, not to &#34;{v}&#34;&#39;,
                tm=False,
            )
            continue
        self.perfParams[k] = v
    info(&#34;Performance parameters, current values:&#34;, tm=False)
    for (k, v) in sorted(self.perfParams.items()):
        info(f&#34;\t{k:&lt;20} = {v:&gt;7}&#34;, tm=False)
    SearchExe.setPerfParams(self.perfParams)
    setSilent(wasSilent)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<p><a href="https://github.com/annotation" title="annotation on GitHub"><img src="../../tf/images/tf-small.png" alt="annotation"></a></p>
<p><a href="../../tf/index.html">tf home</a> -
<a href="../../tf/cheatsheet.html">cheat sheet</a> -
<a href="https://github.com/annotation/text-fabric" title="GitHub repo"><img src="../../tf/images/GitHub_Logo.png" alt="GitHub" width="50"></a></p>
</p>
<form>
<input id="lunr-search" name="q" placeholder=" Search ..." aria-label="Search"
disabled minlength="2">
</form>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/tingle/0.15.3/tingle.min.css" integrity="sha512-j1u8eUJ4f23xPPxwOrLUPQaCD2dwzNqqmDDcWS4deWsMv2ohLqmXXuP3hU7g8TyzbMSakP/mMqoNBYWj8AEIFg==" crossorigin>
<script src="https://cdnjs.cloudflare.com/ajax/libs/tingle/0.15.3/tingle.min.js" integrity="sha512-plGUER9JkeEWPPqQBE4sdLqBoQug5Ap+BCGMc7bJ8BXkm+VVj6QzkpBz5Yv2yPkkq+cqg9IpkBaGCas6uDbW8g==" crossorigin></script>
<style>
.modal-dialog iframe {
width: 100vw;
height: calc(100vh - 80px);
}
@media screen and (min-width: 700px) {
.modal-dialog iframe {
width: 70vw;
height: 80vh;
}
}
.modal-dialog .tingle-modal-box {width: auto;}
.modal-dialog .tingle-modal-box__content {padding: 0;}
</style>
<script>
const input = document.getElementById('lunr-search');
input.disabled = false;
input.form.addEventListener('submit', (ev) => {
ev.preventDefault();
const url = new URL(window.location);
url.searchParams.set('q', input.value);
history.replaceState({}, null, url.toString());
search(input.value);
});
const query = new URL(window.location).searchParams.get('q');
if (query)
search(query);
function search(query) {
const url = '../../doc-search.html#' + encodeURIComponent(query);
new tingle.modal({
cssClass: ['modal-dialog'],
onClose: () => {
const url = new URL(window.location);
url.searchParams.delete('q');
history.replaceState({}, null, url.toString());
setTimeout(() => input.focus(), 100);
}
}).setContent('<iframe src="' + url + '"></iframe>').open();
}
</script>
<h1>Index</h1>
<div class="toc">
<ul>
<li><a href="#search-top-level">Search (top-level)</a></li>
</ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="tf.search" href="index.html">tf.search</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="tf.search.search.Search" href="#tf.search.search.Search">Search</a></code></h4>
<ul class="two-column">
<li><code><a title="tf.search.search.Search.count" href="#tf.search.search.Search.count">count</a></code></li>
<li><code><a title="tf.search.search.Search.fetch" href="#tf.search.search.Search.fetch">fetch</a></code></li>
<li><code><a title="tf.search.search.Search.glean" href="#tf.search.search.Search.glean">glean</a></code></li>
<li><code><a title="tf.search.search.Search.relationsLegend" href="#tf.search.search.Search.relationsLegend">relationsLegend</a></code></li>
<li><code><a title="tf.search.search.Search.search" href="#tf.search.search.Search.search">search</a></code></li>
<li><code><a title="tf.search.search.Search.showPlan" href="#tf.search.search.Search.showPlan">showPlan</a></code></li>
<li><code><a title="tf.search.search.Search.study" href="#tf.search.search.Search.study">study</a></code></li>
<li><code><a title="tf.search.search.Search.tweakPerformance" href="#tf.search.search.Search.tweakPerformance">tweakPerformance</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<a href="https://pure.knaw.nl/portal/en/persons/dirk-roorda">Dirk Roorda</a>
<a href="https://huc.knaw.nl"><img alt="HuC" src="../../tf/images/huc.png" width="200" alt="Humanities Cluster"></a>
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>