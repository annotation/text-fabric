<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.11.1" />
<title>tf.convert.pandas API documentation</title>
<meta name="description" content="Export a TF dataset to a `pandas` data frame â€¦" />
<!-- integrity SRI from https://cdnjs.com/libraries/10up-sanitize.css/11.0.1 -->
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css"
integrity="sha512-kcbluZFacWN57NgWZ4aH6eUMBEaTyErFhIFD3y5qYZbKuuyImH0K/AKsBbfXlivh2z5C+3IDTIhI11YmKomzmA=="
crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css"
integrity="sha512-uVeAgzAmieLUTGba0qr9vXQgVD7fko2kcbYIKIraXUIDg9iJLxveTFUrg3DJhqn3cAf3HFDbgmhq0eGko5wEAA=="
crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>tf.convert.pandas</code></h1>
</header>
<section id="section-intro">
<h1 id="export-a-tf-dataset-to-a-pandas-data-frame">Export a TF dataset to a <code>pandas</code> data frame.</h1>
<p>There is a natural mapping of a TF dataset with its nodes, edges and features to a
rectangular data frame with rows and columns:</p>
<ul>
<li>the <em>nodes</em> correspond to <em>rows</em>;</li>
<li>the node <em>features</em> correspond to <em>columns</em>;</li>
<li>the <em>value</em> of a feature for a node is in the row that corresponds with the node
and the column that corresponds with the feature.</li>
<li>the <em>edge</em> features correspond to columns, in that column you find for each row
the nodes where edges arrive, i.e. the edges from the node that correspond with
the row.</li>
</ul>
<p>We also write the data that says which nodes are contained in which other nodes.
To each row we add the following columns:</p>
<ul>
<li>for each node type, except the slot type, there is a column with named
<code>in_nodeType</code>, that contains the node of the smallest object that
contains the node of the row;</li>
</ul>
<p>We compose the big table and save it as a tab delimited file.
This temporary result can be processed by <code>R</code> and <code>pandas</code>.</p>
<p>It turns out that for this size of the data <code>pandas</code> is a bit
quicker than R. It is also more Pythonic, which is a pro if you use other Python
programs, such as TF, to process the same data.</p>
<h1 id="examples">Examples</h1>
<ul>
<li><a href="https://nbviewer.org/github/ETCBC/bhsa/blob/master/tutorial/export.ipynb">BHSA</a></li>
<li><a href="https://nbviewer.org/github/annotation/mobydick/blob/main/tutorial/exportPandas.ipynb">Moby Dick</a></li>
<li><a href="https://nbviewer.org/github/CLARIAH/wp6-ferdinandhuyck/blob/main/tutorial/export.ipynb">Ferdinand Huyck</a></li>
</ul>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric/blob/bba7d245341786fc367f29ac5a15453beaa5bdb4/tf/convert/pandas.py#L1-L296" class="git-link">Browse git</a>
</summary>
<pre><code class="python">&#34;&#34;&#34;
# Export a TF dataset to a `pandas` data frame.

There is a natural mapping of a TF dataset with its nodes, edges and features to a
rectangular data frame with rows and columns:

*   the *nodes* correspond to *rows*;
*   the node *features* correspond to *columns*;
*   the *value* of a feature for a node is in the row that corresponds with the node
    and the column that corresponds with the feature.
*   the *edge* features correspond to columns, in that column you find for each row
    the nodes where edges arrive, i.e. the edges from the node that correspond with
    the row.

We also write the data that says which nodes are contained in which other nodes.
To each row we add the following columns:

*   for each node type, except the slot type, there is a column with named
    `in_nodeType`, that contains the node of the smallest object that
    contains the node of the row;

We compose the big table and save it as a tab delimited file.
This temporary result can be processed by `R` and `pandas`.

It turns out that for this size of the data `pandas` is a bit
quicker than R. It is also more Pythonic, which is a pro if you use other Python
programs, such as TF, to process the same data.

# Examples

*   [BHSA](https://nbviewer.org/github/ETCBC/bhsa/blob/master/tutorial/export.ipynb)
*   [Moby Dick](https://nbviewer.org/github/annotation/mobydick/blob/main/tutorial/exportPandas.ipynb)
*   [Ferdinand Huyck](https://nbviewer.org/github/CLARIAH/wp6-ferdinandhuyck/blob/main/tutorial/export.ipynb)
&#34;&#34;&#34;

from ..capable import CheckImport
from ..parameters import OTYPE, OSLOTS
from ..core.files import TEMP_DIR, fileOpen, unexpanduser as ux, expandDir, dirMake
from ..core.helpers import fitemize, pandasEsc, PANDAS_QUOTE, PANDAS_ESCAPE


HELP = &#34;&#34;&#34;
Transforms TF dataset into `pandas`
&#34;&#34;&#34;

INT = &#34;Int64&#34;
STR = &#34;str&#34;
NA = [&#34;&#34;]


def exportPandas(app, inTypes=None, exportDir=None):
    &#34;&#34;&#34;Export a currently loaded TF dataset to `pandas`.

    The function proceeds by first producing a TSV file as an intermediate result.
    This is usually too big for GitHub, to it is produced in a `/_temp` directory
    that is usually in the `.gitignore` of the repo.

    This file serves as the basis for the export to a `pandas` data frame.

    !!! hint &#34;R&#34;
        You can import this file in other programs as well, e.g.
        [R](https://www.r-project.org)

    !!! note &#34;Quotation, newlines, tabs, backslashes and escaping&#34;
        If the data as it comes from TF contains newlines or tabs or
        double quotes, we put them escaped into the TSV, as follows:

        *   *newline* becomes *backslash* plus `n`;
        *   *tab* becomes a single space;
        *   *double quote* becomes *Control-A* plus *double quote*;
        *   *backslash* remains *backslash*.

        In this way, the TSV file is not disturbed by non-delimiting tabs, i.e.
        tabs that are part of the content of a field. No field will contain a tab!

        Also, no field will contain a newline, so the lines are not disturbed by
        newlines that are part of the content of a field. No field will contain a
        newline!

        Double quotes in a TSV file might pose a problem. Several programs interpret
        double quotes as a way to include tabs and newlines in the content of a field,
        especially if the quote occurs at the beginning of a field.
        That&#39;s why we escape it by putting a character in front of it that is very
        unlikely to occur in the text of a corpus: Ctrl A, which is ASCII character 1.

        Backslashes are no problem, but programs might interpret them in a special
        way in combination with specific following characters.

        Now what happens to these characters when `pandas` reads the file?

        We instruct the `pandas` table reading function to use the Control-A as
        escape char and the double quote as quote char.

        **Backslash**

        `pandas` has two special behaviours:

        *   *backslash* `n` becomes a *newline*;
        *   *backslash* *backslash* becomes a single *backslash*.

        This is almost what we want: the newline behaviour is desired; the
        reducing of backslashes not, but we leave it as it is.

        **Double quote**

        *Ctrl-A* plus *double quote* becomes *double quote*.

        That is exactly what we want.

    Parameters
    ----------
    app: object
        A `tf.advanced.app.App` object that represent a loaded corpus, together with
        all its loaded data modules.
    inTypes: string | iterable, optional None
        A bunch of node types for which columns should be made that contain nodes
        in which the row node is contained.
        If `None`, all node types will have such columns. But for certain TEI corpora
        this might lead to overly many columns.
        So, if you specify `&#34;&#34;` or `{}`, there will only be columns for sectional
        node types.
        But you can also specify the list of such node types explicitly.
        In all cases, there will be columns for sectional node types.
    exportDir: string, optional None
        The directory to which the `pandas` file will be exported.
        If `None`, it is the `/pandas` directory in the repo of the app.
    &#34;&#34;&#34;
    CI = CheckImport(&#34;pandas&#34;, &#34;pyarrow&#34;)
    if CI.importOK(hint=True):
        (pandas, pyarrow) = CI.importGet()
    else:
        return

    api = app.api
    Eall = api.Eall
    Fall = api.Fall
    Es = api.Es
    Fs = api.Fs
    F = api.F
    N = api.N
    L = api.L
    T = api.T
    TF = api.TF

    app.indent(reset=True)

    sectionTypes = T.sectionTypes
    sectionFeats = T.sectionFeats

    sectionTypeSet = set(sectionTypes)
    sectionFeatIndex = {}

    for i, f in enumerate(sectionFeats):
        sectionFeatIndex[f] = i

    skipFeatures = {f for f in Fall() + Eall() if &#34;@&#34; in f}

    textFeatures = set()
    for textFormatSpec in TF.cformats.values():
        for featGroup in textFormatSpec[2]:
            for feat in featGroup[0]:
                textFeatures.add(feat)
    textFeatures = sorted(textFeatures)

    inTypes = [
        t
        for t in (F.otype.all if inTypes is None else fitemize(inTypes))
        if t not in sectionTypes
    ]
    edgeFeatures = sorted(set(Eall()) - {OSLOTS} - skipFeatures)
    nodeFeatures = sorted(set(Fall()) - {OTYPE} - set(textFeatures) - skipFeatures)

    dtype = dict(nd=INT, otype=STR)

    for f in sectionTypes:
        dtype[f&#34;in_{f}&#34;] = INT

    for f in nodeFeatures:
        dtype[f] = INT if Fs(f).meta[&#34;valueType&#34;] == &#34;int&#34; else STR

    naValues = dict((x, set() if dtype[x] == STR else {&#34;&#34;}) for x in dtype)

    baseDir = f&#34;{app.repoLocation}&#34;
    tempDir = f&#34;{baseDir}/{TEMP_DIR}&#34;
    if exportDir is None:
        exportDir = f&#34;{baseDir}/pandas&#34;
    else:
        exportDir = exportDir
        exportDir = expandDir(app, exportDir)

    dirMake(tempDir)
    dirMake(exportDir)

    tableFile = f&#34;{tempDir}/data-{app.version}.tsv&#34;
    tableFilePd = f&#34;{exportDir}/data-{app.version}.pd&#34;

    chunkSize = max((100, int(round(F.otype.maxNode / 20))))

    app.info(&#34;Create tsv file ...&#34;)
    app.indent(level=True, reset=True)

    with fileOpen(tableFile, mode=&#34;w&#34;) as hr:
        cells = (
            &#34;nd&#34;,
            &#34;otype&#34;,
            *textFeatures,
            *[f&#34;in_{x}&#34; for x in sectionTypes],
            *[f&#34;in_{x}&#34; for x in inTypes],
            *edgeFeatures,
            *nodeFeatures,
        )
        hr.write(&#34;\t&#34;.join(cells) + &#34;\n&#34;)
        i = 0
        s = 0
        perc = 0

        for n in N.walk():
            nType = F.otype.v(n)
            textValues = [pandasEsc(str(Fs(f).v(n) or &#34;&#34;)) for f in textFeatures]
            sectionNodes = [
                n if nType == section else (L.u(n, otype=section) or NA)[0]
                for section in sectionTypes
            ]
            inValues = [(L.u(n, otype=inType) or NA)[0] for inType in inTypes]
            edgeValues = [pandasEsc(str((Es(f).f(n) or NA)[0])) for f in edgeFeatures]
            nodeValues = [
                pandasEsc(
                    str(
                        (Fs(f).v(sectionNodes[sectionFeatIndex[f]]) or NA[0])
                        if f in sectionFeatIndex and nType in sectionTypeSet
                        else Fs(f).v(n) or &#34;&#34;
                    )
                )
                for f in nodeFeatures
            ]
            cells = (
                str(n),
                F.otype.v(n),
                *textValues,
                *[str(x) for x in sectionNodes],
                *[str(x) for x in inValues],
                *edgeValues,
                *nodeValues,
            )
            hr.write(&#34;\t&#34;.join(cells).replace(&#34;\n&#34;, &#34;\\n&#34;) + &#34;\n&#34;)
            i += 1
            s += 1
            if s == chunkSize:
                s = 0
                perc = int(round(i * 100 / F.otype.maxNode))
                app.info(f&#34;{perc:&gt;3}% {i:&gt;7} nodes written&#34;)

    app.info(f&#34;{perc:&gt;3}% {i:&gt;7} nodes written and done&#34;)
    app.indent(level=False)

    app.info(f&#34;TSV file is {ux(tableFile)}&#34;)

    with fileOpen(tableFile, mode=&#34;r&#34;) as hr:
        rows = 0
        chars = 0
        columns = 0
        for i, line in enumerate(hr):
            if i == 0:
                columns = line.split(&#34;\t&#34;)
                app.info(f&#34;Columns {len(columns)}:&#34;)
                for col in columns:
                    app.info(f&#34;\t{col}&#34;)
            rows += 1
            chars += len(line)
    app.info(f&#34;\t{rows} rows&#34;)
    app.info(f&#34;\t{chars} characters&#34;)

    app.info(&#34;Importing into Pandas ...&#34;)
    app.indent(level=True, reset=True)
    app.info(&#34;Reading tsv file ...&#34;)

    dataFrame = pandas.read_table(
        tableFile,
        delimiter=&#34;\t&#34;,
        quotechar=PANDAS_QUOTE.encode(&#34;utf-8&#34;),
        escapechar=PANDAS_ESCAPE.encode(&#34;utf-8&#34;),
        doublequote=False,
        low_memory=False,
        encoding=&#34;utf8&#34;,
        keep_default_na=False,
        na_values=naValues,
        dtype=dtype,
    )
    app.info(&#34;Done. Size = {}&#34;.format(dataFrame.size))

    app.info(&#34;Saving as Parquet file ...&#34;)

    dataFrame.to_parquet(tableFilePd, engine=&#34;pyarrow&#34;)
    app.info(&#34;Saved&#34;)
    app.indent(level=False)
    app.info(f&#34;PD  in {ux(tableFilePd)}&#34;)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="tf.convert.pandas.exportPandas"><code class="name flex">
<span>def <span class="ident">exportPandas</span></span>(<span>app, inTypes=None, exportDir=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Export a currently loaded TF dataset to <code>pandas</code>.</p>
<p>The function proceeds by first producing a TSV file as an intermediate result.
This is usually too big for GitHub, to it is produced in a <code>/_temp</code> directory
that is usually in the <code>.gitignore</code> of the repo.</p>
<p>This file serves as the basis for the export to a <code>pandas</code> data frame.</p>
<div class="admonition hint">
<p class="admonition-title">R</p>
<p>You can import this file in other programs as well, e.g.
<a href="https://www.r-project.org">R</a></p>
</div>
<div class="admonition note">
<p class="admonition-title">Quotation, newlines, tabs, backslashes and escaping</p>
<p>If the data as it comes from TF contains newlines or tabs or
double quotes, we put them escaped into the TSV, as follows:</p>
<ul>
<li><em>newline</em> becomes <em>backslash</em> plus <code>n</code>;</li>
<li><em>tab</em> becomes a single space;</li>
<li><em>double quote</em> becomes <em>Control-A</em> plus <em>double quote</em>;</li>
<li><em>backslash</em> remains <em>backslash</em>.</li>
</ul>
<p>In this way, the TSV file is not disturbed by non-delimiting tabs, i.e.
tabs that are part of the content of a field. No field will contain a tab!</p>
<p>Also, no field will contain a newline, so the lines are not disturbed by
newlines that are part of the content of a field. No field will contain a
newline!</p>
<p>Double quotes in a TSV file might pose a problem. Several programs interpret
double quotes as a way to include tabs and newlines in the content of a field,
especially if the quote occurs at the beginning of a field.
That's why we escape it by putting a character in front of it that is very
unlikely to occur in the text of a corpus: Ctrl A, which is ASCII character 1.</p>
<p>Backslashes are no problem, but programs might interpret them in a special
way in combination with specific following characters.</p>
<p>Now what happens to these characters when <code>pandas</code> reads the file?</p>
<p>We instruct the <code>pandas</code> table reading function to use the Control-A as
escape char and the double quote as quote char.</p>
<p><strong>Backslash</strong></p>
<p><code>pandas</code> has two special behaviours:</p>
<ul>
<li><em>backslash</em> <code>n</code> becomes a <em>newline</em>;</li>
<li><em>backslash</em> <em>backslash</em> becomes a single <em>backslash</em>.</li>
</ul>
<p>This is almost what we want: the newline behaviour is desired; the
reducing of backslashes not, but we leave it as it is.</p>
<p><strong>Double quote</strong></p>
<p><em>Ctrl-A</em> plus <em>double quote</em> becomes <em>double quote</em>.</p>
<p>That is exactly what we want.</p>
</div>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>app</code></strong> :&ensp;<code>object</code></dt>
<dd>A <code><a title="tf.advanced.app.App" href="../advanced/app.html#tf.advanced.app.App">App</a></code> object that represent a loaded corpus, together with
all its loaded data modules.</dd>
<dt><strong><code>inTypes</code></strong> :&ensp;<code>string | iterable</code>, optional <code>None</code></dt>
<dd>A bunch of node types for which columns should be made that contain nodes
in which the row node is contained.
If <code>None</code>, all node types will have such columns. But for certain TEI corpora
this might lead to overly many columns.
So, if you specify <code>""</code> or <code>{}</code>, there will only be columns for sectional
node types.
But you can also specify the list of such node types explicitly.
In all cases, there will be columns for sectional node types.</dd>
<dt><strong><code>exportDir</code></strong> :&ensp;<code>string</code>, optional <code>None</code></dt>
<dd>The directory to which the <code>pandas</code> file will be exported.
If <code>None</code>, it is the <code>/pandas</code> directory in the repo of the app.</dd>
</dl></div>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<p><a href="https://github.com/annotation" title="annotation on GitHub"><img src="../../tf/images/tf-small.png" alt="annotation"></a></p>
<p><a href="../../tf/index.html">tf home</a> -
<a href="../../tf/cheatsheet.html">cheat sheet</a> -
<a href="https://github.com/annotation/text-fabric" title="GitHub repo"><img src="../../tf/images/GitHub_Logo.png" alt="GitHub" width="50"></a></p>
</p>
<form>
<input id="lunr-search" name="q" placeholder="ðŸ”Ž Search ..." aria-label="Search"
disabled minlength="2">
</form>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/tingle/0.15.3/tingle.min.css" integrity="sha512-j1u8eUJ4f23xPPxwOrLUPQaCD2dwzNqqmDDcWS4deWsMv2ohLqmXXuP3hU7g8TyzbMSakP/mMqoNBYWj8AEIFg==" crossorigin>
<script src="https://cdnjs.cloudflare.com/ajax/libs/tingle/0.15.3/tingle.min.js" integrity="sha512-plGUER9JkeEWPPqQBE4sdLqBoQug5Ap+BCGMc7bJ8BXkm+VVj6QzkpBz5Yv2yPkkq+cqg9IpkBaGCas6uDbW8g==" crossorigin></script>
<style>
.modal-dialog iframe {
width: 100vw;
height: calc(100vh - 80px);
}
@media screen and (min-width: 700px) {
.modal-dialog iframe {
width: 70vw;
height: 80vh;
}
}
.modal-dialog .tingle-modal-box {width: auto;}
.modal-dialog .tingle-modal-box__content {padding: 0;}
</style>
<script>
const input = document.getElementById('lunr-search');
input.disabled = false;
input.form.addEventListener('submit', (ev) => {
ev.preventDefault();
const url = new URL(window.location);
url.searchParams.set('q', input.value);
history.replaceState({}, null, url.toString());
search(input.value);
});
const query = new URL(window.location).searchParams.get('q');
if (query)
search(query);
function search(query) {
const url = '../../doc-search.html#' + encodeURIComponent(query);
new tingle.modal({
cssClass: ['modal-dialog'],
onClose: () => {
const url = new URL(window.location);
url.searchParams.delete('q');
history.replaceState({}, null, url.toString());
setTimeout(() => input.focus(), 100);
}
}).setContent('<iframe src="' + url + '"></iframe>').open();
}
</script>
<h1>Index</h1>
<div class="toc">
<ul>
<li><a href="#export-a-tf-dataset-to-a-pandas-data-frame">Export a TF dataset to a pandas data frame.</a></li>
<li><a href="#examples">Examples</a></li>
</ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="tf.convert" href="index.html">tf.convert</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="tf.convert.pandas.exportPandas" href="#tf.convert.pandas.exportPandas">exportPandas</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<a href="https://pure.knaw.nl/portal/en/persons/dirk-roorda">Dirk Roorda</a>
<a href="https://huc.knaw.nl"><img alt="HuC" src="../../tf/images/huc.png" width="200" alt="Humanities Cluster"></a>
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.11.1</a>.</p>
</footer>
</body>
</html>
