<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.11.6" />
<title>tf.ner.triggers API documentation</title>
<meta name="description" content="Management of triggers in NER spreadsheets …" />
<!-- integrity SRI from https://cdnjs.com/libraries/10up-sanitize.css/11.0.1 -->
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css"
integrity="sha512-kcbluZFacWN57NgWZ4aH6eUMBEaTyErFhIFD3y5qYZbKuuyImH0K/AKsBbfXlivh2z5C+3IDTIhI11YmKomzmA=="
crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css"
integrity="sha512-uVeAgzAmieLUTGba0qr9vXQgVD7fko2kcbYIKIraXUIDg9iJLxveTFUrg3DJhqn3cAf3HFDbgmhq0eGko5wEAA=="
crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>tf.ner.triggers</code></h1>
</header>
<section id="section-intro">
<p>Management of triggers in NER spreadsheets.</p>
<p>Triggers in NER spreadsheets may have unexpected interactions with each other, and
with the scopes in which they are defined.</p>
<p>When NER sheets grow large, we need extra tooling to diagnose these interactions,
so that the user gets the proper feedback on for improving the sheet.</p>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric/blob/3fbd589957f5b3364f2e9ec4fa03bd61f3a68e34/tf/ner/triggers.py#L1-L1200" class="git-link">Browse git</a>
</summary>
<pre><code class="python">&#34;&#34;&#34;Management of triggers in NER spreadsheets.

Triggers in NER spreadsheets may have unexpected interactions with each other, and
with the scopes in which they are defined.

When NER sheets grow large, we need extra tooling to diagnose these interactions,
so that the user gets the proper feedback on for improving the sheet.
&#34;&#34;&#34;

import collections
from textwrap import dedent

from ..core.files import fileOpen
from ..core.helpers import console

from .helpers import toTokens
from .match import occMatch
from .scopes import locInScope


def hasCommon(tokensA, tokensB):
    &#34;&#34;&#34;Whether one sequence of tokens interferes with another.

    The idea is: we want to determine whether matches for `tokensA` may interfere
    with matches for `tokensB`.

    This happens if `tokensB` is a sublist of `tokensA`, or if an initial segment of
    `tokensB` coincides with a final segment of `tokensA`.

    Or the same with `tokensA` and `tokensB` reversed.

    **Proposition:** *`tokensA` en `tokensB` have something in common (in the above sense)
    if and only if you can make a text where `tokensA` and `tokensB` have overlapping
    matches.*

    $$Proof**:

    (direction `=&gt;`)

    Suppose `tokensA` and `tokensB` have something in common.

    Let `i`, `j` be the start-end position of the (part of) `tokensB` that occur in
    `tokensA`.  Construct a match for the combination of `tokensA` and
    `tokensB` as follows:

    ```
    tokensA[0:i] + tokensA[i:j] + xxx
    ```

    Two cases:

    1.  `tokensB` is fully contained in `tokensA`.
        Then take for `xxx`: `tokensA[j:]`.
        The result is a match for `tokensA` and hence for `tokensB`.
    2.  `tokensB` is only contained in `tokensA` up to index `k`. By definition
        of common, this means that `tokensB[0:k]` is equal to `tokensA[-k:]` and hence
        that `j == len(tokensA)`.
        Then take for `xxx`: `tokensB[k:]`.

        We then have:

        ```
        tokensA + tokensB[k:] =
        tokensA[0:i] + tokensA[i:] + tokensB[k:]
        tokensA[0:i] + tokensA[i:j] + tokensB[k:] =
        ```

        because `j == len(tokensA)` :

        ```
        tokensA[0:i] + tokensA[i:j] + tokensB[k:] =
        tokensA[0:i] + tokensB[0:k] + tokensB[k:] =
        tokensA[0:i] + tokensB
        ```

        So, this text is a match for `tokensA` and for `tokensB`

        (direction `&lt;=`)

        Suppose we have a text `T` with an overlapping match for `tokensA` and
        `tokensB`.

        Suppose `T[i:j]` is a match for `tokensA` and `T[n:m]` is a match for
        `tokensB`, and `T[i:j]` and `T[m:n]` overlap.

        Two cases:

        1.  one match is contained in the other. We consider `T[m:n]` is
            contained in `T[i:j]`. For the reverse case, the argument is the same
            with `tokensA` and `tokensB` interchanged.

            `T[m:n]` is part of a match of `tokensA`, so `T[m:n]` occurs in `tokensA`.
            `T[m:n]` is also a match for `tokensB`, so `tokensB == T[m:n]`, so `tokensB`
            is a part of `tokensA`, hence, by definition: `tokensA` and `tokensB`
            have something in common.
        2.  the two matches have a region in common, but none is contained in the
            other.
            We consider the case where m is between i and j. The case where i is
            between m and n is analogous, with `tokensA` and `tokensB` interchanged.

            Now `T[m:j]` is part of a match for `tokensA` and for `tokensB`.
            Then `T[m:j]` is at the end of `T[i:j]`, so an initial part of
            `tokensB` is a final part of `tokensA`.

    Parameters
    ----------
    tokensA: iterable of string
        first operand
    tokensB: iterable of string
        second operand

    Returns
    -------
    tuple of integer
        We return a result consisting of 3 integers: `ref`, `pos`, `length`

        `ref`: 0 if the two operands are identical; 1 if the first operand
        properly contains the second one or if the second one starts somewhere
        in the first one; -1 otherwise.

        `pos`: the position in the one operand where the other starts.

        `length`: the length of the common part of the two operands.
    &#34;&#34;&#34;
    nA = len(tokensA)
    nB = len(tokensB)

    if tokensA == tokensB:
        return (0, 0, nA)

    for i in range(nA - 1, -1, -1):
        end = min((nB, nA - i))

        if tokensA[i : i + end] == tokensB[0:end]:
            ref = 1 if i &gt; 0 else 1 if nA &gt;= nB else -1
            return (ref, i, end)

    for i in range(nB - 1, -1, -1):
        end = min((nA, nB - i))

        if tokensB[i : i + end] == tokensA[0:end]:
            ref = -1 if i &gt; 0 else -1 if nB &gt;= nA else 1
            return (ref, i, end)

    return None


def testCommon():
    &#34;&#34;&#34;Test suite for testing the `hasCommon()` function.&#34;&#34;&#34;

    tokensA = list(&#34;abcd&#34;)
    tokensB = list(&#34;cdef&#34;)
    tokensC = list(&#34;defg&#34;)
    tokensD = list(&#34;bc&#34;)
    tokensE = list(&#34;ab&#34;)
    tokensF = list(&#34;cd&#34;)
    tokensG = list(&#34;a&#34;)
    assert hasCommon(tokensA, tokensA) == (0, 0, 4), hasCommon(tokensA, tokensA)
    assert hasCommon(tokensA, tokensB) == (1, 2, 2), hasCommon(tokensA, tokensB)
    assert hasCommon(tokensB, tokensA) == (-1, 2, 2), hasCommon(tokensB, tokensA)
    assert hasCommon(tokensA, tokensC) == (1, 3, 1), hasCommon(tokensA, tokensC)
    assert hasCommon(tokensC, tokensA) == (-1, 3, 1), hasCommon(tokensC, tokensA)
    assert hasCommon(tokensA, tokensD) == (1, 1, 2), hasCommon(tokensA, tokensD)
    assert hasCommon(tokensD, tokensA) == (-1, 1, 2), hasCommon(tokensD, tokensA)
    assert hasCommon(tokensA, tokensE) == (1, 0, 2), hasCommon(tokensA, tokensE)
    assert hasCommon(tokensE, tokensA) == (-1, 0, 2), hasCommon(tokensE, tokensA)
    assert hasCommon(tokensA, tokensF) == (1, 2, 2), hasCommon(tokensA, tokensF)
    assert hasCommon(tokensF, tokensA) == (-1, 2, 2), hasCommon(tokensF, tokensA)
    assert hasCommon(tokensE, tokensG) == (1, 0, 1), hasCommon(tokensE, tokensG)
    assert hasCommon(tokensG, tokensE) == (-1, 0, 1), hasCommon(tokensG, tokensE)

    tokensA = list(&#34;abcd&#34;)
    tokensB = list(&#34;cef&#34;)
    tokensC = list(&#34;efg&#34;)
    tokensD = list(&#34;bd&#34;)
    tokensE = list(&#34;ac&#34;)
    tokensF = list(&#34;ad&#34;)

    assert hasCommon(tokensA, tokensB) is None, hasCommon(tokensA, tokensB)
    assert hasCommon(tokensB, tokensA) is None, hasCommon(tokensB, tokensA)
    assert hasCommon(tokensA, tokensC) is None, hasCommon(tokensA, tokensC)
    assert hasCommon(tokensC, tokensA) is None, hasCommon(tokensC, tokensA)
    assert hasCommon(tokensA, tokensD) is None, hasCommon(tokensA, tokensD)
    assert hasCommon(tokensD, tokensA) is None, hasCommon(tokensD, tokensA)
    assert hasCommon(tokensA, tokensE) is None, hasCommon(tokensA, tokensE)
    assert hasCommon(tokensE, tokensA) is None, hasCommon(tokensE, tokensA)
    assert hasCommon(tokensA, tokensF) is None, hasCommon(tokensA, tokensF)
    assert hasCommon(tokensF, tokensA) is None, hasCommon(tokensF, tokensA)


def makePartition(triggers, myToTokens):
    &#34;&#34;&#34;Partition a set of triggers into groups of pairwise non-interfering triggers.

    The intention is to explore all triggers that apparently do not have hits.
    We need to look them up in isolation, because then they might have hits on
    their own that are overshadowed by other triggers.

    But searching per trigger is expensive. We want to group triggers together
    that can not interact with each other.
    A hit of one trigger can then never be part of a hit of any other trigger
    in the group.

    &#34;Not being able to interact&#34; is captured by the function `hasCommon()`.

    Parameters
    ----------
    triggers: iterable of string
        The triggers that must be partitioned
    myToTokens: function
        Takes a trigger (string) and produces a sequence of tokens.
        Here you can pass a function that corresponds to how the strings in the corpus
        are divided up into tokens.

    Returns
    -------
    tuple
        The first member is a dict, mapping triggers to sequences of the tokens of which
        they consist;

        the second member is the partition itself, which is a list of parts, where each
        part is a list of triggers that do not have conflicting pairs of triggers.
    &#34;&#34;&#34;

    triggerTokens = {}
    nTriggerTokens = {}

    for trigger in triggers:
        tokens = myToTokens(trigger)
        triggerTokens[trigger] = tokens
        nTriggerTokens.setdefault(len(tokens), {})[trigger] = tokens

    singleTokenTriggers = list(nTriggerTokens[1]) if 1 in nTriggerTokens else []

    partition = [singleTokenTriggers]

    for n in sorted(nTriggerTokens):
        if n == 1:
            continue
        for triggerA, tokensA in nTriggerTokens[n].items():
            added = False

            for part in partition:
                common = False

                for triggerB in part:
                    tokensB = triggerTokens[triggerB]

                    if hasCommon(tokensA, tokensB):
                        common = True
                        break

                if common:
                    continue

                part.append(triggerA)
                added = True
                break

            if not added:
                partition.append([triggerA])

    return (triggerTokens, partition)


class Triggers:
    def partitionTriggers(self, triggers):
        &#34;&#34;&#34;Wrapper around the partitioning function.

        This function calls `tf.ner.triggers.makePartition()` with the corpus
        dependent parameter for turning strings into tokens.

        Parameters
        ----------
        triggers: iterable of string
            A sequence of triggers.

        Returns
        -------
        tuple
            The same as what `tf.ner.triggers.makePartition()` returns.
        &#34;&#34;&#34;
        return makePartition(triggers, self.getToTokensFunc())[1]

    def findOccs(self):
        &#34;&#34;&#34;Finds the occurrences of multiple triggers.

        This is meant to efficiently list all occurrences of many token
        sequences in the corpus.

        The triggers are in member `instructions`, which must first
        be constructed by reading a number of excel files.

        It adds the member `inventory` to the object, which is a dict
        with subdicts:

        `occurrences`: keyed by tuples (eid, kind), the values are
        the occurrences of that entity in the corpus.
        A single occurrence is represented as a tuple of slots.

        `names`: keyed by tuples (eid, kind) and then path,
        the value is the name of that entity in the context indicated by path.

        &#34;&#34;&#34;
        if not self.properlySetup:
            return

        settings = self.settings
        spaceEscaped = settings.spaceEscaped

        setData = self.getSetData()
        tokensFromNode = self.tokensFromNode
        getSeqFromNode = self.getSeqFromNode

        buckets = setData.buckets or ()
        sheetData = self.getSheetData()
        caseSensitive = sheetData.caseSensitive
        instructions = sheetData.instructions

        sheetData.inventory = occMatch(
            tokensFromNode,
            getSeqFromNode,
            buckets,
            instructions,
            spaceEscaped,
            caseSensitive=caseSensitive,
        )

    def reportHits(self, silent=None, showNoHits=False):
        &#34;&#34;&#34;Reports the inventory.

        It diagnoses all triggers by means of `diagnoseTriggers()`.

        Parameters
        ----------
        silent: boolean, optional None
            Whether to be silent. If None, it is taken from the corresponding member
            of the instance.
        showNoHits: boolean, optional False
            Whether to show which triggers do not have hits.
        &#34;&#34;&#34;
        if not self.properlySetup:
            return

        silent = self.silent if silent is None else silent
        sectionHead = self.sectionHead
        sheetData = self.getSheetData()
        allTriggers = sheetData.allTriggers
        inventory = sheetData.inventory

        setName = self.setName
        annoDir = self.annoDir
        setDir = f&#34;{annoDir}/{setName}&#34;
        reportFile = f&#34;{setDir}/hits.tsv&#34;
        reportTriggerBySlotFile = f&#34;{setDir}/triggerBySlot.tsv&#34;

        hitData = []
        names = set()
        noHits = set()
        triggersBySlot = {}

        for e in sorted(allTriggers):
            (name, eidkind, trigger, scope) = e

            names.add(name)

            entry = (name, trigger, scope)
            section = &#34;&#34;
            hits = &#34;&#34;

            entInfo = inventory.get(eidkind, None)

            if entInfo is None:
                hitData.append((&#34;!E&#34;, *entry, &#34;&#34;, 0))
                noHits.add(trigger)
                continue

            triggerInfo = entInfo.get(trigger, None)

            if triggerInfo is None:
                hitData.append((&#34;!T&#34;, *entry, &#34;&#34;, 0))
                noHits.add(trigger)
                continue

            occs = triggerInfo.get(scope, None)

            if occs is None or len(occs) == 0:
                hitData.append((&#34;!P&#34;, *entry, &#34;&#34;, 0))
                noHits.add(trigger)
                continue

            sectionInfo = collections.Counter()

            for slots in occs:
                for slot in slots:
                    triggersBySlot.setdefault(slot, set()).add(trigger)

                section = sectionHead(slots[0])
                sectionInfo[section] += 1

            for section, hits in sorted(sectionInfo.items()):
                hitData.append((&#34;OK&#34;, *entry, section, hits))

        multipleTriggers = {}
        triggerBySlot = {}
        self.triggerBySlot = triggerBySlot

        for slot, triggers in triggersBySlot.items():
            if len(triggers) &gt; 1:
                multipleTriggers[slot] = triggers

            triggerBySlot[slot] = list(triggers)[0]

        if len(multipleTriggers) == 0:
            self.console(&#34;No slot is covered by more than one trigger&#34;)
        else:
            console(
                f&#34;Slots covered by multiple triggers: {len(multipleTriggers)}&#34;,
                error=True,
            )
            for slot, triggers in multipleTriggers.items():
                triggersRep = &#34;, &#34;.join(f&#34;«{trigger}»&#34; for trigger in sorted(triggers))
                self.console(f&#34;{slot:&gt;7}: {triggersRep}&#34;, error=True)

        trigWithout = len(noHits)

        if showNoHits and (trigWithout &gt; 0):
            uncovered = 0
            console(
                &#34;Triggers without hits: &#34; f&#34;{trigWithout}x:&#34;,
                error=True,
            )

            if len(noHits):
                uncovered = self.diagnoseTriggers(noHits, detail=False)

        with fileOpen(reportFile, &#34;w&#34;) as rh:
            rh.write(&#34;label\tname\ttrigger\tscope\tsection\thits\n&#34;)

            for h in sorted(hitData):
                line = &#34;\t&#34;.join(str(c) for c in h)
                rh.write(f&#34;{line}\n&#34;)

        with fileOpen(reportTriggerBySlotFile, &#34;w&#34;) as rh:
            rh.write(&#34;slot\ttrigger\n&#34;)

            for slot, trigger in sorted(
                triggerBySlot.items(), key=lambda x: (x[1], x[0])
            ):
                rh.write(f&#34;{slot}\t{trigger}\n&#34;)

        nEnt = len(names)
        nTriggers = len(allTriggers)
        nHits = sum(e[-1] for e in hitData)

        msg = (
            f&#34;\t{nEnt} entities targeted with {nHits} occurrences. See {reportFile}&#34;
            if silent
            else dedent(
                f&#34;&#34;&#34;
                Entities targeted:          {nEnt:&gt;5}
                Triggers searched for:      {nTriggers:&gt;5}
                Triggers without hits:      {trigWithout:&gt;5}
                 - completely covered:      {trigWithout - uncovered:&gt;5}
                 - missing hits:            {uncovered:&gt;5}
                Triggers with hits:         {nTriggers - trigWithout:&gt;5}
                Total hits:                 {nHits:&gt;5}

                All hits in report file:      {reportFile}
                Triggers by slot in file:     {reportTriggerBySlotFile}
                &#34;&#34;&#34;
            )
        )
        console(msg)

    def triggerInterference(self, alsoInternal=False, alsoExpected=False):
        &#34;&#34;&#34;Produce a report of interferences between triggers.

        Triggers interfere if they have matches that intersect, i.e. there is a match
        `m1` of trigger `t1` and a match `m2` of trigger `t2` such that `m1` and
        `m2` intersect (see `tf.ner.triggers.hasCommon()`.

        Triggers may interfere *potentially*: if the triggers have something in
        common they can have overlapping matches. But it does not mean that
        the corpus contains these overlapping matches, i.e. that the triggers conflict
        *actually*.

        We report the *actually* interfering triggers only.

        Triggers within one row are associated to the same entity and work in the same
        row. It is not bad if they are interfering with each other. If there
        are overlapping matches, the trigger that wins still flags the same entity.
        The worst thing is that some of these triggers are superfluous, but there is
        no reason to be picky on superfluous triggers.

        When one trigger is a proper part of another, this is mostly intentional.
        If the longer trigger matches, it wins it from the shorter trigger, unless
        the shorter trigger&#39;s match starts before the longer trigger&#39;s match.

        We think the user expects the longer trigger to win, but it may surprise him
        if the shorter triggers wins because it starts earlier.

        Parameters
        ----------
        alsoInternal: boolean, optional False
            Also report interference between triggers on the same row.
        alsoExpected: boolean, optional False
            Also report expected interferences.
        &#34;&#34;&#34;
        if not self.properlySetup:
            return

        setName = self.setName
        annoDir = self.annoDir
        setDir = f&#34;{annoDir}/{setName}&#34;
        reportFile = f&#34;{setDir}/interference.txt&#34;

        app = self.app
        L = app.api.L
        T = app.api.T
        sheetData = self.getSheetData()
        rowMap = sheetData.rowMap
        triggerScopes = sheetData.triggerScopes

        interferences, parts = self.interference(
            rowMap,
            triggerScopes,
            self.getToTokensFunc(),
            self.getSeqFromStr,
            alsoInternal=alsoInternal,
            alsoExpected=alsoExpected,
        )

        messages = []
        witnessed = {}

        nParts = len(parts)
        plural = &#34;&#34; if nParts == 1 else &#34;es&#34;
        self.console(
            f&#34;Looking up {len(interferences)} potential interferences &#34;
            f&#34;in {len(parts)} pass{plural} over the corpus &#34;,
            newline=False,
        )

        for part in parts:
            self.console(&#34;.&#34;, newline=False)
            inventory = self.findTriggers(part)

            for trigger, data in inventory.items():
                occs = data.get(trigger, {}).get(&#34;&#34;, [])
                nOccs = len(occs)

                if nOccs:
                    witnessed[trigger] = occs

        self.console(&#34;&#34;)

        msg = (
            f&#34;{len(witnessed)} potential conflicting trigger pairs with &#34;
            f&#34;{sum(len(x) for x in witnessed.values())} conflicts&#34;
        )
        console(msg)
        messages.append(msg)

        conflicts = {}

        for (
            triggerA,
            triggerB,
            triggerC,
            scopeRepA,
            scopeRepB,
            commonScopes,
        ) in interferences:
            if triggerC not in witnessed:
                continue

            rowA = sorted(set(rowMap[triggerA]))
            rowB = sorted(set(rowMap[triggerB]))
            key = &#34;same row&#34; if rowA == rowB else &#34;different rows&#34;
            conflicts.setdefault(key, []).append(
                (
                    rowA,
                    rowB,
                    triggerA,
                    triggerB,
                    witnessed[triggerC],
                    scopeRepA,
                    scopeRepB,
                    commonScopes,
                )
            )

        for key, confls in conflicts.items():
            newConfls = []

            for (
                rowA,
                rowB,
                triggerA,
                triggerB,
                occs,
                scopeRepA,
                scopeRepB,
                commonScopes,
            ) in confls:
                hits = {}

                for occ in sorted(occs):
                    sectionNode = L.u(occ[0], otype=&#34;chunk&#34;)[0]
                    heading = tuple(
                        int(x if type(x) is int else x.lstrip(&#34;0&#34;) or &#34;0&#34;)
                        for x in T.sectionFromNode(sectionNode, fillup=True)
                    )

                    if not locInScope(heading, commonScopes):
                        continue

                    heading = app.sectionStrFromNode(sectionNode)
                    hits.setdefault(heading, []).append(occ)

                if len(hits) == 0:
                    continue

                newConfls.append(
                    (rowA, rowB, triggerA, triggerB, hits, scopeRepA, scopeRepB)
                )

            msg = f&#34;{key} ({len(newConfls)} pairs)&#34;
            msg = f&#34;----------\n{msg}\n----------&#34;
            console(msg)
            messages.append(msg)

            for (
                rowA,
                rowB,
                triggerA,
                triggerB,
                hits,
                scopeRepA,
                scopeRepB,
            ) in newConfls:
                rowRepA = &#34;,&#34;.join(str(r) for r in rowA)
                rowRepB = &#34;,&#34;.join(str(r) for r in rowB)
                msg = (
                    f&#34;{rowRepA:&lt;12} ({scopeRepA:&lt;12}): «{triggerA}»\n&#34;
                    f&#34;{rowRepB:&lt;12} ({scopeRepB:&lt;12}): «{triggerB}»&#34;
                )
                console(msg)
                messages.append(msg)

                diags = []

                i = 0

                for heading, occs in sorted(hits.items()):
                    nOccs = len(occs)

                    if i == 0:
                        diags.append([])

                    diags[-1].append(f&#34;{heading} x {nOccs}&#34;)
                    i += 1

                    if i == 5:
                        i = 0

                first = True

                for batch in diags:
                    label = f&#34;{&#39;occurrences&#39;:&gt;25}: &#34; if first else (&#34; &#34; * 27)
                    first = False
                    msg = f&#34;{label} {&#39;, &#39;.join(batch)}&#34;
                    console(msg)
                    messages.append(msg)

        with fileOpen(reportFile, &#34;w&#34;) as fh:
            for msg in messages:
                fh.write(f&#34;{msg}\n&#34;)

        console(f&#34;Diagnostic trigger interferences written to {reportFile}&#34;)

    def diagnoseTriggers(self, triggers, detail=False):
        &#34;&#34;&#34;Diagnose triggers individually.

        !!! Caution
            This method will be called by `reportHits()` and should not be called
            on its own, since it expects the instance member `triggerBySlot` which
            is constructed by `reportHits()`

        Here we have a closer look to each trigger individually, not focussing on the
        interaction with other triggers.

        The triggers will be partitioned and each part of the partition will be looked
        up in a separate pass over the corpus.

        Parameters
        ----------
        triggers: iterable of string
            The triggers that must be diagnosed.
        detail: boolean, optional False
            If True, produces more detail per trigger, see `diagnoseTrigger()`

        Returns
        -------
        int
            The number of triggers with uncovered occurrences, see `diagnoseTrigger()`
        &#34;&#34;&#34;
        if not self.properlySetup:
            return None

        sheetData = self.getSheetData()
        triggerScopes = sheetData.triggerScopes

        parts = self.partitionTriggers(triggers)

        nParts = len(parts)
        plural = &#34;&#34; if nParts == 1 else &#34;es&#34;
        self.console(
            f&#34;Looking up {len(triggers)} triggers &#34;
            f&#34;in {len(parts)} pass{plural} over the corpus &#34;,
            newline=False,
        )

        items = []

        for part in parts:
            self.console(&#34;.&#34;, newline=False)
            inventory = self.findTriggers(part)

            for trigger, data in inventory.items():
                occs = data.get(trigger, {}).get(&#34;&#34;, [])
                items.append((trigger, occs))

        uncovered = 0

        for trigger, occs in sorted(
            items,
            key=lambda x: (&#34;, &#34;.join(sorted(triggerScopes[x[0]])), x[0].lower()),
        ):
            uncovered += 0 if self.diagnoseTrigger(trigger, occs, detail=detail) else 1

        self.console(&#34;&#34;)

        return uncovered

    def diagnoseTrigger(self, trigger, occs, detail=False):
        &#34;&#34;&#34;Diagnoses an individual trigger.

        !!! Caution
            This method will be called by `diagnoseTriggers()` and should not be called
            on its own, since it expects the instance member `triggerBySlot` which
            is constructed by `reportHits()`, which calls `diagnoseTriggers()`.

        All occurrences of the trigger will be checked: is every slot in such
        an occurrence part of a match according to the original spreadsheet?

        If not so, we check whether it is a match of the trigger in question, or of
        another trigger.

        In this way we can detect where the potential but unrealized matches are.

        If there are matches of the trigger in isolation that contain slots that are
        not part of any match of any trigger in the original search, we say that
        the trigger has uncovered occurrences. It will be returned as the result of this
        function whether this is the case.

        These uncovered occurrences are reported as missing hits.

        It can also be the case that the trigger in isolation has matches that
        are completely covered by matches of other triggers in the original search.
        We can also list these, but since these are probably intentional, we suppress
        these cases unless `detail=True` is passed.

        Parameters
        ----------
        trigger: string
            The trigger to be diagnosed.
        occs: iterable of tuple of integer
            The occurrences of this trigger in the whole corpus, irrespective of scope;
        detail: boolean, optional False
            If True, produces complete diagnostics.
            Otherwise, only produces output if there are missed hits.

        Returns
        -------
        boolean
            Whether there are uncovered occurrences.
        &#34;&#34;&#34;
        if not self.properlySetup:
            return None

        app = self.app
        L = app.api.L
        triggerBySlot = self.triggerBySlot
        sheetData = self.getSheetData()
        triggerScopes = sheetData.triggerScopes

        uncoveredSlots = set()
        coveredBy = {}

        for slots in occs:
            for slot in slots:
                cTrigger = triggerBySlot.get(slot, None)

                if cTrigger is None:
                    uncoveredSlots.add(slot)
                else:
                    coveredBy.setdefault(cTrigger, set()).add(slot)

        uncoveredOccs = {}

        nUncoveredSlots = len(uncoveredSlots)
        ok = nUncoveredSlots == 0

        if nUncoveredSlots:
            for slot in sorted(uncoveredSlots):
                heading = app.sectionStrFromNode(L.u(slot, otype=&#34;chunk&#34;)[0])
                occ = uncoveredOccs.setdefault(heading, [[]])

                if len(occ[-1]) == 0 or occ[-1][-1] + 1 == slot:
                    occ[-1].append(slot)
                else:
                    occ.append([slot])

        nMissedHits = 0
        uncoveredOccsDiag = []
        uncoveredOccsDiagCompact = []

        for heading, occs in uncoveredOccs.items():
            nOccs = len(occs)
            nMissedHits += nOccs
            uncoveredOccsDiag.append(f&#34;\t\t{heading}: {nOccs} x&#34;)
            uncoveredOccsDiagCompact.append(f&#34;{heading} x {nOccs}&#34;)

        uncoveredOccsDiag[0:0] = [f&#34;\tuncovered: {nMissedHits} x&#34;]

        coveredOccsDiag = []

        for cTrigger in sorted(coveredBy, key=lambda x: x.lower()):
            thisCoveredOccsDiag = []
            coveredSlots = sorted(coveredBy[cTrigger])

            coveredHits = {}

            for slot in sorted(coveredSlots):
                heading = app.sectionStrFromNode(L.u(slot, otype=&#34;chunk&#34;)[0])
                occ = coveredHits.setdefault(heading, [[]])

                if len(occ[-1]) == 0 or occ[-1][-1] + 1 == slot:
                    occ[-1].append(slot)
                else:
                    occ.append([slot])

            nCoveredHits = 0

            for heading, occs in coveredHits.items():
                nOccs = len(occs)
                nCoveredHits += nOccs
                thisCoveredOccsDiag.append(f&#34;\t\t{heading}: {nOccs} x&#34;)

            thisCoveredOccsDiag[0:0] = [f&#34;\tcovered by: {cTrigger}: {nCoveredHits} x&#34;]

            coveredOccsDiag.extend(thisCoveredOccsDiag)

        scopeRep = f&#34;({&#39;, &#39;.join(sorted(triggerScopes[trigger]))})&#34;

        if detail:
            console(f&#34;{trigger} {scopeRep}:&#34;)

            for line in uncoveredOccsDiag:
                console(line)

            for line in coveredOccsDiag:
                console(line)

        else:
            if nUncoveredSlots == 0:
                if False:
                    console(f&#34;{trigger} {scopeRep}: covered by other triggers&#34;)
            else:
                missedHits = []

                i = 0
                for occRep in uncoveredOccsDiagCompact:
                    if i == 0:
                        missedHits.append([occRep])
                    else:
                        missedHits[-1].append(occRep)

                    i += 1
                    if i == 5:
                        i = 0

                missedHitsRep = &#34;, &#34;.join(missedHits[0])
                console(f&#34;{trigger:&lt;40} {scopeRep:&lt;12}: {missedHitsRep}&#34;, error=True)

                for m in missedHits[1:]:
                    missedHitsRep = &#34;, &#34;.join(m)
                    console(f&#34;{&#39; &#39; * 55}{missedHitsRep}&#34;, error=True)

        return ok

    def interference(
        self,
        rowMap,
        triggerScopes,
        myToTokens,
        getSeqFromStr,
        alsoInternal=False,
        alsoExpected=False,
    ):
        &#34;&#34;&#34;Workhorse to calculate interference of triggers.

        This function is used by method `triggerInterference()` for calculating the
        *potential* interferences within a set of triggers, irrespective whether
        the corpus contains instances of these interferences.

        When two triggers interfere, you can build a combined trigger out of them
        whose matches are exactly the points of interference. We call this the
        *combined* trigger of the interference.

        Parameters
        ----------
        rowMap: dict
            mapping from triggers to the rows where they occur in the spreadsheet.
            We take the set of triggers from here, so that we can issue proper
            diagnostic information later, i.e. we can mentoin the row in the spreadsheet
            where the offending triggers are.
        triggerScopes: dict
            mapping from triggers to the scopes for which they are defined.
        myToTokens: function
            corpus dependent function for parsing a trigger, which is a string,
            to tokens, in the same way as the text of the corpus is parsed into tokens.
        getSeqfromStr: function
            corpus dependent function that can translate a section heading into a
            tuple of integers that represents the same heading in the &#34;legal&#34; numbering
            system.
        alsoInternal: boolean, optional False
            Whether to report interfering triggers even if they belong to the
            same entity
        alsoExpected: boolean, optional False
            Whether to report interfering triggers even if one is a proper
            initial part of the other.

        Returns
        -------
        tuple
            There are two parts:

            *interferences*: a list of interfering pairs of triggers, where each
            interference has these components:

            *   *triggerA* the first trigger in the pair;
            *   *triggerB* the second trigger in the pair;
            *   *triggerC* the combined trigger of the interference;
            *   *scopeRepA* the scope of the first trigger;
            *   *scopeRepB* the scope of the second trigger;
            *   *commonScopes* the intersection of the scopes of both triggers.

            *parts*: a partition of the combined triggers of all interferences so that
            within each part none of these interfere.
        &#34;&#34;&#34;
        if not self.properlySetup:
            return (None, None)

        triggers = list(rowMap)

        triggerTokens, parts = makePartition(triggers, myToTokens)

        nParts = len(parts)

        interferences = []

        intersections = {}

        for i, part in enumerate(parts):
            if i == nParts - 1:
                break

            for otherPart in parts[i + 1 : nParts]:
                for triggerA in part:
                    for triggerB in otherPart:
                        tokensA = triggerTokens[triggerA]
                        tokensB = triggerTokens[triggerB]

                        if not alsoInternal:
                            rowsA = set(rowMap[triggerA])
                            rowsB = set(rowMap[triggerB])
                            if rowsA == rowsB:
                                continue

                        scopesA = &#34;,&#34;.join(sorted(triggerScopes[triggerA]))
                        scopesB = &#34;,&#34;.join(sorted(triggerScopes[triggerB]))
                        commonScopes = intersections.get((triggerA, triggerB), None)

                        if commonScopes is None:
                            commonScopes = self.intersectScopes(scopesA, scopesB)
                            intersections[(triggerA, triggerB)] = commonScopes

                        if len(commonScopes) == 0:
                            continue

                        common = hasCommon(tokensA, tokensB)

                        if common is None:
                            continue

                        ref, pos, length = common
                        nTokensA = len(tokensA)
                        nTokensB = len(tokensB)

                        nTokensLatter = nTokensB if ref == 1 else nTokensA

                        expected = length == nTokensLatter

                        if expected and not alsoExpected:
                            continue

                        if ref == 1:
                            nB = len(tokensB)
                            union = tokensA

                            if length &lt; nB:
                                union += tokensB[length:]
                        else:
                            nA = len(tokensA)
                            union = tokensB

                            if length &lt; nA:
                                union += tokensA[length:]

                        interferences.append(
                            (
                                triggerA,
                                triggerB,
                                &#34; &#34;.join(union),
                                scopesA,
                                scopesB,
                                commonScopes,
                            )
                        )

        parts = makePartition([x[2] for x in interferences], myToTokens)[1]

        return interferences, parts

    def findTriggers(self, triggers):
        &#34;&#34;&#34;Looks up occurrences of multiple triggers efficiently.

        This is a lot like `findOccs()`, but where as `findOccs()` finds
        its search instructions in the sheet data and stores its search results in the
        sheet data, this function makes its own instructions and returns the search
        results.

        We use this function when we need to investigate what triggers do in isolation
        and without scope restrictions.

        So, the instructions generated by this functions are derived from the
        spreadsheet, but ignore all scope restrictions.

        Parameters
        ----------
        triggers: iterable of string
            These are the triggers to be looked up. Typically they come from one
            part of a partition of triggers, but not necessarily so.

        Returns
        -------
        dict
            The inventory of occurrences of the triggers, as returned by
            `tf.ner.match.occMatch()`.
        &#34;&#34;&#34;
        if not self.properlySetup:
            return {}

        settings = self.settings
        spaceEscaped = settings.spaceEscaped

        setData = self.getSetData()
        tokensFromNode = self.tokensFromNode
        getSeqFromNode = self.getSeqFromNode

        buckets = setData.buckets or ()
        sheetData = self.getSheetData()
        caseSensitive = sheetData.caseSensitive

        idMap = {trigger: trigger for trigger in triggers}
        tMap = {trigger: &#34;&#34; for trigger in triggers}
        tPos = {}
        triggerSet = set()
        instructions = {(): dict(tPos=tPos, tMap=tMap, idMap=idMap)}

        for trigger in triggers:
            triggerT = toTokens(
                trigger, spaceEscaped=spaceEscaped, caseSensitive=caseSensitive
            )
            triggerSet.add(triggerT)

        for triggerT in triggerSet:
            for i, token in enumerate(triggerT):
                tPos.setdefault(i, {}).setdefault(token, set()).add(triggerT)

        inventory = occMatch(
            tokensFromNode,
            getSeqFromNode,
            buckets,
            instructions,
            spaceEscaped,
            caseSensitive=caseSensitive,
        )

        return inventory

    def findTrigger(self, trigger, show=True):
        &#34;&#34;&#34;Looks up occurrences of a single triggers.

        This is a lot like `findTriggers()`, but where as `findTriggers()` looks up
        multiple triggers, this one looks up a single trigger.

        Like `findTriggers()` the search is done without scope restrictions.

        We use this function when we need to investigate what a single trigger
        does in isolation and without scope restrictions.

        So, the instructions generated by this functions are derived from the
        spreadsheet, but ignore all scope restrictions.

        Parameters
        ----------
        trigger: string
            This is the trigger to be looked up.
        show: boolean, optional True
            If True, it shows the result on the console, otherwise it returns
            the result.

        Returns
        -------
        list or void
            The list of occurrences of the trigger, provided `show=False` is passed,
            else there is no function result.
        &#34;&#34;&#34;
        if not self.properlySetup:
            return []

        app = self.app
        L = app.api.L

        settings = self.settings
        spaceEscaped = settings.spaceEscaped

        setData = self.getSetData()
        tokensFromNode = self.tokensFromNode
        getSeqFromNode = self.getSeqFromNode

        buckets = setData.buckets or ()
        sheetData = self.getSheetData()
        caseSensitive = sheetData.caseSensitive

        triggerT = toTokens(
            trigger, spaceEscaped=spaceEscaped, caseSensitive=caseSensitive
        )
        idMap = {trigger: trigger}
        tMap = {trigger: &#34;&#34;}
        tPos = {}

        for i, token in enumerate(triggerT):
            tPos.setdefault(i, {}).setdefault(token, set()).add(triggerT)

        instructions = {(): dict(tPos=tPos, tMap=tMap, idMap=idMap)}

        inventory = occMatch(
            tokensFromNode,
            getSeqFromNode,
            buckets,
            instructions,
            spaceEscaped,
            caseSensitive=caseSensitive,
        )

        occs = inventory.get(trigger, {}).get(trigger, {}).get(&#34;&#34;, [])

        if show:
            nOccs = len(occs)
            plural = &#34;&#34; if nOccs == 1 else &#34;s&#34;
            app.dm(f&#34;**{nOccs} occurrence{plural}**\n&#34;)

            if nOccs:
                headings = set()
                highlights = set()

                for occ in occs:
                    headings.add(L.u(occ[0], otype=&#34;chunk&#34;)[0])

                    for slot in occ:
                        highlights.add(slot)

                for hd in sorted(headings):
                    app.plain(hd, highlights=highlights)
        else:
            return occs</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="tf.ner.triggers.hasCommon"><code class="name flex">
<span>def <span class="ident">hasCommon</span></span>(<span>tokensA, tokensB)</span>
</code></dt>
<dd>
<div class="desc"><p>Whether one sequence of tokens interferes with another.</p>
<p>The idea is: we want to determine whether matches for <code>tokensA</code> may interfere
with matches for <code>tokensB</code>.</p>
<p>This happens if <code>tokensB</code> is a sublist of <code>tokensA</code>, or if an initial segment of
<code>tokensB</code> coincides with a final segment of <code>tokensA</code>.</p>
<p>Or the same with <code>tokensA</code> and <code>tokensB</code> reversed.</p>
<p><strong>Proposition:</strong> <em><code>tokensA</code> en <code>tokensB</code> have something in common (in the above sense)
if and only if you can make a text where <code>tokensA</code> and <code>tokensB</code> have overlapping
matches.</em></p>
<p>$$Proof**:</p>
<p>(direction <code>=&gt;</code>)</p>
<p>Suppose <code>tokensA</code> and <code>tokensB</code> have something in common.</p>
<p>Let <code>i</code>, <code>j</code> be the start-end position of the (part of) <code>tokensB</code> that occur in
<code>tokensA</code>.
Construct a match for the combination of <code>tokensA</code> and
<code>tokensB</code> as follows:</p>
<pre><code>tokensA[0:i] + tokensA[i:j] + xxx
</code></pre>
<p>Two cases:</p>
<ol>
<li><code>tokensB</code> is fully contained in <code>tokensA</code>.
Then take for <code>xxx</code>: <code>tokensA[j:]</code>.
The result is a match for <code>tokensA</code> and hence for <code>tokensB</code>.</li>
<li>
<p><code>tokensB</code> is only contained in <code>tokensA</code> up to index <code>k</code>. By definition
of common, this means that <code>tokensB[0:k]</code> is equal to <code>tokensA[-k:]</code> and hence
that <code>j == len(tokensA)</code>.
Then take for <code>xxx</code>: <code>tokensB[k:]</code>.</p>
<p>We then have:</p>
<p><code>tokensA + tokensB[k:] =
tokensA[0:i] + tokensA[i:] + tokensB[k:]
tokensA[0:i] + tokensA[i:j] + tokensB[k:] =</code></p>
<p>because <code>j == len(tokensA)</code> :</p>
<p><code>tokensA[0:i] + tokensA[i:j] + tokensB[k:] =
tokensA[0:i] + tokensB[0:k] + tokensB[k:] =
tokensA[0:i] + tokensB</code></p>
<p>So, this text is a match for <code>tokensA</code> and for <code>tokensB</code></p>
<p>(direction <code>&lt;=</code>)</p>
<p>Suppose we have a text <code>T</code> with an overlapping match for <code>tokensA</code> and
<code>tokensB</code>.</p>
<p>Suppose <code>T[i:j]</code> is a match for <code>tokensA</code> and <code>T[n:m]</code> is a match for
<code>tokensB</code>, and <code>T[i:j]</code> and <code>T[m:n]</code> overlap.</p>
<p>Two cases:</p>
<ol>
<li>
<p>one match is contained in the other. We consider <code>T[m:n]</code> is
contained in <code>T[i:j]</code>. For the reverse case, the argument is the same
with <code>tokensA</code> and <code>tokensB</code> interchanged.</p>
<p><code>T[m:n]</code> is part of a match of <code>tokensA</code>, so <code>T[m:n]</code> occurs in <code>tokensA</code>.
<code>T[m:n]</code> is also a match for <code>tokensB</code>, so <code>tokensB == T[m:n]</code>, so <code>tokensB</code>
is a part of <code>tokensA</code>, hence, by definition: <code>tokensA</code> and <code>tokensB</code>
have something in common.
2.
the two matches have a region in common, but none is contained in the
other.
We consider the case where m is between i and j. The case where i is
between m and n is analogous, with <code>tokensA</code> and <code>tokensB</code> interchanged.</p>
<p>Now <code>T[m:j]</code> is part of a match for <code>tokensA</code> and for <code>tokensB</code>.
Then <code>T[m:j]</code> is at the end of <code>T[i:j]</code>, so an initial part of
<code>tokensB</code> is a final part of <code>tokensA</code>.</p>
</li>
</ol>
</li>
</ol>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tokensA</code></strong> :&ensp;<code>iterable</code> of <code>string</code></dt>
<dd>first operand</dd>
<dt><strong><code>tokensB</code></strong> :&ensp;<code>iterable</code> of <code>string</code></dt>
<dd>second operand</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code> of <code>integer</code></dt>
<dd>
<p>We return a result consisting of 3 integers: <code>ref</code>, <code>pos</code>, <code>length</code></p>
<p><code>ref</code>: 0 if the two operands are identical; 1 if the first operand
properly contains the second one or if the second one starts somewhere
in the first one; -1 otherwise.</p>
<p><code>pos</code>: the position in the one operand where the other starts.</p>
<p><code>length</code>: the length of the common part of the two operands.</p>
</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric/blob/3fbd589957f5b3364f2e9ec4fa03bd61f3a68e34/tf/ner/triggers.py#L21-L145" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def hasCommon(tokensA, tokensB):
    &#34;&#34;&#34;Whether one sequence of tokens interferes with another.

    The idea is: we want to determine whether matches for `tokensA` may interfere
    with matches for `tokensB`.

    This happens if `tokensB` is a sublist of `tokensA`, or if an initial segment of
    `tokensB` coincides with a final segment of `tokensA`.

    Or the same with `tokensA` and `tokensB` reversed.

    **Proposition:** *`tokensA` en `tokensB` have something in common (in the above sense)
    if and only if you can make a text where `tokensA` and `tokensB` have overlapping
    matches.*

    $$Proof**:

    (direction `=&gt;`)

    Suppose `tokensA` and `tokensB` have something in common.

    Let `i`, `j` be the start-end position of the (part of) `tokensB` that occur in
    `tokensA`.  Construct a match for the combination of `tokensA` and
    `tokensB` as follows:

    ```
    tokensA[0:i] + tokensA[i:j] + xxx
    ```

    Two cases:

    1.  `tokensB` is fully contained in `tokensA`.
        Then take for `xxx`: `tokensA[j:]`.
        The result is a match for `tokensA` and hence for `tokensB`.
    2.  `tokensB` is only contained in `tokensA` up to index `k`. By definition
        of common, this means that `tokensB[0:k]` is equal to `tokensA[-k:]` and hence
        that `j == len(tokensA)`.
        Then take for `xxx`: `tokensB[k:]`.

        We then have:

        ```
        tokensA + tokensB[k:] =
        tokensA[0:i] + tokensA[i:] + tokensB[k:]
        tokensA[0:i] + tokensA[i:j] + tokensB[k:] =
        ```

        because `j == len(tokensA)` :

        ```
        tokensA[0:i] + tokensA[i:j] + tokensB[k:] =
        tokensA[0:i] + tokensB[0:k] + tokensB[k:] =
        tokensA[0:i] + tokensB
        ```

        So, this text is a match for `tokensA` and for `tokensB`

        (direction `&lt;=`)

        Suppose we have a text `T` with an overlapping match for `tokensA` and
        `tokensB`.

        Suppose `T[i:j]` is a match for `tokensA` and `T[n:m]` is a match for
        `tokensB`, and `T[i:j]` and `T[m:n]` overlap.

        Two cases:

        1.  one match is contained in the other. We consider `T[m:n]` is
            contained in `T[i:j]`. For the reverse case, the argument is the same
            with `tokensA` and `tokensB` interchanged.

            `T[m:n]` is part of a match of `tokensA`, so `T[m:n]` occurs in `tokensA`.
            `T[m:n]` is also a match for `tokensB`, so `tokensB == T[m:n]`, so `tokensB`
            is a part of `tokensA`, hence, by definition: `tokensA` and `tokensB`
            have something in common.
        2.  the two matches have a region in common, but none is contained in the
            other.
            We consider the case where m is between i and j. The case where i is
            between m and n is analogous, with `tokensA` and `tokensB` interchanged.

            Now `T[m:j]` is part of a match for `tokensA` and for `tokensB`.
            Then `T[m:j]` is at the end of `T[i:j]`, so an initial part of
            `tokensB` is a final part of `tokensA`.

    Parameters
    ----------
    tokensA: iterable of string
        first operand
    tokensB: iterable of string
        second operand

    Returns
    -------
    tuple of integer
        We return a result consisting of 3 integers: `ref`, `pos`, `length`

        `ref`: 0 if the two operands are identical; 1 if the first operand
        properly contains the second one or if the second one starts somewhere
        in the first one; -1 otherwise.

        `pos`: the position in the one operand where the other starts.

        `length`: the length of the common part of the two operands.
    &#34;&#34;&#34;
    nA = len(tokensA)
    nB = len(tokensB)

    if tokensA == tokensB:
        return (0, 0, nA)

    for i in range(nA - 1, -1, -1):
        end = min((nB, nA - i))

        if tokensA[i : i + end] == tokensB[0:end]:
            ref = 1 if i &gt; 0 else 1 if nA &gt;= nB else -1
            return (ref, i, end)

    for i in range(nB - 1, -1, -1):
        end = min((nA, nB - i))

        if tokensB[i : i + end] == tokensA[0:end]:
            ref = -1 if i &gt; 0 else -1 if nB &gt;= nA else 1
            return (ref, i, end)

    return None</code></pre>
</details>
</dd>
<dt id="tf.ner.triggers.makePartition"><code class="name flex">
<span>def <span class="ident">makePartition</span></span>(<span>triggers, myToTokens)</span>
</code></dt>
<dd>
<div class="desc"><p>Partition a set of triggers into groups of pairwise non-interfering triggers.</p>
<p>The intention is to explore all triggers that apparently do not have hits.
We need to look them up in isolation, because then they might have hits on
their own that are overshadowed by other triggers.</p>
<p>But searching per trigger is expensive. We want to group triggers together
that can not interact with each other.
A hit of one trigger can then never be part of a hit of any other trigger
in the group.</p>
<p>"Not being able to interact" is captured by the function <code><a title="tf.ner.triggers.hasCommon" href="#tf.ner.triggers.hasCommon">hasCommon()</a></code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>triggers</code></strong> :&ensp;<code>iterable</code> of <code>string</code></dt>
<dd>The triggers that must be partitioned</dd>
<dt><strong><code>myToTokens</code></strong> :&ensp;<code>function</code></dt>
<dd>Takes a trigger (string) and produces a sequence of tokens.
Here you can pass a function that corresponds to how the strings in the corpus
are divided up into tokens.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code></dt>
<dd>
<p>The first member is a dict, mapping triggers to sequences of the tokens of which
they consist;</p>
<p>the second member is the partition itself, which is a list of parts, where each
part is a list of triggers that do not have conflicting pairs of triggers.</p>
</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric/blob/3fbd589957f5b3364f2e9ec4fa03bd61f3a68e34/tf/ner/triggers.py#L191-L262" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def makePartition(triggers, myToTokens):
    &#34;&#34;&#34;Partition a set of triggers into groups of pairwise non-interfering triggers.

    The intention is to explore all triggers that apparently do not have hits.
    We need to look them up in isolation, because then they might have hits on
    their own that are overshadowed by other triggers.

    But searching per trigger is expensive. We want to group triggers together
    that can not interact with each other.
    A hit of one trigger can then never be part of a hit of any other trigger
    in the group.

    &#34;Not being able to interact&#34; is captured by the function `hasCommon()`.

    Parameters
    ----------
    triggers: iterable of string
        The triggers that must be partitioned
    myToTokens: function
        Takes a trigger (string) and produces a sequence of tokens.
        Here you can pass a function that corresponds to how the strings in the corpus
        are divided up into tokens.

    Returns
    -------
    tuple
        The first member is a dict, mapping triggers to sequences of the tokens of which
        they consist;

        the second member is the partition itself, which is a list of parts, where each
        part is a list of triggers that do not have conflicting pairs of triggers.
    &#34;&#34;&#34;

    triggerTokens = {}
    nTriggerTokens = {}

    for trigger in triggers:
        tokens = myToTokens(trigger)
        triggerTokens[trigger] = tokens
        nTriggerTokens.setdefault(len(tokens), {})[trigger] = tokens

    singleTokenTriggers = list(nTriggerTokens[1]) if 1 in nTriggerTokens else []

    partition = [singleTokenTriggers]

    for n in sorted(nTriggerTokens):
        if n == 1:
            continue
        for triggerA, tokensA in nTriggerTokens[n].items():
            added = False

            for part in partition:
                common = False

                for triggerB in part:
                    tokensB = triggerTokens[triggerB]

                    if hasCommon(tokensA, tokensB):
                        common = True
                        break

                if common:
                    continue

                part.append(triggerA)
                added = True
                break

            if not added:
                partition.append([triggerA])

    return (triggerTokens, partition)</code></pre>
</details>
</dd>
<dt id="tf.ner.triggers.testCommon"><code class="name flex">
<span>def <span class="ident">testCommon</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Test suite for testing the <code><a title="tf.ner.triggers.hasCommon" href="#tf.ner.triggers.hasCommon">hasCommon()</a></code> function.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric/blob/3fbd589957f5b3364f2e9ec4fa03bd61f3a68e34/tf/ner/triggers.py#L148-L188" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def testCommon():
    &#34;&#34;&#34;Test suite for testing the `hasCommon()` function.&#34;&#34;&#34;

    tokensA = list(&#34;abcd&#34;)
    tokensB = list(&#34;cdef&#34;)
    tokensC = list(&#34;defg&#34;)
    tokensD = list(&#34;bc&#34;)
    tokensE = list(&#34;ab&#34;)
    tokensF = list(&#34;cd&#34;)
    tokensG = list(&#34;a&#34;)
    assert hasCommon(tokensA, tokensA) == (0, 0, 4), hasCommon(tokensA, tokensA)
    assert hasCommon(tokensA, tokensB) == (1, 2, 2), hasCommon(tokensA, tokensB)
    assert hasCommon(tokensB, tokensA) == (-1, 2, 2), hasCommon(tokensB, tokensA)
    assert hasCommon(tokensA, tokensC) == (1, 3, 1), hasCommon(tokensA, tokensC)
    assert hasCommon(tokensC, tokensA) == (-1, 3, 1), hasCommon(tokensC, tokensA)
    assert hasCommon(tokensA, tokensD) == (1, 1, 2), hasCommon(tokensA, tokensD)
    assert hasCommon(tokensD, tokensA) == (-1, 1, 2), hasCommon(tokensD, tokensA)
    assert hasCommon(tokensA, tokensE) == (1, 0, 2), hasCommon(tokensA, tokensE)
    assert hasCommon(tokensE, tokensA) == (-1, 0, 2), hasCommon(tokensE, tokensA)
    assert hasCommon(tokensA, tokensF) == (1, 2, 2), hasCommon(tokensA, tokensF)
    assert hasCommon(tokensF, tokensA) == (-1, 2, 2), hasCommon(tokensF, tokensA)
    assert hasCommon(tokensE, tokensG) == (1, 0, 1), hasCommon(tokensE, tokensG)
    assert hasCommon(tokensG, tokensE) == (-1, 0, 1), hasCommon(tokensG, tokensE)

    tokensA = list(&#34;abcd&#34;)
    tokensB = list(&#34;cef&#34;)
    tokensC = list(&#34;efg&#34;)
    tokensD = list(&#34;bd&#34;)
    tokensE = list(&#34;ac&#34;)
    tokensF = list(&#34;ad&#34;)

    assert hasCommon(tokensA, tokensB) is None, hasCommon(tokensA, tokensB)
    assert hasCommon(tokensB, tokensA) is None, hasCommon(tokensB, tokensA)
    assert hasCommon(tokensA, tokensC) is None, hasCommon(tokensA, tokensC)
    assert hasCommon(tokensC, tokensA) is None, hasCommon(tokensC, tokensA)
    assert hasCommon(tokensA, tokensD) is None, hasCommon(tokensA, tokensD)
    assert hasCommon(tokensD, tokensA) is None, hasCommon(tokensD, tokensA)
    assert hasCommon(tokensA, tokensE) is None, hasCommon(tokensA, tokensE)
    assert hasCommon(tokensE, tokensA) is None, hasCommon(tokensE, tokensA)
    assert hasCommon(tokensA, tokensF) is None, hasCommon(tokensA, tokensF)
    assert hasCommon(tokensF, tokensA) is None, hasCommon(tokensF, tokensA)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="tf.ner.triggers.Triggers"><code class="flex name class">
<span>class <span class="ident">Triggers</span></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric/blob/3fbd589957f5b3364f2e9ec4fa03bd61f3a68e34/tf/ner/triggers.py#L265-L1200" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class Triggers:
    def partitionTriggers(self, triggers):
        &#34;&#34;&#34;Wrapper around the partitioning function.

        This function calls `tf.ner.triggers.makePartition()` with the corpus
        dependent parameter for turning strings into tokens.

        Parameters
        ----------
        triggers: iterable of string
            A sequence of triggers.

        Returns
        -------
        tuple
            The same as what `tf.ner.triggers.makePartition()` returns.
        &#34;&#34;&#34;
        return makePartition(triggers, self.getToTokensFunc())[1]

    def findOccs(self):
        &#34;&#34;&#34;Finds the occurrences of multiple triggers.

        This is meant to efficiently list all occurrences of many token
        sequences in the corpus.

        The triggers are in member `instructions`, which must first
        be constructed by reading a number of excel files.

        It adds the member `inventory` to the object, which is a dict
        with subdicts:

        `occurrences`: keyed by tuples (eid, kind), the values are
        the occurrences of that entity in the corpus.
        A single occurrence is represented as a tuple of slots.

        `names`: keyed by tuples (eid, kind) and then path,
        the value is the name of that entity in the context indicated by path.

        &#34;&#34;&#34;
        if not self.properlySetup:
            return

        settings = self.settings
        spaceEscaped = settings.spaceEscaped

        setData = self.getSetData()
        tokensFromNode = self.tokensFromNode
        getSeqFromNode = self.getSeqFromNode

        buckets = setData.buckets or ()
        sheetData = self.getSheetData()
        caseSensitive = sheetData.caseSensitive
        instructions = sheetData.instructions

        sheetData.inventory = occMatch(
            tokensFromNode,
            getSeqFromNode,
            buckets,
            instructions,
            spaceEscaped,
            caseSensitive=caseSensitive,
        )

    def reportHits(self, silent=None, showNoHits=False):
        &#34;&#34;&#34;Reports the inventory.

        It diagnoses all triggers by means of `diagnoseTriggers()`.

        Parameters
        ----------
        silent: boolean, optional None
            Whether to be silent. If None, it is taken from the corresponding member
            of the instance.
        showNoHits: boolean, optional False
            Whether to show which triggers do not have hits.
        &#34;&#34;&#34;
        if not self.properlySetup:
            return

        silent = self.silent if silent is None else silent
        sectionHead = self.sectionHead
        sheetData = self.getSheetData()
        allTriggers = sheetData.allTriggers
        inventory = sheetData.inventory

        setName = self.setName
        annoDir = self.annoDir
        setDir = f&#34;{annoDir}/{setName}&#34;
        reportFile = f&#34;{setDir}/hits.tsv&#34;
        reportTriggerBySlotFile = f&#34;{setDir}/triggerBySlot.tsv&#34;

        hitData = []
        names = set()
        noHits = set()
        triggersBySlot = {}

        for e in sorted(allTriggers):
            (name, eidkind, trigger, scope) = e

            names.add(name)

            entry = (name, trigger, scope)
            section = &#34;&#34;
            hits = &#34;&#34;

            entInfo = inventory.get(eidkind, None)

            if entInfo is None:
                hitData.append((&#34;!E&#34;, *entry, &#34;&#34;, 0))
                noHits.add(trigger)
                continue

            triggerInfo = entInfo.get(trigger, None)

            if triggerInfo is None:
                hitData.append((&#34;!T&#34;, *entry, &#34;&#34;, 0))
                noHits.add(trigger)
                continue

            occs = triggerInfo.get(scope, None)

            if occs is None or len(occs) == 0:
                hitData.append((&#34;!P&#34;, *entry, &#34;&#34;, 0))
                noHits.add(trigger)
                continue

            sectionInfo = collections.Counter()

            for slots in occs:
                for slot in slots:
                    triggersBySlot.setdefault(slot, set()).add(trigger)

                section = sectionHead(slots[0])
                sectionInfo[section] += 1

            for section, hits in sorted(sectionInfo.items()):
                hitData.append((&#34;OK&#34;, *entry, section, hits))

        multipleTriggers = {}
        triggerBySlot = {}
        self.triggerBySlot = triggerBySlot

        for slot, triggers in triggersBySlot.items():
            if len(triggers) &gt; 1:
                multipleTriggers[slot] = triggers

            triggerBySlot[slot] = list(triggers)[0]

        if len(multipleTriggers) == 0:
            self.console(&#34;No slot is covered by more than one trigger&#34;)
        else:
            console(
                f&#34;Slots covered by multiple triggers: {len(multipleTriggers)}&#34;,
                error=True,
            )
            for slot, triggers in multipleTriggers.items():
                triggersRep = &#34;, &#34;.join(f&#34;«{trigger}»&#34; for trigger in sorted(triggers))
                self.console(f&#34;{slot:&gt;7}: {triggersRep}&#34;, error=True)

        trigWithout = len(noHits)

        if showNoHits and (trigWithout &gt; 0):
            uncovered = 0
            console(
                &#34;Triggers without hits: &#34; f&#34;{trigWithout}x:&#34;,
                error=True,
            )

            if len(noHits):
                uncovered = self.diagnoseTriggers(noHits, detail=False)

        with fileOpen(reportFile, &#34;w&#34;) as rh:
            rh.write(&#34;label\tname\ttrigger\tscope\tsection\thits\n&#34;)

            for h in sorted(hitData):
                line = &#34;\t&#34;.join(str(c) for c in h)
                rh.write(f&#34;{line}\n&#34;)

        with fileOpen(reportTriggerBySlotFile, &#34;w&#34;) as rh:
            rh.write(&#34;slot\ttrigger\n&#34;)

            for slot, trigger in sorted(
                triggerBySlot.items(), key=lambda x: (x[1], x[0])
            ):
                rh.write(f&#34;{slot}\t{trigger}\n&#34;)

        nEnt = len(names)
        nTriggers = len(allTriggers)
        nHits = sum(e[-1] for e in hitData)

        msg = (
            f&#34;\t{nEnt} entities targeted with {nHits} occurrences. See {reportFile}&#34;
            if silent
            else dedent(
                f&#34;&#34;&#34;
                Entities targeted:          {nEnt:&gt;5}
                Triggers searched for:      {nTriggers:&gt;5}
                Triggers without hits:      {trigWithout:&gt;5}
                 - completely covered:      {trigWithout - uncovered:&gt;5}
                 - missing hits:            {uncovered:&gt;5}
                Triggers with hits:         {nTriggers - trigWithout:&gt;5}
                Total hits:                 {nHits:&gt;5}

                All hits in report file:      {reportFile}
                Triggers by slot in file:     {reportTriggerBySlotFile}
                &#34;&#34;&#34;
            )
        )
        console(msg)

    def triggerInterference(self, alsoInternal=False, alsoExpected=False):
        &#34;&#34;&#34;Produce a report of interferences between triggers.

        Triggers interfere if they have matches that intersect, i.e. there is a match
        `m1` of trigger `t1` and a match `m2` of trigger `t2` such that `m1` and
        `m2` intersect (see `tf.ner.triggers.hasCommon()`.

        Triggers may interfere *potentially*: if the triggers have something in
        common they can have overlapping matches. But it does not mean that
        the corpus contains these overlapping matches, i.e. that the triggers conflict
        *actually*.

        We report the *actually* interfering triggers only.

        Triggers within one row are associated to the same entity and work in the same
        row. It is not bad if they are interfering with each other. If there
        are overlapping matches, the trigger that wins still flags the same entity.
        The worst thing is that some of these triggers are superfluous, but there is
        no reason to be picky on superfluous triggers.

        When one trigger is a proper part of another, this is mostly intentional.
        If the longer trigger matches, it wins it from the shorter trigger, unless
        the shorter trigger&#39;s match starts before the longer trigger&#39;s match.

        We think the user expects the longer trigger to win, but it may surprise him
        if the shorter triggers wins because it starts earlier.

        Parameters
        ----------
        alsoInternal: boolean, optional False
            Also report interference between triggers on the same row.
        alsoExpected: boolean, optional False
            Also report expected interferences.
        &#34;&#34;&#34;
        if not self.properlySetup:
            return

        setName = self.setName
        annoDir = self.annoDir
        setDir = f&#34;{annoDir}/{setName}&#34;
        reportFile = f&#34;{setDir}/interference.txt&#34;

        app = self.app
        L = app.api.L
        T = app.api.T
        sheetData = self.getSheetData()
        rowMap = sheetData.rowMap
        triggerScopes = sheetData.triggerScopes

        interferences, parts = self.interference(
            rowMap,
            triggerScopes,
            self.getToTokensFunc(),
            self.getSeqFromStr,
            alsoInternal=alsoInternal,
            alsoExpected=alsoExpected,
        )

        messages = []
        witnessed = {}

        nParts = len(parts)
        plural = &#34;&#34; if nParts == 1 else &#34;es&#34;
        self.console(
            f&#34;Looking up {len(interferences)} potential interferences &#34;
            f&#34;in {len(parts)} pass{plural} over the corpus &#34;,
            newline=False,
        )

        for part in parts:
            self.console(&#34;.&#34;, newline=False)
            inventory = self.findTriggers(part)

            for trigger, data in inventory.items():
                occs = data.get(trigger, {}).get(&#34;&#34;, [])
                nOccs = len(occs)

                if nOccs:
                    witnessed[trigger] = occs

        self.console(&#34;&#34;)

        msg = (
            f&#34;{len(witnessed)} potential conflicting trigger pairs with &#34;
            f&#34;{sum(len(x) for x in witnessed.values())} conflicts&#34;
        )
        console(msg)
        messages.append(msg)

        conflicts = {}

        for (
            triggerA,
            triggerB,
            triggerC,
            scopeRepA,
            scopeRepB,
            commonScopes,
        ) in interferences:
            if triggerC not in witnessed:
                continue

            rowA = sorted(set(rowMap[triggerA]))
            rowB = sorted(set(rowMap[triggerB]))
            key = &#34;same row&#34; if rowA == rowB else &#34;different rows&#34;
            conflicts.setdefault(key, []).append(
                (
                    rowA,
                    rowB,
                    triggerA,
                    triggerB,
                    witnessed[triggerC],
                    scopeRepA,
                    scopeRepB,
                    commonScopes,
                )
            )

        for key, confls in conflicts.items():
            newConfls = []

            for (
                rowA,
                rowB,
                triggerA,
                triggerB,
                occs,
                scopeRepA,
                scopeRepB,
                commonScopes,
            ) in confls:
                hits = {}

                for occ in sorted(occs):
                    sectionNode = L.u(occ[0], otype=&#34;chunk&#34;)[0]
                    heading = tuple(
                        int(x if type(x) is int else x.lstrip(&#34;0&#34;) or &#34;0&#34;)
                        for x in T.sectionFromNode(sectionNode, fillup=True)
                    )

                    if not locInScope(heading, commonScopes):
                        continue

                    heading = app.sectionStrFromNode(sectionNode)
                    hits.setdefault(heading, []).append(occ)

                if len(hits) == 0:
                    continue

                newConfls.append(
                    (rowA, rowB, triggerA, triggerB, hits, scopeRepA, scopeRepB)
                )

            msg = f&#34;{key} ({len(newConfls)} pairs)&#34;
            msg = f&#34;----------\n{msg}\n----------&#34;
            console(msg)
            messages.append(msg)

            for (
                rowA,
                rowB,
                triggerA,
                triggerB,
                hits,
                scopeRepA,
                scopeRepB,
            ) in newConfls:
                rowRepA = &#34;,&#34;.join(str(r) for r in rowA)
                rowRepB = &#34;,&#34;.join(str(r) for r in rowB)
                msg = (
                    f&#34;{rowRepA:&lt;12} ({scopeRepA:&lt;12}): «{triggerA}»\n&#34;
                    f&#34;{rowRepB:&lt;12} ({scopeRepB:&lt;12}): «{triggerB}»&#34;
                )
                console(msg)
                messages.append(msg)

                diags = []

                i = 0

                for heading, occs in sorted(hits.items()):
                    nOccs = len(occs)

                    if i == 0:
                        diags.append([])

                    diags[-1].append(f&#34;{heading} x {nOccs}&#34;)
                    i += 1

                    if i == 5:
                        i = 0

                first = True

                for batch in diags:
                    label = f&#34;{&#39;occurrences&#39;:&gt;25}: &#34; if first else (&#34; &#34; * 27)
                    first = False
                    msg = f&#34;{label} {&#39;, &#39;.join(batch)}&#34;
                    console(msg)
                    messages.append(msg)

        with fileOpen(reportFile, &#34;w&#34;) as fh:
            for msg in messages:
                fh.write(f&#34;{msg}\n&#34;)

        console(f&#34;Diagnostic trigger interferences written to {reportFile}&#34;)

    def diagnoseTriggers(self, triggers, detail=False):
        &#34;&#34;&#34;Diagnose triggers individually.

        !!! Caution
            This method will be called by `reportHits()` and should not be called
            on its own, since it expects the instance member `triggerBySlot` which
            is constructed by `reportHits()`

        Here we have a closer look to each trigger individually, not focussing on the
        interaction with other triggers.

        The triggers will be partitioned and each part of the partition will be looked
        up in a separate pass over the corpus.

        Parameters
        ----------
        triggers: iterable of string
            The triggers that must be diagnosed.
        detail: boolean, optional False
            If True, produces more detail per trigger, see `diagnoseTrigger()`

        Returns
        -------
        int
            The number of triggers with uncovered occurrences, see `diagnoseTrigger()`
        &#34;&#34;&#34;
        if not self.properlySetup:
            return None

        sheetData = self.getSheetData()
        triggerScopes = sheetData.triggerScopes

        parts = self.partitionTriggers(triggers)

        nParts = len(parts)
        plural = &#34;&#34; if nParts == 1 else &#34;es&#34;
        self.console(
            f&#34;Looking up {len(triggers)} triggers &#34;
            f&#34;in {len(parts)} pass{plural} over the corpus &#34;,
            newline=False,
        )

        items = []

        for part in parts:
            self.console(&#34;.&#34;, newline=False)
            inventory = self.findTriggers(part)

            for trigger, data in inventory.items():
                occs = data.get(trigger, {}).get(&#34;&#34;, [])
                items.append((trigger, occs))

        uncovered = 0

        for trigger, occs in sorted(
            items,
            key=lambda x: (&#34;, &#34;.join(sorted(triggerScopes[x[0]])), x[0].lower()),
        ):
            uncovered += 0 if self.diagnoseTrigger(trigger, occs, detail=detail) else 1

        self.console(&#34;&#34;)

        return uncovered

    def diagnoseTrigger(self, trigger, occs, detail=False):
        &#34;&#34;&#34;Diagnoses an individual trigger.

        !!! Caution
            This method will be called by `diagnoseTriggers()` and should not be called
            on its own, since it expects the instance member `triggerBySlot` which
            is constructed by `reportHits()`, which calls `diagnoseTriggers()`.

        All occurrences of the trigger will be checked: is every slot in such
        an occurrence part of a match according to the original spreadsheet?

        If not so, we check whether it is a match of the trigger in question, or of
        another trigger.

        In this way we can detect where the potential but unrealized matches are.

        If there are matches of the trigger in isolation that contain slots that are
        not part of any match of any trigger in the original search, we say that
        the trigger has uncovered occurrences. It will be returned as the result of this
        function whether this is the case.

        These uncovered occurrences are reported as missing hits.

        It can also be the case that the trigger in isolation has matches that
        are completely covered by matches of other triggers in the original search.
        We can also list these, but since these are probably intentional, we suppress
        these cases unless `detail=True` is passed.

        Parameters
        ----------
        trigger: string
            The trigger to be diagnosed.
        occs: iterable of tuple of integer
            The occurrences of this trigger in the whole corpus, irrespective of scope;
        detail: boolean, optional False
            If True, produces complete diagnostics.
            Otherwise, only produces output if there are missed hits.

        Returns
        -------
        boolean
            Whether there are uncovered occurrences.
        &#34;&#34;&#34;
        if not self.properlySetup:
            return None

        app = self.app
        L = app.api.L
        triggerBySlot = self.triggerBySlot
        sheetData = self.getSheetData()
        triggerScopes = sheetData.triggerScopes

        uncoveredSlots = set()
        coveredBy = {}

        for slots in occs:
            for slot in slots:
                cTrigger = triggerBySlot.get(slot, None)

                if cTrigger is None:
                    uncoveredSlots.add(slot)
                else:
                    coveredBy.setdefault(cTrigger, set()).add(slot)

        uncoveredOccs = {}

        nUncoveredSlots = len(uncoveredSlots)
        ok = nUncoveredSlots == 0

        if nUncoveredSlots:
            for slot in sorted(uncoveredSlots):
                heading = app.sectionStrFromNode(L.u(slot, otype=&#34;chunk&#34;)[0])
                occ = uncoveredOccs.setdefault(heading, [[]])

                if len(occ[-1]) == 0 or occ[-1][-1] + 1 == slot:
                    occ[-1].append(slot)
                else:
                    occ.append([slot])

        nMissedHits = 0
        uncoveredOccsDiag = []
        uncoveredOccsDiagCompact = []

        for heading, occs in uncoveredOccs.items():
            nOccs = len(occs)
            nMissedHits += nOccs
            uncoveredOccsDiag.append(f&#34;\t\t{heading}: {nOccs} x&#34;)
            uncoveredOccsDiagCompact.append(f&#34;{heading} x {nOccs}&#34;)

        uncoveredOccsDiag[0:0] = [f&#34;\tuncovered: {nMissedHits} x&#34;]

        coveredOccsDiag = []

        for cTrigger in sorted(coveredBy, key=lambda x: x.lower()):
            thisCoveredOccsDiag = []
            coveredSlots = sorted(coveredBy[cTrigger])

            coveredHits = {}

            for slot in sorted(coveredSlots):
                heading = app.sectionStrFromNode(L.u(slot, otype=&#34;chunk&#34;)[0])
                occ = coveredHits.setdefault(heading, [[]])

                if len(occ[-1]) == 0 or occ[-1][-1] + 1 == slot:
                    occ[-1].append(slot)
                else:
                    occ.append([slot])

            nCoveredHits = 0

            for heading, occs in coveredHits.items():
                nOccs = len(occs)
                nCoveredHits += nOccs
                thisCoveredOccsDiag.append(f&#34;\t\t{heading}: {nOccs} x&#34;)

            thisCoveredOccsDiag[0:0] = [f&#34;\tcovered by: {cTrigger}: {nCoveredHits} x&#34;]

            coveredOccsDiag.extend(thisCoveredOccsDiag)

        scopeRep = f&#34;({&#39;, &#39;.join(sorted(triggerScopes[trigger]))})&#34;

        if detail:
            console(f&#34;{trigger} {scopeRep}:&#34;)

            for line in uncoveredOccsDiag:
                console(line)

            for line in coveredOccsDiag:
                console(line)

        else:
            if nUncoveredSlots == 0:
                if False:
                    console(f&#34;{trigger} {scopeRep}: covered by other triggers&#34;)
            else:
                missedHits = []

                i = 0
                for occRep in uncoveredOccsDiagCompact:
                    if i == 0:
                        missedHits.append([occRep])
                    else:
                        missedHits[-1].append(occRep)

                    i += 1
                    if i == 5:
                        i = 0

                missedHitsRep = &#34;, &#34;.join(missedHits[0])
                console(f&#34;{trigger:&lt;40} {scopeRep:&lt;12}: {missedHitsRep}&#34;, error=True)

                for m in missedHits[1:]:
                    missedHitsRep = &#34;, &#34;.join(m)
                    console(f&#34;{&#39; &#39; * 55}{missedHitsRep}&#34;, error=True)

        return ok

    def interference(
        self,
        rowMap,
        triggerScopes,
        myToTokens,
        getSeqFromStr,
        alsoInternal=False,
        alsoExpected=False,
    ):
        &#34;&#34;&#34;Workhorse to calculate interference of triggers.

        This function is used by method `triggerInterference()` for calculating the
        *potential* interferences within a set of triggers, irrespective whether
        the corpus contains instances of these interferences.

        When two triggers interfere, you can build a combined trigger out of them
        whose matches are exactly the points of interference. We call this the
        *combined* trigger of the interference.

        Parameters
        ----------
        rowMap: dict
            mapping from triggers to the rows where they occur in the spreadsheet.
            We take the set of triggers from here, so that we can issue proper
            diagnostic information later, i.e. we can mentoin the row in the spreadsheet
            where the offending triggers are.
        triggerScopes: dict
            mapping from triggers to the scopes for which they are defined.
        myToTokens: function
            corpus dependent function for parsing a trigger, which is a string,
            to tokens, in the same way as the text of the corpus is parsed into tokens.
        getSeqfromStr: function
            corpus dependent function that can translate a section heading into a
            tuple of integers that represents the same heading in the &#34;legal&#34; numbering
            system.
        alsoInternal: boolean, optional False
            Whether to report interfering triggers even if they belong to the
            same entity
        alsoExpected: boolean, optional False
            Whether to report interfering triggers even if one is a proper
            initial part of the other.

        Returns
        -------
        tuple
            There are two parts:

            *interferences*: a list of interfering pairs of triggers, where each
            interference has these components:

            *   *triggerA* the first trigger in the pair;
            *   *triggerB* the second trigger in the pair;
            *   *triggerC* the combined trigger of the interference;
            *   *scopeRepA* the scope of the first trigger;
            *   *scopeRepB* the scope of the second trigger;
            *   *commonScopes* the intersection of the scopes of both triggers.

            *parts*: a partition of the combined triggers of all interferences so that
            within each part none of these interfere.
        &#34;&#34;&#34;
        if not self.properlySetup:
            return (None, None)

        triggers = list(rowMap)

        triggerTokens, parts = makePartition(triggers, myToTokens)

        nParts = len(parts)

        interferences = []

        intersections = {}

        for i, part in enumerate(parts):
            if i == nParts - 1:
                break

            for otherPart in parts[i + 1 : nParts]:
                for triggerA in part:
                    for triggerB in otherPart:
                        tokensA = triggerTokens[triggerA]
                        tokensB = triggerTokens[triggerB]

                        if not alsoInternal:
                            rowsA = set(rowMap[triggerA])
                            rowsB = set(rowMap[triggerB])
                            if rowsA == rowsB:
                                continue

                        scopesA = &#34;,&#34;.join(sorted(triggerScopes[triggerA]))
                        scopesB = &#34;,&#34;.join(sorted(triggerScopes[triggerB]))
                        commonScopes = intersections.get((triggerA, triggerB), None)

                        if commonScopes is None:
                            commonScopes = self.intersectScopes(scopesA, scopesB)
                            intersections[(triggerA, triggerB)] = commonScopes

                        if len(commonScopes) == 0:
                            continue

                        common = hasCommon(tokensA, tokensB)

                        if common is None:
                            continue

                        ref, pos, length = common
                        nTokensA = len(tokensA)
                        nTokensB = len(tokensB)

                        nTokensLatter = nTokensB if ref == 1 else nTokensA

                        expected = length == nTokensLatter

                        if expected and not alsoExpected:
                            continue

                        if ref == 1:
                            nB = len(tokensB)
                            union = tokensA

                            if length &lt; nB:
                                union += tokensB[length:]
                        else:
                            nA = len(tokensA)
                            union = tokensB

                            if length &lt; nA:
                                union += tokensA[length:]

                        interferences.append(
                            (
                                triggerA,
                                triggerB,
                                &#34; &#34;.join(union),
                                scopesA,
                                scopesB,
                                commonScopes,
                            )
                        )

        parts = makePartition([x[2] for x in interferences], myToTokens)[1]

        return interferences, parts

    def findTriggers(self, triggers):
        &#34;&#34;&#34;Looks up occurrences of multiple triggers efficiently.

        This is a lot like `findOccs()`, but where as `findOccs()` finds
        its search instructions in the sheet data and stores its search results in the
        sheet data, this function makes its own instructions and returns the search
        results.

        We use this function when we need to investigate what triggers do in isolation
        and without scope restrictions.

        So, the instructions generated by this functions are derived from the
        spreadsheet, but ignore all scope restrictions.

        Parameters
        ----------
        triggers: iterable of string
            These are the triggers to be looked up. Typically they come from one
            part of a partition of triggers, but not necessarily so.

        Returns
        -------
        dict
            The inventory of occurrences of the triggers, as returned by
            `tf.ner.match.occMatch()`.
        &#34;&#34;&#34;
        if not self.properlySetup:
            return {}

        settings = self.settings
        spaceEscaped = settings.spaceEscaped

        setData = self.getSetData()
        tokensFromNode = self.tokensFromNode
        getSeqFromNode = self.getSeqFromNode

        buckets = setData.buckets or ()
        sheetData = self.getSheetData()
        caseSensitive = sheetData.caseSensitive

        idMap = {trigger: trigger for trigger in triggers}
        tMap = {trigger: &#34;&#34; for trigger in triggers}
        tPos = {}
        triggerSet = set()
        instructions = {(): dict(tPos=tPos, tMap=tMap, idMap=idMap)}

        for trigger in triggers:
            triggerT = toTokens(
                trigger, spaceEscaped=spaceEscaped, caseSensitive=caseSensitive
            )
            triggerSet.add(triggerT)

        for triggerT in triggerSet:
            for i, token in enumerate(triggerT):
                tPos.setdefault(i, {}).setdefault(token, set()).add(triggerT)

        inventory = occMatch(
            tokensFromNode,
            getSeqFromNode,
            buckets,
            instructions,
            spaceEscaped,
            caseSensitive=caseSensitive,
        )

        return inventory

    def findTrigger(self, trigger, show=True):
        &#34;&#34;&#34;Looks up occurrences of a single triggers.

        This is a lot like `findTriggers()`, but where as `findTriggers()` looks up
        multiple triggers, this one looks up a single trigger.

        Like `findTriggers()` the search is done without scope restrictions.

        We use this function when we need to investigate what a single trigger
        does in isolation and without scope restrictions.

        So, the instructions generated by this functions are derived from the
        spreadsheet, but ignore all scope restrictions.

        Parameters
        ----------
        trigger: string
            This is the trigger to be looked up.
        show: boolean, optional True
            If True, it shows the result on the console, otherwise it returns
            the result.

        Returns
        -------
        list or void
            The list of occurrences of the trigger, provided `show=False` is passed,
            else there is no function result.
        &#34;&#34;&#34;
        if not self.properlySetup:
            return []

        app = self.app
        L = app.api.L

        settings = self.settings
        spaceEscaped = settings.spaceEscaped

        setData = self.getSetData()
        tokensFromNode = self.tokensFromNode
        getSeqFromNode = self.getSeqFromNode

        buckets = setData.buckets or ()
        sheetData = self.getSheetData()
        caseSensitive = sheetData.caseSensitive

        triggerT = toTokens(
            trigger, spaceEscaped=spaceEscaped, caseSensitive=caseSensitive
        )
        idMap = {trigger: trigger}
        tMap = {trigger: &#34;&#34;}
        tPos = {}

        for i, token in enumerate(triggerT):
            tPos.setdefault(i, {}).setdefault(token, set()).add(triggerT)

        instructions = {(): dict(tPos=tPos, tMap=tMap, idMap=idMap)}

        inventory = occMatch(
            tokensFromNode,
            getSeqFromNode,
            buckets,
            instructions,
            spaceEscaped,
            caseSensitive=caseSensitive,
        )

        occs = inventory.get(trigger, {}).get(trigger, {}).get(&#34;&#34;, [])

        if show:
            nOccs = len(occs)
            plural = &#34;&#34; if nOccs == 1 else &#34;s&#34;
            app.dm(f&#34;**{nOccs} occurrence{plural}**\n&#34;)

            if nOccs:
                headings = set()
                highlights = set()

                for occ in occs:
                    headings.add(L.u(occ[0], otype=&#34;chunk&#34;)[0])

                    for slot in occ:
                        highlights.add(slot)

                for hd in sorted(headings):
                    app.plain(hd, highlights=highlights)
        else:
            return occs</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="tf.ner.sheets.Sheets" href="sheets.html#tf.ner.sheets.Sheets">Sheets</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="tf.ner.triggers.Triggers.diagnoseTrigger"><code class="name flex">
<span>def <span class="ident">diagnoseTrigger</span></span>(<span>self, trigger, occs, detail=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Diagnoses an individual trigger.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>This method will be called by <code>diagnoseTriggers()</code> and should not be called
on its own, since it expects the instance member <code>triggerBySlot</code> which
is constructed by <code>reportHits()</code>, which calls <code>diagnoseTriggers()</code>.</p>
</div>
<p>All occurrences of the trigger will be checked: is every slot in such
an occurrence part of a match according to the original spreadsheet?</p>
<p>If not so, we check whether it is a match of the trigger in question, or of
another trigger.</p>
<p>In this way we can detect where the potential but unrealized matches are.</p>
<p>If there are matches of the trigger in isolation that contain slots that are
not part of any match of any trigger in the original search, we say that
the trigger has uncovered occurrences. It will be returned as the result of this
function whether this is the case.</p>
<p>These uncovered occurrences are reported as missing hits.</p>
<p>It can also be the case that the trigger in isolation has matches that
are completely covered by matches of other triggers in the original search.
We can also list these, but since these are probably intentional, we suppress
these cases unless <code>detail=True</code> is passed.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>trigger</code></strong> :&ensp;<code>string</code></dt>
<dd>The trigger to be diagnosed.</dd>
<dt><strong><code>occs</code></strong> :&ensp;<code>iterable</code> of <code>tuple</code> of <code>integer</code></dt>
<dd>The occurrences of this trigger in the whole corpus, irrespective of scope;</dd>
<dt><strong><code>detail</code></strong> :&ensp;<code>boolean</code>, optional <code>False</code></dt>
<dd>If True, produces complete diagnostics.
Otherwise, only produces output if there are missed hits.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>boolean</code></dt>
<dd>Whether there are uncovered occurrences.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric/blob/3fbd589957f5b3364f2e9ec4fa03bd61f3a68e34/tf/ner/triggers.py#L746-L901" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def diagnoseTrigger(self, trigger, occs, detail=False):
    &#34;&#34;&#34;Diagnoses an individual trigger.

    !!! Caution
        This method will be called by `diagnoseTriggers()` and should not be called
        on its own, since it expects the instance member `triggerBySlot` which
        is constructed by `reportHits()`, which calls `diagnoseTriggers()`.

    All occurrences of the trigger will be checked: is every slot in such
    an occurrence part of a match according to the original spreadsheet?

    If not so, we check whether it is a match of the trigger in question, or of
    another trigger.

    In this way we can detect where the potential but unrealized matches are.

    If there are matches of the trigger in isolation that contain slots that are
    not part of any match of any trigger in the original search, we say that
    the trigger has uncovered occurrences. It will be returned as the result of this
    function whether this is the case.

    These uncovered occurrences are reported as missing hits.

    It can also be the case that the trigger in isolation has matches that
    are completely covered by matches of other triggers in the original search.
    We can also list these, but since these are probably intentional, we suppress
    these cases unless `detail=True` is passed.

    Parameters
    ----------
    trigger: string
        The trigger to be diagnosed.
    occs: iterable of tuple of integer
        The occurrences of this trigger in the whole corpus, irrespective of scope;
    detail: boolean, optional False
        If True, produces complete diagnostics.
        Otherwise, only produces output if there are missed hits.

    Returns
    -------
    boolean
        Whether there are uncovered occurrences.
    &#34;&#34;&#34;
    if not self.properlySetup:
        return None

    app = self.app
    L = app.api.L
    triggerBySlot = self.triggerBySlot
    sheetData = self.getSheetData()
    triggerScopes = sheetData.triggerScopes

    uncoveredSlots = set()
    coveredBy = {}

    for slots in occs:
        for slot in slots:
            cTrigger = triggerBySlot.get(slot, None)

            if cTrigger is None:
                uncoveredSlots.add(slot)
            else:
                coveredBy.setdefault(cTrigger, set()).add(slot)

    uncoveredOccs = {}

    nUncoveredSlots = len(uncoveredSlots)
    ok = nUncoveredSlots == 0

    if nUncoveredSlots:
        for slot in sorted(uncoveredSlots):
            heading = app.sectionStrFromNode(L.u(slot, otype=&#34;chunk&#34;)[0])
            occ = uncoveredOccs.setdefault(heading, [[]])

            if len(occ[-1]) == 0 or occ[-1][-1] + 1 == slot:
                occ[-1].append(slot)
            else:
                occ.append([slot])

    nMissedHits = 0
    uncoveredOccsDiag = []
    uncoveredOccsDiagCompact = []

    for heading, occs in uncoveredOccs.items():
        nOccs = len(occs)
        nMissedHits += nOccs
        uncoveredOccsDiag.append(f&#34;\t\t{heading}: {nOccs} x&#34;)
        uncoveredOccsDiagCompact.append(f&#34;{heading} x {nOccs}&#34;)

    uncoveredOccsDiag[0:0] = [f&#34;\tuncovered: {nMissedHits} x&#34;]

    coveredOccsDiag = []

    for cTrigger in sorted(coveredBy, key=lambda x: x.lower()):
        thisCoveredOccsDiag = []
        coveredSlots = sorted(coveredBy[cTrigger])

        coveredHits = {}

        for slot in sorted(coveredSlots):
            heading = app.sectionStrFromNode(L.u(slot, otype=&#34;chunk&#34;)[0])
            occ = coveredHits.setdefault(heading, [[]])

            if len(occ[-1]) == 0 or occ[-1][-1] + 1 == slot:
                occ[-1].append(slot)
            else:
                occ.append([slot])

        nCoveredHits = 0

        for heading, occs in coveredHits.items():
            nOccs = len(occs)
            nCoveredHits += nOccs
            thisCoveredOccsDiag.append(f&#34;\t\t{heading}: {nOccs} x&#34;)

        thisCoveredOccsDiag[0:0] = [f&#34;\tcovered by: {cTrigger}: {nCoveredHits} x&#34;]

        coveredOccsDiag.extend(thisCoveredOccsDiag)

    scopeRep = f&#34;({&#39;, &#39;.join(sorted(triggerScopes[trigger]))})&#34;

    if detail:
        console(f&#34;{trigger} {scopeRep}:&#34;)

        for line in uncoveredOccsDiag:
            console(line)

        for line in coveredOccsDiag:
            console(line)

    else:
        if nUncoveredSlots == 0:
            if False:
                console(f&#34;{trigger} {scopeRep}: covered by other triggers&#34;)
        else:
            missedHits = []

            i = 0
            for occRep in uncoveredOccsDiagCompact:
                if i == 0:
                    missedHits.append([occRep])
                else:
                    missedHits[-1].append(occRep)

                i += 1
                if i == 5:
                    i = 0

            missedHitsRep = &#34;, &#34;.join(missedHits[0])
            console(f&#34;{trigger:&lt;40} {scopeRep:&lt;12}: {missedHitsRep}&#34;, error=True)

            for m in missedHits[1:]:
                missedHitsRep = &#34;, &#34;.join(m)
                console(f&#34;{&#39; &#39; * 55}{missedHitsRep}&#34;, error=True)

    return ok</code></pre>
</details>
</dd>
<dt id="tf.ner.triggers.Triggers.diagnoseTriggers"><code class="name flex">
<span>def <span class="ident">diagnoseTriggers</span></span>(<span>self, triggers, detail=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Diagnose triggers individually.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>This method will be called by <code>reportHits()</code> and should not be called
on its own, since it expects the instance member <code>triggerBySlot</code> which
is constructed by <code>reportHits()</code></p>
</div>
<p>Here we have a closer look to each trigger individually, not focussing on the
interaction with other triggers.</p>
<p>The triggers will be partitioned and each part of the partition will be looked
up in a separate pass over the corpus.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>triggers</code></strong> :&ensp;<code>iterable</code> of <code>string</code></dt>
<dd>The triggers that must be diagnosed.</dd>
<dt><strong><code>detail</code></strong> :&ensp;<code>boolean</code>, optional <code>False</code></dt>
<dd>If True, produces more detail per trigger, see <code>diagnoseTrigger()</code></dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>The number of triggers with uncovered occurrences, see <code>diagnoseTrigger()</code></dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric/blob/3fbd589957f5b3364f2e9ec4fa03bd61f3a68e34/tf/ner/triggers.py#L682-L744" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def diagnoseTriggers(self, triggers, detail=False):
    &#34;&#34;&#34;Diagnose triggers individually.

    !!! Caution
        This method will be called by `reportHits()` and should not be called
        on its own, since it expects the instance member `triggerBySlot` which
        is constructed by `reportHits()`

    Here we have a closer look to each trigger individually, not focussing on the
    interaction with other triggers.

    The triggers will be partitioned and each part of the partition will be looked
    up in a separate pass over the corpus.

    Parameters
    ----------
    triggers: iterable of string
        The triggers that must be diagnosed.
    detail: boolean, optional False
        If True, produces more detail per trigger, see `diagnoseTrigger()`

    Returns
    -------
    int
        The number of triggers with uncovered occurrences, see `diagnoseTrigger()`
    &#34;&#34;&#34;
    if not self.properlySetup:
        return None

    sheetData = self.getSheetData()
    triggerScopes = sheetData.triggerScopes

    parts = self.partitionTriggers(triggers)

    nParts = len(parts)
    plural = &#34;&#34; if nParts == 1 else &#34;es&#34;
    self.console(
        f&#34;Looking up {len(triggers)} triggers &#34;
        f&#34;in {len(parts)} pass{plural} over the corpus &#34;,
        newline=False,
    )

    items = []

    for part in parts:
        self.console(&#34;.&#34;, newline=False)
        inventory = self.findTriggers(part)

        for trigger, data in inventory.items():
            occs = data.get(trigger, {}).get(&#34;&#34;, [])
            items.append((trigger, occs))

    uncovered = 0

    for trigger, occs in sorted(
        items,
        key=lambda x: (&#34;, &#34;.join(sorted(triggerScopes[x[0]])), x[0].lower()),
    ):
        uncovered += 0 if self.diagnoseTrigger(trigger, occs, detail=detail) else 1

    self.console(&#34;&#34;)

    return uncovered</code></pre>
</details>
</dd>
<dt id="tf.ner.triggers.Triggers.findOccs"><code class="name flex">
<span>def <span class="ident">findOccs</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Finds the occurrences of multiple triggers.</p>
<p>This is meant to efficiently list all occurrences of many token
sequences in the corpus.</p>
<p>The triggers are in member <code>instructions</code>, which must first
be constructed by reading a number of excel files.</p>
<p>It adds the member <code>inventory</code> to the object, which is a dict
with subdicts:</p>
<p><code>occurrences</code>: keyed by tuples (eid, kind), the values are
the occurrences of that entity in the corpus.
A single occurrence is represented as a tuple of slots.</p>
<p><code>names</code>: keyed by tuples (eid, kind) and then path,
the value is the name of that entity in the context indicated by path.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric/blob/3fbd589957f5b3364f2e9ec4fa03bd61f3a68e34/tf/ner/triggers.py#L284-L326" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def findOccs(self):
    &#34;&#34;&#34;Finds the occurrences of multiple triggers.

    This is meant to efficiently list all occurrences of many token
    sequences in the corpus.

    The triggers are in member `instructions`, which must first
    be constructed by reading a number of excel files.

    It adds the member `inventory` to the object, which is a dict
    with subdicts:

    `occurrences`: keyed by tuples (eid, kind), the values are
    the occurrences of that entity in the corpus.
    A single occurrence is represented as a tuple of slots.

    `names`: keyed by tuples (eid, kind) and then path,
    the value is the name of that entity in the context indicated by path.

    &#34;&#34;&#34;
    if not self.properlySetup:
        return

    settings = self.settings
    spaceEscaped = settings.spaceEscaped

    setData = self.getSetData()
    tokensFromNode = self.tokensFromNode
    getSeqFromNode = self.getSeqFromNode

    buckets = setData.buckets or ()
    sheetData = self.getSheetData()
    caseSensitive = sheetData.caseSensitive
    instructions = sheetData.instructions

    sheetData.inventory = occMatch(
        tokensFromNode,
        getSeqFromNode,
        buckets,
        instructions,
        spaceEscaped,
        caseSensitive=caseSensitive,
    )</code></pre>
</details>
</dd>
<dt id="tf.ner.triggers.Triggers.findTrigger"><code class="name flex">
<span>def <span class="ident">findTrigger</span></span>(<span>self, trigger, show=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Looks up occurrences of a single triggers.</p>
<p>This is a lot like <code>findTriggers()</code>, but where as <code>findTriggers()</code> looks up
multiple triggers, this one looks up a single trigger.</p>
<p>Like <code>findTriggers()</code> the search is done without scope restrictions.</p>
<p>We use this function when we need to investigate what a single trigger
does in isolation and without scope restrictions.</p>
<p>So, the instructions generated by this functions are derived from the
spreadsheet, but ignore all scope restrictions.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>trigger</code></strong> :&ensp;<code>string</code></dt>
<dd>This is the trigger to be looked up.</dd>
<dt><strong><code>show</code></strong> :&ensp;<code>boolean</code>, optional <code>True</code></dt>
<dd>If True, it shows the result on the console, otherwise it returns
the result.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code> or <code>void</code></dt>
<dd>The list of occurrences of the trigger, provided <code>show=False</code> is passed,
else there is no function result.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric/blob/3fbd589957f5b3364f2e9ec4fa03bd61f3a68e34/tf/ner/triggers.py#L1114-L1200" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def findTrigger(self, trigger, show=True):
    &#34;&#34;&#34;Looks up occurrences of a single triggers.

    This is a lot like `findTriggers()`, but where as `findTriggers()` looks up
    multiple triggers, this one looks up a single trigger.

    Like `findTriggers()` the search is done without scope restrictions.

    We use this function when we need to investigate what a single trigger
    does in isolation and without scope restrictions.

    So, the instructions generated by this functions are derived from the
    spreadsheet, but ignore all scope restrictions.

    Parameters
    ----------
    trigger: string
        This is the trigger to be looked up.
    show: boolean, optional True
        If True, it shows the result on the console, otherwise it returns
        the result.

    Returns
    -------
    list or void
        The list of occurrences of the trigger, provided `show=False` is passed,
        else there is no function result.
    &#34;&#34;&#34;
    if not self.properlySetup:
        return []

    app = self.app
    L = app.api.L

    settings = self.settings
    spaceEscaped = settings.spaceEscaped

    setData = self.getSetData()
    tokensFromNode = self.tokensFromNode
    getSeqFromNode = self.getSeqFromNode

    buckets = setData.buckets or ()
    sheetData = self.getSheetData()
    caseSensitive = sheetData.caseSensitive

    triggerT = toTokens(
        trigger, spaceEscaped=spaceEscaped, caseSensitive=caseSensitive
    )
    idMap = {trigger: trigger}
    tMap = {trigger: &#34;&#34;}
    tPos = {}

    for i, token in enumerate(triggerT):
        tPos.setdefault(i, {}).setdefault(token, set()).add(triggerT)

    instructions = {(): dict(tPos=tPos, tMap=tMap, idMap=idMap)}

    inventory = occMatch(
        tokensFromNode,
        getSeqFromNode,
        buckets,
        instructions,
        spaceEscaped,
        caseSensitive=caseSensitive,
    )

    occs = inventory.get(trigger, {}).get(trigger, {}).get(&#34;&#34;, [])

    if show:
        nOccs = len(occs)
        plural = &#34;&#34; if nOccs == 1 else &#34;s&#34;
        app.dm(f&#34;**{nOccs} occurrence{plural}**\n&#34;)

        if nOccs:
            headings = set()
            highlights = set()

            for occ in occs:
                headings.add(L.u(occ[0], otype=&#34;chunk&#34;)[0])

                for slot in occ:
                    highlights.add(slot)

            for hd in sorted(headings):
                app.plain(hd, highlights=highlights)
    else:
        return occs</code></pre>
</details>
</dd>
<dt id="tf.ner.triggers.Triggers.findTriggers"><code class="name flex">
<span>def <span class="ident">findTriggers</span></span>(<span>self, triggers)</span>
</code></dt>
<dd>
<div class="desc"><p>Looks up occurrences of multiple triggers efficiently.</p>
<p>This is a lot like <code>findOccs()</code>, but where as <code>findOccs()</code> finds
its search instructions in the sheet data and stores its search results in the
sheet data, this function makes its own instructions and returns the search
results.</p>
<p>We use this function when we need to investigate what triggers do in isolation
and without scope restrictions.</p>
<p>So, the instructions generated by this functions are derived from the
spreadsheet, but ignore all scope restrictions.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>triggers</code></strong> :&ensp;<code>iterable</code> of <code>string</code></dt>
<dd>These are the triggers to be looked up. Typically they come from one
part of a partition of triggers, but not necessarily so.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>The inventory of occurrences of the triggers, as returned by
<code><a title="tf.ner.match.occMatch" href="match.html#tf.ner.match.occMatch">occMatch()</a></code>.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric/blob/3fbd589957f5b3364f2e9ec4fa03bd61f3a68e34/tf/ner/triggers.py#L1047-L1112" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def findTriggers(self, triggers):
    &#34;&#34;&#34;Looks up occurrences of multiple triggers efficiently.

    This is a lot like `findOccs()`, but where as `findOccs()` finds
    its search instructions in the sheet data and stores its search results in the
    sheet data, this function makes its own instructions and returns the search
    results.

    We use this function when we need to investigate what triggers do in isolation
    and without scope restrictions.

    So, the instructions generated by this functions are derived from the
    spreadsheet, but ignore all scope restrictions.

    Parameters
    ----------
    triggers: iterable of string
        These are the triggers to be looked up. Typically they come from one
        part of a partition of triggers, but not necessarily so.

    Returns
    -------
    dict
        The inventory of occurrences of the triggers, as returned by
        `tf.ner.match.occMatch()`.
    &#34;&#34;&#34;
    if not self.properlySetup:
        return {}

    settings = self.settings
    spaceEscaped = settings.spaceEscaped

    setData = self.getSetData()
    tokensFromNode = self.tokensFromNode
    getSeqFromNode = self.getSeqFromNode

    buckets = setData.buckets or ()
    sheetData = self.getSheetData()
    caseSensitive = sheetData.caseSensitive

    idMap = {trigger: trigger for trigger in triggers}
    tMap = {trigger: &#34;&#34; for trigger in triggers}
    tPos = {}
    triggerSet = set()
    instructions = {(): dict(tPos=tPos, tMap=tMap, idMap=idMap)}

    for trigger in triggers:
        triggerT = toTokens(
            trigger, spaceEscaped=spaceEscaped, caseSensitive=caseSensitive
        )
        triggerSet.add(triggerT)

    for triggerT in triggerSet:
        for i, token in enumerate(triggerT):
            tPos.setdefault(i, {}).setdefault(token, set()).add(triggerT)

    inventory = occMatch(
        tokensFromNode,
        getSeqFromNode,
        buckets,
        instructions,
        spaceEscaped,
        caseSensitive=caseSensitive,
    )

    return inventory</code></pre>
</details>
</dd>
<dt id="tf.ner.triggers.Triggers.interference"><code class="name flex">
<span>def <span class="ident">interference</span></span>(<span>self, rowMap, triggerScopes, myToTokens, getSeqFromStr, alsoInternal=False, alsoExpected=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Workhorse to calculate interference of triggers.</p>
<p>This function is used by method <code>triggerInterference()</code> for calculating the
<em>potential</em> interferences within a set of triggers, irrespective whether
the corpus contains instances of these interferences.</p>
<p>When two triggers interfere, you can build a combined trigger out of them
whose matches are exactly the points of interference. We call this the
<em>combined</em> trigger of the interference.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>rowMap</code></strong> :&ensp;<code>dict</code></dt>
<dd>mapping from triggers to the rows where they occur in the spreadsheet.
We take the set of triggers from here, so that we can issue proper
diagnostic information later, i.e. we can mentoin the row in the spreadsheet
where the offending triggers are.</dd>
<dt><strong><code>triggerScopes</code></strong> :&ensp;<code>dict</code></dt>
<dd>mapping from triggers to the scopes for which they are defined.</dd>
<dt><strong><code>myToTokens</code></strong> :&ensp;<code>function</code></dt>
<dd>corpus dependent function for parsing a trigger, which is a string,
to tokens, in the same way as the text of the corpus is parsed into tokens.</dd>
<dt><strong><code>getSeqfromStr</code></strong> :&ensp;<code>function</code></dt>
<dd>corpus dependent function that can translate a section heading into a
tuple of integers that represents the same heading in the "legal" numbering
system.</dd>
<dt><strong><code>alsoInternal</code></strong> :&ensp;<code>boolean</code>, optional <code>False</code></dt>
<dd>Whether to report interfering triggers even if they belong to the
same entity</dd>
<dt><strong><code>alsoExpected</code></strong> :&ensp;<code>boolean</code>, optional <code>False</code></dt>
<dd>Whether to report interfering triggers even if one is a proper
initial part of the other.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code></dt>
<dd>
<p>There are two parts:</p>
<p><em>interferences</em>: a list of interfering pairs of triggers, where each
interference has these components:</p>
<ul>
<li><em>triggerA</em> the first trigger in the pair;</li>
<li><em>triggerB</em> the second trigger in the pair;</li>
<li><em>triggerC</em> the combined trigger of the interference;</li>
<li><em>scopeRepA</em> the scope of the first trigger;</li>
<li><em>scopeRepB</em> the scope of the second trigger;</li>
<li><em>commonScopes</em> the intersection of the scopes of both triggers.</li>
</ul>
<p><em>parts</em>: a partition of the combined triggers of all interferences so that
within each part none of these interfere.</p>
</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric/blob/3fbd589957f5b3364f2e9ec4fa03bd61f3a68e34/tf/ner/triggers.py#L903-L1045" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def interference(
    self,
    rowMap,
    triggerScopes,
    myToTokens,
    getSeqFromStr,
    alsoInternal=False,
    alsoExpected=False,
):
    &#34;&#34;&#34;Workhorse to calculate interference of triggers.

    This function is used by method `triggerInterference()` for calculating the
    *potential* interferences within a set of triggers, irrespective whether
    the corpus contains instances of these interferences.

    When two triggers interfere, you can build a combined trigger out of them
    whose matches are exactly the points of interference. We call this the
    *combined* trigger of the interference.

    Parameters
    ----------
    rowMap: dict
        mapping from triggers to the rows where they occur in the spreadsheet.
        We take the set of triggers from here, so that we can issue proper
        diagnostic information later, i.e. we can mentoin the row in the spreadsheet
        where the offending triggers are.
    triggerScopes: dict
        mapping from triggers to the scopes for which they are defined.
    myToTokens: function
        corpus dependent function for parsing a trigger, which is a string,
        to tokens, in the same way as the text of the corpus is parsed into tokens.
    getSeqfromStr: function
        corpus dependent function that can translate a section heading into a
        tuple of integers that represents the same heading in the &#34;legal&#34; numbering
        system.
    alsoInternal: boolean, optional False
        Whether to report interfering triggers even if they belong to the
        same entity
    alsoExpected: boolean, optional False
        Whether to report interfering triggers even if one is a proper
        initial part of the other.

    Returns
    -------
    tuple
        There are two parts:

        *interferences*: a list of interfering pairs of triggers, where each
        interference has these components:

        *   *triggerA* the first trigger in the pair;
        *   *triggerB* the second trigger in the pair;
        *   *triggerC* the combined trigger of the interference;
        *   *scopeRepA* the scope of the first trigger;
        *   *scopeRepB* the scope of the second trigger;
        *   *commonScopes* the intersection of the scopes of both triggers.

        *parts*: a partition of the combined triggers of all interferences so that
        within each part none of these interfere.
    &#34;&#34;&#34;
    if not self.properlySetup:
        return (None, None)

    triggers = list(rowMap)

    triggerTokens, parts = makePartition(triggers, myToTokens)

    nParts = len(parts)

    interferences = []

    intersections = {}

    for i, part in enumerate(parts):
        if i == nParts - 1:
            break

        for otherPart in parts[i + 1 : nParts]:
            for triggerA in part:
                for triggerB in otherPart:
                    tokensA = triggerTokens[triggerA]
                    tokensB = triggerTokens[triggerB]

                    if not alsoInternal:
                        rowsA = set(rowMap[triggerA])
                        rowsB = set(rowMap[triggerB])
                        if rowsA == rowsB:
                            continue

                    scopesA = &#34;,&#34;.join(sorted(triggerScopes[triggerA]))
                    scopesB = &#34;,&#34;.join(sorted(triggerScopes[triggerB]))
                    commonScopes = intersections.get((triggerA, triggerB), None)

                    if commonScopes is None:
                        commonScopes = self.intersectScopes(scopesA, scopesB)
                        intersections[(triggerA, triggerB)] = commonScopes

                    if len(commonScopes) == 0:
                        continue

                    common = hasCommon(tokensA, tokensB)

                    if common is None:
                        continue

                    ref, pos, length = common
                    nTokensA = len(tokensA)
                    nTokensB = len(tokensB)

                    nTokensLatter = nTokensB if ref == 1 else nTokensA

                    expected = length == nTokensLatter

                    if expected and not alsoExpected:
                        continue

                    if ref == 1:
                        nB = len(tokensB)
                        union = tokensA

                        if length &lt; nB:
                            union += tokensB[length:]
                    else:
                        nA = len(tokensA)
                        union = tokensB

                        if length &lt; nA:
                            union += tokensA[length:]

                    interferences.append(
                        (
                            triggerA,
                            triggerB,
                            &#34; &#34;.join(union),
                            scopesA,
                            scopesB,
                            commonScopes,
                        )
                    )

    parts = makePartition([x[2] for x in interferences], myToTokens)[1]

    return interferences, parts</code></pre>
</details>
</dd>
<dt id="tf.ner.triggers.Triggers.partitionTriggers"><code class="name flex">
<span>def <span class="ident">partitionTriggers</span></span>(<span>self, triggers)</span>
</code></dt>
<dd>
<div class="desc"><p>Wrapper around the partitioning function.</p>
<p>This function calls <code><a title="tf.ner.triggers.makePartition" href="#tf.ner.triggers.makePartition">makePartition()</a></code> with the corpus
dependent parameter for turning strings into tokens.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>triggers</code></strong> :&ensp;<code>iterable</code> of <code>string</code></dt>
<dd>A sequence of triggers.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code></dt>
<dd>The same as what <code><a title="tf.ner.triggers.makePartition" href="#tf.ner.triggers.makePartition">makePartition()</a></code> returns.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric/blob/3fbd589957f5b3364f2e9ec4fa03bd61f3a68e34/tf/ner/triggers.py#L266-L282" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def partitionTriggers(self, triggers):
    &#34;&#34;&#34;Wrapper around the partitioning function.

    This function calls `tf.ner.triggers.makePartition()` with the corpus
    dependent parameter for turning strings into tokens.

    Parameters
    ----------
    triggers: iterable of string
        A sequence of triggers.

    Returns
    -------
    tuple
        The same as what `tf.ner.triggers.makePartition()` returns.
    &#34;&#34;&#34;
    return makePartition(triggers, self.getToTokensFunc())[1]</code></pre>
</details>
</dd>
<dt id="tf.ner.triggers.Triggers.reportHits"><code class="name flex">
<span>def <span class="ident">reportHits</span></span>(<span>self, silent=None, showNoHits=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Reports the inventory.</p>
<p>It diagnoses all triggers by means of <code>diagnoseTriggers()</code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>silent</code></strong> :&ensp;<code>boolean</code>, optional <code>None</code></dt>
<dd>Whether to be silent. If None, it is taken from the corresponding member
of the instance.</dd>
<dt><strong><code>showNoHits</code></strong> :&ensp;<code>boolean</code>, optional <code>False</code></dt>
<dd>Whether to show which triggers do not have hits.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric/blob/3fbd589957f5b3364f2e9ec4fa03bd61f3a68e34/tf/ner/triggers.py#L328-L473" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def reportHits(self, silent=None, showNoHits=False):
    &#34;&#34;&#34;Reports the inventory.

    It diagnoses all triggers by means of `diagnoseTriggers()`.

    Parameters
    ----------
    silent: boolean, optional None
        Whether to be silent. If None, it is taken from the corresponding member
        of the instance.
    showNoHits: boolean, optional False
        Whether to show which triggers do not have hits.
    &#34;&#34;&#34;
    if not self.properlySetup:
        return

    silent = self.silent if silent is None else silent
    sectionHead = self.sectionHead
    sheetData = self.getSheetData()
    allTriggers = sheetData.allTriggers
    inventory = sheetData.inventory

    setName = self.setName
    annoDir = self.annoDir
    setDir = f&#34;{annoDir}/{setName}&#34;
    reportFile = f&#34;{setDir}/hits.tsv&#34;
    reportTriggerBySlotFile = f&#34;{setDir}/triggerBySlot.tsv&#34;

    hitData = []
    names = set()
    noHits = set()
    triggersBySlot = {}

    for e in sorted(allTriggers):
        (name, eidkind, trigger, scope) = e

        names.add(name)

        entry = (name, trigger, scope)
        section = &#34;&#34;
        hits = &#34;&#34;

        entInfo = inventory.get(eidkind, None)

        if entInfo is None:
            hitData.append((&#34;!E&#34;, *entry, &#34;&#34;, 0))
            noHits.add(trigger)
            continue

        triggerInfo = entInfo.get(trigger, None)

        if triggerInfo is None:
            hitData.append((&#34;!T&#34;, *entry, &#34;&#34;, 0))
            noHits.add(trigger)
            continue

        occs = triggerInfo.get(scope, None)

        if occs is None or len(occs) == 0:
            hitData.append((&#34;!P&#34;, *entry, &#34;&#34;, 0))
            noHits.add(trigger)
            continue

        sectionInfo = collections.Counter()

        for slots in occs:
            for slot in slots:
                triggersBySlot.setdefault(slot, set()).add(trigger)

            section = sectionHead(slots[0])
            sectionInfo[section] += 1

        for section, hits in sorted(sectionInfo.items()):
            hitData.append((&#34;OK&#34;, *entry, section, hits))

    multipleTriggers = {}
    triggerBySlot = {}
    self.triggerBySlot = triggerBySlot

    for slot, triggers in triggersBySlot.items():
        if len(triggers) &gt; 1:
            multipleTriggers[slot] = triggers

        triggerBySlot[slot] = list(triggers)[0]

    if len(multipleTriggers) == 0:
        self.console(&#34;No slot is covered by more than one trigger&#34;)
    else:
        console(
            f&#34;Slots covered by multiple triggers: {len(multipleTriggers)}&#34;,
            error=True,
        )
        for slot, triggers in multipleTriggers.items():
            triggersRep = &#34;, &#34;.join(f&#34;«{trigger}»&#34; for trigger in sorted(triggers))
            self.console(f&#34;{slot:&gt;7}: {triggersRep}&#34;, error=True)

    trigWithout = len(noHits)

    if showNoHits and (trigWithout &gt; 0):
        uncovered = 0
        console(
            &#34;Triggers without hits: &#34; f&#34;{trigWithout}x:&#34;,
            error=True,
        )

        if len(noHits):
            uncovered = self.diagnoseTriggers(noHits, detail=False)

    with fileOpen(reportFile, &#34;w&#34;) as rh:
        rh.write(&#34;label\tname\ttrigger\tscope\tsection\thits\n&#34;)

        for h in sorted(hitData):
            line = &#34;\t&#34;.join(str(c) for c in h)
            rh.write(f&#34;{line}\n&#34;)

    with fileOpen(reportTriggerBySlotFile, &#34;w&#34;) as rh:
        rh.write(&#34;slot\ttrigger\n&#34;)

        for slot, trigger in sorted(
            triggerBySlot.items(), key=lambda x: (x[1], x[0])
        ):
            rh.write(f&#34;{slot}\t{trigger}\n&#34;)

    nEnt = len(names)
    nTriggers = len(allTriggers)
    nHits = sum(e[-1] for e in hitData)

    msg = (
        f&#34;\t{nEnt} entities targeted with {nHits} occurrences. See {reportFile}&#34;
        if silent
        else dedent(
            f&#34;&#34;&#34;
            Entities targeted:          {nEnt:&gt;5}
            Triggers searched for:      {nTriggers:&gt;5}
            Triggers without hits:      {trigWithout:&gt;5}
             - completely covered:      {trigWithout - uncovered:&gt;5}
             - missing hits:            {uncovered:&gt;5}
            Triggers with hits:         {nTriggers - trigWithout:&gt;5}
            Total hits:                 {nHits:&gt;5}

            All hits in report file:      {reportFile}
            Triggers by slot in file:     {reportTriggerBySlotFile}
            &#34;&#34;&#34;
        )
    )
    console(msg)</code></pre>
</details>
</dd>
<dt id="tf.ner.triggers.Triggers.triggerInterference"><code class="name flex">
<span>def <span class="ident">triggerInterference</span></span>(<span>self, alsoInternal=False, alsoExpected=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Produce a report of interferences between triggers.</p>
<p>Triggers interfere if they have matches that intersect, i.e. there is a match
<code>m1</code> of trigger <code>t1</code> and a match <code>m2</code> of trigger <code>t2</code> such that <code>m1</code> and
<code>m2</code> intersect (see <code><a title="tf.ner.triggers.hasCommon" href="#tf.ner.triggers.hasCommon">hasCommon()</a></code>.</p>
<p>Triggers may interfere <em>potentially</em>: if the triggers have something in
common they can have overlapping matches. But it does not mean that
the corpus contains these overlapping matches, i.e. that the triggers conflict
<em>actually</em>.</p>
<p>We report the <em>actually</em> interfering triggers only.</p>
<p>Triggers within one row are associated to the same entity and work in the same
row. It is not bad if they are interfering with each other. If there
are overlapping matches, the trigger that wins still flags the same entity.
The worst thing is that some of these triggers are superfluous, but there is
no reason to be picky on superfluous triggers.</p>
<p>When one trigger is a proper part of another, this is mostly intentional.
If the longer trigger matches, it wins it from the shorter trigger, unless
the shorter trigger's match starts before the longer trigger's match.</p>
<p>We think the user expects the longer trigger to win, but it may surprise him
if the shorter triggers wins because it starts earlier.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>alsoInternal</code></strong> :&ensp;<code>boolean</code>, optional <code>False</code></dt>
<dd>Also report interference between triggers on the same row.</dd>
<dt><strong><code>alsoExpected</code></strong> :&ensp;<code>boolean</code>, optional <code>False</code></dt>
<dd>Also report expected interferences.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/annotation/text-fabric/blob/3fbd589957f5b3364f2e9ec4fa03bd61f3a68e34/tf/ner/triggers.py#L475-L680" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def triggerInterference(self, alsoInternal=False, alsoExpected=False):
    &#34;&#34;&#34;Produce a report of interferences between triggers.

    Triggers interfere if they have matches that intersect, i.e. there is a match
    `m1` of trigger `t1` and a match `m2` of trigger `t2` such that `m1` and
    `m2` intersect (see `tf.ner.triggers.hasCommon()`.

    Triggers may interfere *potentially*: if the triggers have something in
    common they can have overlapping matches. But it does not mean that
    the corpus contains these overlapping matches, i.e. that the triggers conflict
    *actually*.

    We report the *actually* interfering triggers only.

    Triggers within one row are associated to the same entity and work in the same
    row. It is not bad if they are interfering with each other. If there
    are overlapping matches, the trigger that wins still flags the same entity.
    The worst thing is that some of these triggers are superfluous, but there is
    no reason to be picky on superfluous triggers.

    When one trigger is a proper part of another, this is mostly intentional.
    If the longer trigger matches, it wins it from the shorter trigger, unless
    the shorter trigger&#39;s match starts before the longer trigger&#39;s match.

    We think the user expects the longer trigger to win, but it may surprise him
    if the shorter triggers wins because it starts earlier.

    Parameters
    ----------
    alsoInternal: boolean, optional False
        Also report interference between triggers on the same row.
    alsoExpected: boolean, optional False
        Also report expected interferences.
    &#34;&#34;&#34;
    if not self.properlySetup:
        return

    setName = self.setName
    annoDir = self.annoDir
    setDir = f&#34;{annoDir}/{setName}&#34;
    reportFile = f&#34;{setDir}/interference.txt&#34;

    app = self.app
    L = app.api.L
    T = app.api.T
    sheetData = self.getSheetData()
    rowMap = sheetData.rowMap
    triggerScopes = sheetData.triggerScopes

    interferences, parts = self.interference(
        rowMap,
        triggerScopes,
        self.getToTokensFunc(),
        self.getSeqFromStr,
        alsoInternal=alsoInternal,
        alsoExpected=alsoExpected,
    )

    messages = []
    witnessed = {}

    nParts = len(parts)
    plural = &#34;&#34; if nParts == 1 else &#34;es&#34;
    self.console(
        f&#34;Looking up {len(interferences)} potential interferences &#34;
        f&#34;in {len(parts)} pass{plural} over the corpus &#34;,
        newline=False,
    )

    for part in parts:
        self.console(&#34;.&#34;, newline=False)
        inventory = self.findTriggers(part)

        for trigger, data in inventory.items():
            occs = data.get(trigger, {}).get(&#34;&#34;, [])
            nOccs = len(occs)

            if nOccs:
                witnessed[trigger] = occs

    self.console(&#34;&#34;)

    msg = (
        f&#34;{len(witnessed)} potential conflicting trigger pairs with &#34;
        f&#34;{sum(len(x) for x in witnessed.values())} conflicts&#34;
    )
    console(msg)
    messages.append(msg)

    conflicts = {}

    for (
        triggerA,
        triggerB,
        triggerC,
        scopeRepA,
        scopeRepB,
        commonScopes,
    ) in interferences:
        if triggerC not in witnessed:
            continue

        rowA = sorted(set(rowMap[triggerA]))
        rowB = sorted(set(rowMap[triggerB]))
        key = &#34;same row&#34; if rowA == rowB else &#34;different rows&#34;
        conflicts.setdefault(key, []).append(
            (
                rowA,
                rowB,
                triggerA,
                triggerB,
                witnessed[triggerC],
                scopeRepA,
                scopeRepB,
                commonScopes,
            )
        )

    for key, confls in conflicts.items():
        newConfls = []

        for (
            rowA,
            rowB,
            triggerA,
            triggerB,
            occs,
            scopeRepA,
            scopeRepB,
            commonScopes,
        ) in confls:
            hits = {}

            for occ in sorted(occs):
                sectionNode = L.u(occ[0], otype=&#34;chunk&#34;)[0]
                heading = tuple(
                    int(x if type(x) is int else x.lstrip(&#34;0&#34;) or &#34;0&#34;)
                    for x in T.sectionFromNode(sectionNode, fillup=True)
                )

                if not locInScope(heading, commonScopes):
                    continue

                heading = app.sectionStrFromNode(sectionNode)
                hits.setdefault(heading, []).append(occ)

            if len(hits) == 0:
                continue

            newConfls.append(
                (rowA, rowB, triggerA, triggerB, hits, scopeRepA, scopeRepB)
            )

        msg = f&#34;{key} ({len(newConfls)} pairs)&#34;
        msg = f&#34;----------\n{msg}\n----------&#34;
        console(msg)
        messages.append(msg)

        for (
            rowA,
            rowB,
            triggerA,
            triggerB,
            hits,
            scopeRepA,
            scopeRepB,
        ) in newConfls:
            rowRepA = &#34;,&#34;.join(str(r) for r in rowA)
            rowRepB = &#34;,&#34;.join(str(r) for r in rowB)
            msg = (
                f&#34;{rowRepA:&lt;12} ({scopeRepA:&lt;12}): «{triggerA}»\n&#34;
                f&#34;{rowRepB:&lt;12} ({scopeRepB:&lt;12}): «{triggerB}»&#34;
            )
            console(msg)
            messages.append(msg)

            diags = []

            i = 0

            for heading, occs in sorted(hits.items()):
                nOccs = len(occs)

                if i == 0:
                    diags.append([])

                diags[-1].append(f&#34;{heading} x {nOccs}&#34;)
                i += 1

                if i == 5:
                    i = 0

            first = True

            for batch in diags:
                label = f&#34;{&#39;occurrences&#39;:&gt;25}: &#34; if first else (&#34; &#34; * 27)
                first = False
                msg = f&#34;{label} {&#39;, &#39;.join(batch)}&#34;
                console(msg)
                messages.append(msg)

    with fileOpen(reportFile, &#34;w&#34;) as fh:
        for msg in messages:
            fh.write(f&#34;{msg}\n&#34;)

    console(f&#34;Diagnostic trigger interferences written to {reportFile}&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<p><a href="https://github.com/annotation" title="annotation on GitHub"><img src="../../tf/images/tf-small.png" alt="annotation"></a></p>
<p><a href="../../tf/index.html">tf home</a> -
<a href="../../tf/cheatsheet.html">cheat sheet</a> -
<a href="https://github.com/annotation/text-fabric" title="GitHub repo"><img src="../../tf/images/GitHub_Logo.png" alt="GitHub" width="50"></a></p>
</p>
<form>
<input id="lunr-search" name="q" placeholder="🔎 Search ..." aria-label="Search"
disabled minlength="2">
</form>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/tingle/0.15.3/tingle.min.css" integrity="sha512-j1u8eUJ4f23xPPxwOrLUPQaCD2dwzNqqmDDcWS4deWsMv2ohLqmXXuP3hU7g8TyzbMSakP/mMqoNBYWj8AEIFg==" crossorigin>
<script src="https://cdnjs.cloudflare.com/ajax/libs/tingle/0.15.3/tingle.min.js" integrity="sha512-plGUER9JkeEWPPqQBE4sdLqBoQug5Ap+BCGMc7bJ8BXkm+VVj6QzkpBz5Yv2yPkkq+cqg9IpkBaGCas6uDbW8g==" crossorigin></script>
<style>
.modal-dialog iframe {
width: 100vw;
height: calc(100vh - 80px);
}
@media screen and (min-width: 700px) {
.modal-dialog iframe {
width: 70vw;
height: 80vh;
}
}
.modal-dialog .tingle-modal-box {width: auto;}
.modal-dialog .tingle-modal-box__content {padding: 0;}
</style>
<script>
const input = document.getElementById('lunr-search');
input.disabled = false;
input.form.addEventListener('submit', (ev) => {
ev.preventDefault();
const url = new URL(window.location);
url.searchParams.set('q', input.value);
history.replaceState({}, null, url.toString());
search(input.value);
});
const query = new URL(window.location).searchParams.get('q');
if (query)
search(query);
function search(query) {
const url = '../../doc-search.html#' + encodeURIComponent(query);
new tingle.modal({
cssClass: ['modal-dialog'],
onClose: () => {
const url = new URL(window.location);
url.searchParams.delete('q');
history.replaceState({}, null, url.toString());
setTimeout(() => input.focus(), 100);
}
}).setContent('<iframe src="' + url + '"></iframe>').open();
}
</script>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="tf.ner" href="index.html">tf.ner</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="tf.ner.triggers.hasCommon" href="#tf.ner.triggers.hasCommon">hasCommon</a></code></li>
<li><code><a title="tf.ner.triggers.makePartition" href="#tf.ner.triggers.makePartition">makePartition</a></code></li>
<li><code><a title="tf.ner.triggers.testCommon" href="#tf.ner.triggers.testCommon">testCommon</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="tf.ner.triggers.Triggers" href="#tf.ner.triggers.Triggers">Triggers</a></code></h4>
<ul class="two-column">
<li><code><a title="tf.ner.triggers.Triggers.diagnoseTrigger" href="#tf.ner.triggers.Triggers.diagnoseTrigger">diagnoseTrigger</a></code></li>
<li><code><a title="tf.ner.triggers.Triggers.diagnoseTriggers" href="#tf.ner.triggers.Triggers.diagnoseTriggers">diagnoseTriggers</a></code></li>
<li><code><a title="tf.ner.triggers.Triggers.findOccs" href="#tf.ner.triggers.Triggers.findOccs">findOccs</a></code></li>
<li><code><a title="tf.ner.triggers.Triggers.findTrigger" href="#tf.ner.triggers.Triggers.findTrigger">findTrigger</a></code></li>
<li><code><a title="tf.ner.triggers.Triggers.findTriggers" href="#tf.ner.triggers.Triggers.findTriggers">findTriggers</a></code></li>
<li><code><a title="tf.ner.triggers.Triggers.interference" href="#tf.ner.triggers.Triggers.interference">interference</a></code></li>
<li><code><a title="tf.ner.triggers.Triggers.partitionTriggers" href="#tf.ner.triggers.Triggers.partitionTriggers">partitionTriggers</a></code></li>
<li><code><a title="tf.ner.triggers.Triggers.reportHits" href="#tf.ner.triggers.Triggers.reportHits">reportHits</a></code></li>
<li><code><a title="tf.ner.triggers.Triggers.triggerInterference" href="#tf.ner.triggers.Triggers.triggerInterference">triggerInterference</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<a href="https://pure.knaw.nl/portal/en/persons/dirk-roorda">Dirk Roorda</a>
<a href="https://huc.knaw.nl"><img alt="HuC" src="../../tf/images/huc.png" width="200" alt="Humanities Cluster"></a>
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
